=  ğŸ”§ ç›£è¦–ã¡ã‚ƒã‚“(KanshiChan) ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆè©³ç´°
:toc: left
:toc-title: ç›®æ¬¡
:toclevels: 4
:numbered:
:source-highlighter: highlight.js
:icons: font
:doctype: book
:version: 1.0.0
:author: KanshiChan Development Team
:email: team@kanshichan.dev
:revnumber: 1.0
:revdate: {docdate}
:experimental:

== ğŸ“– æ¦‚è¦

ç›£è¦–ã¡ã‚ƒã‚“ï¼ˆKanshiChanï¼‰ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã®è©³ç´°è¨­è¨ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã™ã€‚
ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å…·ä½“çš„ãªå®Ÿè£…è¨­è¨ˆã€ã‚¯ãƒ©ã‚¹æ§‹é€ ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆç­‰ã‚’åŒ…æ‹¬çš„ã«èª¬æ˜ã—ã¾ã™ã€‚

[NOTE]
====
ğŸ“‹ **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±**

* **å¯¾è±¡èª­è€…**: é–‹ç™ºè€…ã€è¨­è¨ˆè€…ã€æŠ€è¡“ãƒªãƒ¼ãƒ‰ã€æ–°è¦å‚åŠ é–‹ç™ºè€…
* **å‰æçŸ¥è­˜**: Python/Flaskã€React/TypeScriptã€AI/MLåŸºç¤ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ
* **è¨­è¨ˆãƒ¬ãƒ™ãƒ«**: è©³ç´°è¨­è¨ˆï¼ˆå®Ÿè£…å¯èƒ½ãƒ¬ãƒ™ãƒ«ï¼‰
* **æ›´æ–°é »åº¦**: å®Ÿè£…å¤‰æ›´ã«ä¼´ã„éšæ™‚æ›´æ–°
* **æœ€çµ‚æ›´æ–°**: {docdate}

**é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: <<backend-architecture>>, <<development-guide>>, <<database-schema>>
====

== ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“è¨­è¨ˆ

=== ğŸ¯ è¨­è¨ˆåŸå‰‡

[cols="2,3", options="header"]
|===
|è¨­è¨ˆåŸå‰‡ |è©³ç´°èª¬æ˜
|**å˜ä¸€è²¬ä»»åŸå‰‡** |å„ã‚¯ãƒ©ã‚¹ãƒ»ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯å˜ä¸€ã®è²¬ä»»ã®ã¿ã‚’æŒã¤
|**ä¾å­˜æ€§æ³¨å…¥** |è¨­å®šç®¡ç†ã€AIæœ€é©åŒ–ç­‰ã®ä¾å­˜é–¢ä¿‚ã¯æ³¨å…¥ã«ã‚ˆã‚Šç®¡ç†
|**ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‰åˆ†é›¢** |Webå±¤ã€Serviceå±¤ã€Coreå±¤ã®æ˜ç¢ºãªåˆ†é›¢
|**ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•** |WebSocketã«ã‚ˆã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çŠ¶æ…‹æ›´æ–°
|**ãƒ¡ãƒ¢ãƒªåŠ¹ç‡** |AIå‡¦ç†ã«ãŠã‘ã‚‹é©åˆ‡ãªãƒªã‚½ãƒ¼ã‚¹ç®¡ç†
|**ã‚¨ãƒ©ãƒ¼å‡¦ç†** |éšå±¤åŒ–ã•ã‚ŒãŸä¾‹å¤–å‡¦ç†ã¨è©³ç´°ãƒ­ã‚°å‡ºåŠ›
|===

=== ğŸ”„ å…¨ä½“ãƒ•ãƒ­ãƒ¼æ¦‚è¦

[mermaid]
....
graph TB
    subgraph "ğŸŒ Web Interface"
        WEB[Flask Web Server]
        WS[WebSocket Handler]
        API[REST API Endpoints]
    end
    
    subgraph "âš™ï¸ Service Layer"
        ALERT[Alert Manager]
        TTS[TTS Service]
        SCHEDULE[Schedule Manager]
        LLM[LLM Service]
        LINE[LINE Service]
    end
    
    subgraph "ğŸ§  Core AI Engine"
        MONITOR[Monitor]
        DETECTOR[Object Detector]
        FRAME_PROC[Frame Processor]
        AI_OPT[AI Optimizer]
        MEM_MGR[Memory Manager]
    end
    
    subgraph "ğŸ“¹ Input Layer"
        CAMERA[Camera Manager]
        STATE[State Manager]
    end
    
    subgraph "ğŸ’¾ Data Layer"
        REDIS[Redis Cache]
        CONFIG[Config Manager]
        LOGGER[Logger]
    end
    
    subgraph "ğŸ”Š Output Layer"
        SOUND[Sound Service]
        NOTIF[Notification]
        STREAM[Status Broadcast]
    end
    
    %% Web to Service connections
    WEB --> ALERT
    WEB --> SCHEDULE
    WS --> STREAM
    API --> TTS
    API --> LLM
    
    %% Service to Core connections
    ALERT --> MONITOR
    SCHEDULE --> MONITOR
    TTS --> SOUND
    LINE --> NOTIF
    
    %% Core processing flow
    CAMERA --> FRAME_PROC
    FRAME_PROC --> AI_OPT
    AI_OPT --> DETECTOR
    DETECTOR --> MONITOR
    MONITOR --> STATE
    
    %% Memory and optimization
    AI_OPT --> MEM_MGR
    DETECTOR --> MEM_MGR
    MEM_MGR --> REDIS
    
    %% Configuration and logging
    CONFIG --> MONITOR
    CONFIG --> DETECTOR
    LOGGER --> REDIS
    
    %% Output generation
    MONITOR --> STREAM
    MONITOR --> SOUND
    STATE --> STREAM
    
    classDef web fill:#e3f2fd
    classDef service fill:#e8f5e8
    classDef core fill:#fff3e0
    classDef input fill:#f3e5f5
    classDef data fill:#fce4ec
    classDef output fill:#e8eaf6
    
    class WEB,WS,API web
    class ALERT,TTS,SCHEDULE,LLM,LINE service
    class MONITOR,DETECTOR,FRAME_PROC,AI_OPT,MEM_MGR core
    class CAMERA,STATE input
    class REDIS,CONFIG,LOGGER data
    class SOUND,NOTIF,STREAM output
....

== ğŸ§  Coreå±¤è¨­è¨ˆ

=== ğŸ¯ Monitorã‚¯ãƒ©ã‚¹è¨­è¨ˆ

[mermaid]
....
classDiagram
    class Monitor {
        -config_manager: ConfigManager
        -object_detector: ObjectDetector
        -frame_processor: FrameProcessor
        -state_manager: StateManager
        -alert_manager: AlertManager
        -status_broadcaster: StatusBroadcaster
        -ai_optimizer: AIOptimizer
        -memory_manager: MemoryManager
        -logger: Logger
        
        +__init__(config_manager: ConfigManager)
        +start_monitoring(): void
        +stop_monitoring(): void
        +process_frame(frame: ndarray): DetectionResult
        +update_status(): void
        +handle_detection_result(result: DetectionResult): void
        +check_absence_alert(): void
        +check_smartphone_alert(): void
        -_initialize_components(): void
        -_setup_optimization(): void
        -_cleanup_resources(): void
    }
    
    class ObjectDetector {
        -yolo_model: YOLO
        -mediapipe_detector: MediaPipeDetector
        -ai_optimizer: AIOptimizer
        -confidence_threshold: float
        -device: str
        
        +__init__(config_manager: ConfigManager)
        +detect_objects(frame: ndarray): DetectionResult
        +detect_person(frame: ndarray): PersonDetection
        +detect_smartphone(frame: ndarray): SmartphoneDetection
        +initialize_models(): void
        +cleanup_models(): void
        -_optimize_inference(frame: ndarray): ndarray
        -_merge_detections(yolo_result, mp_result): DetectionResult
    }
    
    class AIOptimizer {
        -frame_skipper: FrameSkipper
        -batch_processor: BatchProcessor
        -gpu_manager: GPUManager
        -performance_monitor: PerformanceMonitor
        
        +optimize_yolo_inference(model, frame): Optional[Any]
        +optimize_mediapipe_inference(detector, frame): Optional[Any]
        +should_skip_frame(): bool
        +get_optimal_batch_size(): int
        +optimize_gpu_memory(): void
        +get_performance_stats(): dict
    }
    
    class MemoryManager {
        -frame_cache: LRUCache
        -model_cache: LRUCache
        -gc_threshold: int
        -max_memory_usage: float
        
        +cache_frame(key: str, frame: ndarray): void
        +get_cached_frame(key: str): Optional[ndarray]
        +cache_detection_result(key: str, result: DetectionResult): void
        +cleanup_cache(): void
        +monitor_memory_usage(): float
        +trigger_gc_if_needed(): void
    }
    
    Monitor --> ObjectDetector
    Monitor --> AIOptimizer
    Monitor --> MemoryManager
    ObjectDetector --> AIOptimizer
    ObjectDetector --> MemoryManager
    AIOptimizer --> MemoryManager
....

=== ğŸ” æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹å›³

[mermaid]
....
classDiagram
    class DetectionResult {
        +person_detected: bool
        +smartphone_detected: bool
        +person_confidence: float
        +smartphone_confidence: float
        +person_bbox: tuple
        +smartphone_bbox: tuple
        +processing_time: float
        +timestamp: datetime
        +frame_id: str
        
        +to_dict(): dict
        +is_valid(): bool
        +merge(other: DetectionResult): DetectionResult
    }
    
    class YOLODetector {
        -model: YOLO
        -device: str
        -confidence_threshold: float
        -iou_threshold: float
        
        +__init__(model_path: str, device: str)
        +detect(frame: ndarray): YOLOResult
        +preprocess_frame(frame: ndarray): ndarray
        +postprocess_results(results): List[Detection]
        +optimize_for_inference(): void
    }
    
    class MediaPipeDetector {
        -pose_detector: PoseDetector
        -hand_detector: HandDetector
        -model_complexity: int
        -min_detection_confidence: float
        
        +__init__(config: dict)
        +detect_pose(frame: ndarray): PoseResult
        +detect_hands(frame: ndarray): HandResult
        +infer_smartphone_usage(pose, hands): bool
        +calculate_confidence(detections): float
    }
    
    class FrameProcessor {
        -input_size: tuple
        -color_space: str
        -preprocessing_pipeline: List[Callable]
        
        +preprocess(frame: ndarray): ndarray
        +resize_frame(frame: ndarray, target_size: tuple): ndarray
        +normalize_frame(frame: ndarray): ndarray
        +apply_filters(frame: ndarray): ndarray
        +validate_frame(frame: ndarray): bool
    }
    
    ObjectDetector --> YOLODetector
    ObjectDetector --> MediaPipeDetector
    ObjectDetector --> FrameProcessor
    YOLODetector --> DetectionResult
    MediaPipeDetector --> DetectionResult
    FrameProcessor --> DetectionResult
....

== ğŸŒ Serviceå±¤è¨­è¨ˆ

=== ğŸ“¢ Alertãƒ»é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ 

[mermaid]
....
classDiagram
    class AlertManager {
        -alert_config: dict
        -active_alerts: List[Alert]
        -sound_service: SoundService
        -tts_service: TTSService
        -line_service: LineService
        -logger: Logger
        
        +__init__(config_manager: ConfigManager)
        +trigger_alert(alert_type: AlertType, context: dict): void
        +clear_alert(alert_id: str): void
        +get_active_alerts(): List[Alert]
        +schedule_alert(alert: Alert, delay: int): void
        -_create_alert(alert_type: AlertType): Alert
        -_play_alert_sound(alert: Alert): void
        -_send_notifications(alert: Alert): void
    }
    
    class Alert {
        +id: str
        +type: AlertType
        +message: str
        +severity: int
        +timestamp: datetime
        +context: dict
        +is_active: bool
        
        +to_dict(): dict
        +should_repeat(): bool
        +get_notification_channels(): List[str]
    }
    
    class TTSService {
        -engine: ZonosTTS
        -voice_config: dict
        -audio_queue: Queue
        -emotion_manager: EmotionManager
        
        +__init__(config: dict)
        +synthesize_speech(text: str, emotion: str): AudioData
        +play_tts_alert(message: str): void
        +set_voice_parameters(params: dict): void
        +get_available_voices(): List[str]
        -_process_audio_queue(): void
    }
    
    class SoundService {
        -audio_device: AudioDevice
        -sound_cache: dict
        -volume_level: float
        
        +play_sound(sound_file: str): void
        +play_tts_audio(audio_data: AudioData): void
        +set_volume(level: float): void
        +stop_all_sounds(): void
        +load_sound_files(): void
    }
    
    class LineService {
        -line_token: str
        -api_client: LineAPIClient
        -message_queue: Queue
        
        +send_message(message: str): bool
        +send_status_update(status: dict): bool
        +validate_token(): bool
        +get_quota_status(): dict
    }
    
    AlertManager --> Alert
    AlertManager --> TTSService
    AlertManager --> SoundService
    AlertManager --> LineService
    TTSService --> SoundService
....

=== ğŸ“Š Scheduleãƒ»çŠ¶æ…‹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

[mermaid]
....
classDiagram
    class ScheduleManager {
        -schedules: List[Schedule]
        -schedule_checker: ScheduleChecker
        -timezone: str
        -config_manager: ConfigManager
        
        +__init__(config_manager: ConfigManager)
        +load_schedules(): void
        +add_schedule(schedule: Schedule): void
        +remove_schedule(schedule_id: str): void
        +check_current_schedule(): Optional[Schedule]
        +get_next_schedule(): Optional[Schedule]
        +is_monitoring_time(): bool
    }
    
    class Schedule {
        +id: str
        +name: str
        +start_time: time
        +end_time: time
        +days_of_week: List[int]
        +alert_enabled: bool
        +monitoring_enabled: bool
        +created_at: datetime
        +updated_at: datetime
        
        +is_active_now(): bool
        +is_active_on_day(day: int): bool
        +get_next_occurrence(): datetime
        +to_dict(): dict
    }
    
    class StateManager {
        -current_state: MonitoringState
        -state_history: List[StateTransition]
        -absence_start_time: Optional[datetime]
        -smartphone_start_time: Optional[datetime]
        -max_history_size: int
        
        +update_state(detection_result: DetectionResult): void
        +get_current_state(): MonitoringState
        +get_absence_duration(): int
        +get_smartphone_usage_duration(): int
        +reset_timers(): void
        +get_state_history(): List[StateTransition]
        -_transition_state(new_state: MonitoringState): void
        -_record_transition(transition: StateTransition): void
    }
    
    class MonitoringState {
        <<enumeration>>
        PRESENT
        ABSENT
        SMARTPHONE_DETECTED
        UNKNOWN
    }
    
    class StateTransition {
        +from_state: MonitoringState
        +to_state: MonitoringState
        +timestamp: datetime
        +trigger: str
        +confidence: float
        
        +to_dict(): dict
    }
    
    ScheduleManager --> Schedule
    StateManager --> MonitoringState
    StateManager --> StateTransition
....

== ğŸŒ Webå±¤è¨­è¨ˆ

=== ğŸ”— REST APIè¨­è¨ˆ

[mermaid]
....
classDiagram
    class FlaskApp {
        -app: Flask
        -socketio: SocketIO
        -monitor: Monitor
        -config_manager: ConfigManager
        
        +create_app(): Flask
        +register_blueprints(): void
        +setup_error_handlers(): void
        +setup_middleware(): void
        +run(): void
    }
    
    class APIRoutes {
        +register_routes(app: Flask): void
        +health_check(): Response
        +get_status(): Response
        +get_detection_history(): Response
        +update_config(): Response
        +trigger_manual_alert(): Response
        +get_schedules(): Response
        +create_schedule(): Response
    }
    
    class TTSRoutes {
        +synthesis_text(): Response
        +get_voices(): Response
        +upload_voice_sample(): Response
        +clone_voice(): Response
        +stream_audio(): Response
        +get_synthesis_history(): Response
    }
    
    class WebSocketHandler {
        -socketio: SocketIO
        -status_broadcaster: StatusBroadcaster
        -connected_clients: Set[str]
        
        +handle_connect(): void
        +handle_disconnect(): void
        +broadcast_status(status: dict): void
        +broadcast_alert(alert: Alert): void
        +handle_client_message(data: dict): void
        -_authenticate_client(token: str): bool
    }
    
    class StatusBroadcaster {
        -websocket_handler: WebSocketHandler
        -broadcast_interval: int
        -last_status: dict
        
        +start_broadcasting(): void
        +stop_broadcasting(): void
        +broadcast_detection_status(status: dict): void
        +broadcast_performance_stats(stats: dict): void
        -_should_broadcast(new_status: dict): bool
    }
    
    FlaskApp --> APIRoutes
    FlaskApp --> TTSRoutes
    FlaskApp --> WebSocketHandler
    WebSocketHandler --> StatusBroadcaster
....

=== ğŸ“¡ WebSocketé€šä¿¡ãƒ•ãƒ­ãƒ¼

[mermaid]
....
sequenceDiagram
    participant C as Client
    participant WS as WebSocket Handler
    participant SB as Status Broadcaster
    participant M as Monitor
    participant D as Object Detector
    participant S as State Manager
    
    C->>WS: connect()
    WS->>C: connection_established
    
    loop Real-time monitoring
        M->>D: process_frame()
        D->>M: detection_result
        M->>S: update_state(result)
        S->>M: state_changed
        M->>SB: broadcast_status(status)
        SB->>WS: new_status_available
        WS->>C: status_update (WebSocket)
    end
    
    alt Alert triggered
        M->>SB: broadcast_alert(alert)
        SB->>WS: alert_triggered
        WS->>C: alert_notification
    end
    
    C->>WS: manual_alert_request
    WS->>M: trigger_manual_alert()
    M->>WS: alert_triggered
    WS->>C: alert_confirmation
    
    C->>WS: disconnect()
    WS->>SB: client_disconnected
....

== ğŸ’¾ ãƒ‡ãƒ¼ã‚¿å±¤è¨­è¨ˆ

=== ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆ

[mermaid]
....
erDiagram
    DETECTION_LOG {
        string id PK
        datetime timestamp
        boolean person_detected
        boolean smartphone_detected
        float person_confidence
        float smartphone_confidence
        json person_bbox
        json smartphone_bbox
        float processing_time
        string frame_id
        json metadata
    }
    
    BEHAVIOR_LOG {
        string id PK
        datetime timestamp
        string state
        int duration_seconds
        string trigger
        float confidence
        json context
        string session_id
    }
    
    ALERT_LOG {
        string id PK
        datetime timestamp
        string alert_type
        string message
        int severity
        boolean is_resolved
        datetime resolved_at
        json context
        string triggered_by
    }
    
    SCHEDULE {
        string id PK
        string name
        time start_time
        time end_time
        json days_of_week
        boolean alert_enabled
        boolean monitoring_enabled
        datetime created_at
        datetime updated_at
        json metadata
    }
    
    PERFORMANCE_LOG {
        string id PK
        datetime timestamp
        float fps
        float cpu_usage
        float memory_usage
        float gpu_usage
        int cache_hits
        int cache_misses
        json system_info
    }
    
    TTS_SYNTHESIS_LOG {
        string id PK
        datetime timestamp
        string text
        string voice_id
        string emotion
        float synthesis_time
        int audio_duration_ms
        string file_path
        json parameters
    }
    
    USER_SESSION {
        string session_id PK
        datetime start_time
        datetime end_time
        int total_detections
        int absence_count
        int smartphone_usage_count
        json summary_stats
    }
    
    DETECTION_LOG ||--o{ BEHAVIOR_LOG : triggers
    BEHAVIOR_LOG ||--o{ ALERT_LOG : generates
    SCHEDULE ||--o{ ALERT_LOG : scheduled_by
    USER_SESSION ||--o{ DETECTION_LOG : contains
    USER_SESSION ||--o{ BEHAVIOR_LOG : includes
....

=== ğŸ—„ï¸ Redisã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­è¨ˆ

```python
# Redis Schema Design
CACHE_SCHEMAS = {
    # Session data
    'session:{session_id}': {
        'ttl': 86400,  # 24 hours
        'data': {
            'user_id': str,
            'start_time': datetime,
            'current_state': str,
            'detection_count': int
        }
    },
    
    # Frame cache (short-term)
    'frame:{frame_id}': {
        'ttl': 300,  # 5 minutes
        'data': {
            'frame_data': bytes,
            'timestamp': datetime,
            'preprocessing_done': bool
        }
    },
    
    # Detection results cache
    'detection:{frame_id}': {
        'ttl': 3600,  # 1 hour
        'data': {
            'result': dict,
            'confidence': float,
            'processing_time': float
        }
    },
    
    # Configuration cache
    'config:current': {
        'ttl': -1,  # Persistent
        'data': {
            'ai_config': dict,
            'alert_config': dict,
            'schedule_config': dict
        }
    },
    
    # Performance metrics
    'metrics:current': {
        'ttl': 60,  # 1 minute
        'data': {
            'fps': float,
            'cpu_usage': float,
            'memory_usage': float,
            'gpu_usage': float
        }
    }
}
```

== ğŸ”„ ãƒ—ãƒ­ã‚»ã‚¹ãƒ•ãƒ­ãƒ¼è¨­è¨ˆ

=== ğŸ¯ ãƒ¡ã‚¤ãƒ³ç›£è¦–ãƒ«ãƒ¼ãƒ—

[mermaid]
....
flowchart TD
    START([ç›£è¦–é–‹å§‹])
    
    INIT[ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–]
    LOAD_CONFIG[è¨­å®šèª­ã¿è¾¼ã¿]
    INIT_AI[AIãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–]
    START_CAMERA[ã‚«ãƒ¡ãƒ©èµ·å‹•]
    
    LOOP_START{ç›£è¦–ãƒ«ãƒ¼ãƒ—é–‹å§‹}
    CAPTURE[ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—]
    
    FRAME_CHECK{ãƒ•ãƒ¬ãƒ¼ãƒ æœ‰åŠ¹?}
    SKIP_CHECK{ã‚¹ã‚­ãƒƒãƒ—åˆ¤å®š}
    
    PREPROCESS[å‰å‡¦ç†å®Ÿè¡Œ]
    AI_DETECT[AIæ¤œå‡ºå®Ÿè¡Œ]
    POST_PROCESS[å¾Œå‡¦ç†ãƒ»çµæœçµ±åˆ]
    
    STATE_UPDATE[çŠ¶æ…‹æ›´æ–°]
    ALERT_CHECK{ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶?}
    TRIGGER_ALERT[ã‚¢ãƒ©ãƒ¼ãƒˆç™ºå‹•]
    
    BROADCAST[çŠ¶æ…‹é…ä¿¡]
    CACHE_UPDATE[ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°]
    
    SCHEDULE_CHECK{ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç¢ºèª}
    PERFORMANCE[ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–]
    
    MEMORY_CHECK{ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç¢ºèª}
    CLEANUP[ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—]
    
    CONTINUE{ç¶™ç¶š?}
    STOP_MONITOR[ç›£è¦–åœæ­¢]
    CLEANUP_FINAL[æœ€çµ‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—]
    END([çµ‚äº†])
    
    START --> INIT
    INIT --> LOAD_CONFIG
    LOAD_CONFIG --> INIT_AI
    INIT_AI --> START_CAMERA
    START_CAMERA --> LOOP_START
    
    LOOP_START --> CAPTURE
    CAPTURE --> FRAME_CHECK
    
    FRAME_CHECK -->|æœ‰åŠ¹| SKIP_CHECK
    FRAME_CHECK -->|ç„¡åŠ¹| LOOP_START
    
    SKIP_CHECK -->|å‡¦ç†| PREPROCESS
    SKIP_CHECK -->|ã‚¹ã‚­ãƒƒãƒ—| STATE_UPDATE
    
    PREPROCESS --> AI_DETECT
    AI_DETECT --> POST_PROCESS
    POST_PROCESS --> STATE_UPDATE
    
    STATE_UPDATE --> ALERT_CHECK
    ALERT_CHECK -->|æ¡ä»¶æº€ãŸã™| TRIGGER_ALERT
    ALERT_CHECK -->|æ¡ä»¶æº€ãŸã•ãªã„| BROADCAST
    TRIGGER_ALERT --> BROADCAST
    
    BROADCAST --> CACHE_UPDATE
    CACHE_UPDATE --> SCHEDULE_CHECK
    SCHEDULE_CHECK --> PERFORMANCE
    PERFORMANCE --> MEMORY_CHECK
    
    MEMORY_CHECK -->|æ­£å¸¸| CONTINUE
    MEMORY_CHECK -->|é–¾å€¤è¶…é| CLEANUP
    CLEANUP --> CONTINUE
    
    CONTINUE -->|ç¶™ç¶š| LOOP_START
    CONTINUE -->|åœæ­¢| STOP_MONITOR
    
    STOP_MONITOR --> CLEANUP_FINAL
    CLEANUP_FINAL --> END
    
    classDef startEnd fill:#e8f5e8
    classDef process fill:#e3f2fd
    classDef decision fill:#fff3e0
    classDef alert fill:#ffebee
    
    class START,END startEnd
    class INIT,LOAD_CONFIG,INIT_AI,PREPROCESS,AI_DETECT,POST_PROCESS process
    class FRAME_CHECK,SKIP_CHECK,ALERT_CHECK,MEMORY_CHECK,CONTINUE decision
    class TRIGGER_ALERT alert
....

=== ğŸ§  AIæ¨è«–æœ€é©åŒ–ãƒ•ãƒ­ãƒ¼

[mermaid]
....
flowchart TD
    FRAME_INPUT[å…¥åŠ›ãƒ•ãƒ¬ãƒ¼ãƒ ]
    
    AI_OPT_START[AIæœ€é©åŒ–é–‹å§‹]
    PERF_CHECK[ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç¢ºèª]
    
    FRAME_SKIP_DECISION{ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—åˆ¤å®š}
    FRAME_SKIP[ã‚¹ã‚­ãƒƒãƒ—å®Ÿè¡Œ]
    
    GPU_CHECK{GPUåˆ©ç”¨å¯èƒ½?}
    GPU_OPTIMIZE[GPUæœ€é©åŒ–]
    CPU_FALLBACK[CPU ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯]
    
    BATCH_CHECK{ãƒãƒƒãƒå‡¦ç†å¯èƒ½?}
    BATCH_PROCESS[ãƒãƒƒãƒæ¨è«–]
    SINGLE_PROCESS[å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ æ¨è«–]
    
    YOLO_INFERENCE[YOLOæ¨è«–]
    MP_INFERENCE[MediaPipeæ¨è«–]
    
    RESULT_MERGE[çµæœçµ±åˆ]
    CONFIDENCE_CHECK{ä¿¡é ¼åº¦ç¢ºèª}
    
    CACHE_STORE[çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥]
    PERFORMANCE_LOG[ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ­ã‚°]
    
    MEMORY_MONITOR[ãƒ¡ãƒ¢ãƒªç›£è¦–]
    GC_TRIGGER{GCå®Ÿè¡Œåˆ¤å®š}
    MEMORY_CLEANUP[ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—]
    
    RESULT_OUTPUT[æ¨è«–çµæœå‡ºåŠ›]
    
    FRAME_INPUT --> AI_OPT_START
    AI_OPT_START --> PERF_CHECK
    PERF_CHECK --> FRAME_SKIP_DECISION
    
    FRAME_SKIP_DECISION -->|ã‚¹ã‚­ãƒƒãƒ—| FRAME_SKIP
    FRAME_SKIP_DECISION -->|å‡¦ç†| GPU_CHECK
    FRAME_SKIP --> RESULT_OUTPUT
    
    GPU_CHECK -->|åˆ©ç”¨å¯èƒ½| GPU_OPTIMIZE
    GPU_CHECK -->|åˆ©ç”¨ä¸å¯| CPU_FALLBACK
    
    GPU_OPTIMIZE --> BATCH_CHECK
    CPU_FALLBACK --> BATCH_CHECK
    
    BATCH_CHECK -->|å¯èƒ½| BATCH_PROCESS
    BATCH_CHECK -->|ä¸å¯| SINGLE_PROCESS
    
    BATCH_PROCESS --> YOLO_INFERENCE
    SINGLE_PROCESS --> YOLO_INFERENCE
    
    YOLO_INFERENCE --> MP_INFERENCE
    MP_INFERENCE --> RESULT_MERGE
    
    RESULT_MERGE --> CONFIDENCE_CHECK
    CONFIDENCE_CHECK --> CACHE_STORE
    CACHE_STORE --> PERFORMANCE_LOG
    
    PERFORMANCE_LOG --> MEMORY_MONITOR
    MEMORY_MONITOR --> GC_TRIGGER
    
    GC_TRIGGER -->|å®Ÿè¡Œ| MEMORY_CLEANUP
    GC_TRIGGER -->|ä¸è¦| RESULT_OUTPUT
    MEMORY_CLEANUP --> RESULT_OUTPUT
    
    classDef input fill:#e8f5e8
    classDef optimization fill:#e3f2fd
    classDef inference fill:#fff3e0
    classDef decision fill:#f3e5f5
    classDef output fill:#fce4ec
    
    class FRAME_INPUT input
    class AI_OPT_START,GPU_OPTIMIZE,CPU_FALLBACK,BATCH_PROCESS optimization
    class YOLO_INFERENCE,MP_INFERENCE,RESULT_MERGE inference
    class FRAME_SKIP_DECISION,GPU_CHECK,BATCH_CHECK,CONFIDENCE_CHECK,GC_TRIGGER decision
    class RESULT_OUTPUT,CACHE_STORE,PERFORMANCE_LOG output
....

== ğŸ”§ ä¾‹å¤–å‡¦ç†ãƒ»ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°è¨­è¨ˆ

=== ğŸ“‹ ä¾‹å¤–éšå±¤æ§‹é€ 

[mermaid]
....
classDiagram
    class KanshiChanError {
        +error_code: str
        +message: str
        +details: dict
        +timestamp: datetime
        
        +to_dict(): dict
        +to_response(): Response
    }
    
    class AIModelError {
        +model_type: str
        +model_path: str
    }
    
    class InferenceError {
        +frame_id: str
        +inference_time: float
    }
    
    class OptimizationError {
        +optimization_type: str
        +performance_impact: str
    }
    
    class CameraError {
        +device_id: int
        +device_status: str
    }
    
    class ConfigurationError {
        +config_key: str
        +expected_type: type
        +actual_value: Any
    }
    
    class AlertError {
        +alert_type: str
        +notification_channels: List[str]
    }
    
    class TTSError {
        +voice_id: str
        +text_length: int
        +synthesis_time: float
    }
    
    KanshiChanError <|-- AIModelError
    KanshiChanError <|-- CameraError
    KanshiChanError <|-- ConfigurationError
    KanshiChanError <|-- AlertError
    
    AIModelError <|-- InferenceError
    AIModelError <|-- OptimizationError
    AlertError <|-- TTSError
....

=== ğŸ”„ ã‚¨ãƒ©ãƒ¼å‡¦ç†ãƒ•ãƒ­ãƒ¼

```python
# Exception handling pattern
from utils.exceptions import wrap_exception, create_error_response

class ObjectDetector:
    def detect_objects(self, frame: np.ndarray) -> Dict[str, Any]:
        try:
            # AIæ¨è«–å®Ÿè¡Œ
            results = self._run_inference(frame)
            return self._process_results(results)
            
        except torch.cuda.OutOfMemoryError as e:
            # GPU ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å ´åˆ
            optimization_error = wrap_exception(
                e, OptimizationError,
                "GPU memory insufficient, falling back to CPU",
                error_code="OPT_001",
                details={
                    'gpu_memory_used': torch.cuda.memory_allocated(),
                    'fallback_action': 'switch_to_cpu'
                }
            )
            logger.warning(f"GPU memory issue: {optimization_error.to_dict()}")
            
            # CPU ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self._run_cpu_inference(frame)
            
        except cv2.error as e:
            # OpenCV ã‚¨ãƒ©ãƒ¼
            inference_error = wrap_exception(
                e, InferenceError,
                "Frame processing failed",
                error_code="INF_002",
                details={
                    'frame_shape': frame.shape if frame is not None else None,
                    'frame_dtype': str(frame.dtype) if frame is not None else None
                }
            )
            logger.error(f"OpenCV error: {inference_error.to_dict()}")
            raise inference_error
            
        except Exception as e:
            # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼
            model_error = wrap_exception(
                e, AIModelError,
                "Unexpected error during object detection",
                error_code="AI_999",
                details={'unexpected_error': True}
            )
            logger.error(f"Unexpected detection error: {model_error.to_dict()}", exc_info=True)
            raise model_error
```

== âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–è¨­è¨ˆ

=== ğŸ“Š ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

[mermaid]
....
classDiagram
    class MemoryManager {
        -frame_cache: LRUCache[str, ndarray]
        -result_cache: LRUCache[str, DetectionResult]
        -model_cache: LRUCache[str, Any]
        -gc_threshold: float
        -max_memory_usage: float
        -memory_monitor: MemoryMonitor
        
        +cache_frame(key: str, frame: ndarray): void
        +get_cached_frame(key: str): Optional[ndarray]
        +cache_detection_result(key: str, result: DetectionResult): void
        +get_cached_result(key: str): Optional[DetectionResult]
        +cleanup_expired_cache(): void
        +force_garbage_collection(): void
        +get_memory_stats(): dict
        -_should_trigger_gc(): bool
        -_calculate_cache_efficiency(): float
    }
    
    class LRUCache {
        -max_size: int
        -current_size: int
        -cache_dict: dict
        -access_order: deque
        
        +get(key: str): Optional[Any]
        +put(key: str, value: Any): void
        +remove(key: str): bool
        +clear(): void
        +get_stats(): CacheStats
        -_evict_lru(): void
    }
    
    class MemoryMonitor {
        -process: psutil.Process
        -gpu_monitor: GPUMonitor
        -thresholds: dict
        
        +get_system_memory(): float
        +get_process_memory(): float
        +get_gpu_memory(): float
        +is_memory_critical(): bool
        +get_memory_breakdown(): dict
    }
    
    class CacheStats {
        +hits: int
        +misses: int
        +evictions: int
        +hit_rate: float
        +memory_usage: int
        
        +to_dict(): dict
    }
    
    MemoryManager --> LRUCache
    MemoryManager --> MemoryMonitor
    LRUCache --> CacheStats
....

=== âš¡ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æœ€é©åŒ–

```python
class FrameSkipper:
    def __init__(self, config_manager: ConfigManager):
        self.config = config_manager.get_ai_config()
        self.performance_monitor = PerformanceMonitor()
        self.skip_count = 0
        self.total_frames = 0
        
    def should_skip_frame(self) -> bool:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯"""
        current_fps = self.performance_monitor.get_current_fps()
        target_fps = self.config.get('target_fps', 15.0)
        
        # CPU/GPUä½¿ç”¨ç‡ã«åŸºã¥ãå‹•çš„èª¿æ•´
        cpu_usage = self.performance_monitor.get_cpu_usage()
        gpu_usage = self.performance_monitor.get_gpu_usage()
        
        # ã‚¢ãƒ€ãƒ—ãƒ†ã‚£ãƒ–ã‚¹ã‚­ãƒƒãƒ—æˆ¦ç•¥
        if current_fps < target_fps * 0.8:  # FPS ãŒç›®æ¨™ã®80%ä»¥ä¸‹
            if cpu_usage > 80 or gpu_usage > 85:
                skip_probability = min(0.5, (cpu_usage - 60) / 40)
                return random.random() < skip_probability
                
        return False
        
    def get_skip_stats(self) -> dict:
        """ã‚¹ã‚­ãƒƒãƒ—çµ±è¨ˆã®å–å¾—"""
        return {
            'skip_rate': self.skip_count / max(self.total_frames, 1),
            'total_frames': self.total_frames,
            'skipped_frames': self.skip_count,
            'performance_impact': self._calculate_performance_impact()
        }
```

== ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­è¨ˆ

=== ğŸ›¡ï¸ èªè¨¼ãƒ»èªå¯ã‚·ã‚¹ãƒ†ãƒ 

[mermaid]
....
sequenceDiagram
    participant C as Client
    participant AUTH as Auth Middleware
    participant JWT as JWT Handler
    participant API as API Endpoint
    participant RBAC as RBAC Manager
    
    C->>AUTH: Request with Token
    AUTH->>JWT: Validate Token
    
    alt Token Valid
        JWT->>AUTH: Token Claims
        AUTH->>RBAC: Check Permissions
        
        alt Has Permission
            RBAC->>AUTH: Access Granted
            AUTH->>API: Forward Request
            API->>AUTH: Response
            AUTH->>C: Authorized Response
        else No Permission
            RBAC->>AUTH: Access Denied
            AUTH->>C: 403 Forbidden
        end
        
    else Token Invalid
        JWT->>AUTH: Invalid Token
        AUTH->>C: 401 Unauthorized
    end
....

=== ğŸ” ãƒ‡ãƒ¼ã‚¿æš—å·åŒ–ãƒ»ä¿è­·

```python
class SecurityManager:
    def __init__(self, config_manager: ConfigManager):
        self.config = config_manager.get_security_config()
        self.fernet = self._initialize_encryption()
        
    def encrypt_sensitive_data(self, data: dict) -> str:
        """æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®æš—å·åŒ–"""
        json_data = json.dumps(data)
        encrypted = self.fernet.encrypt(json_data.encode())
        return base64.b64encode(encrypted).decode()
        
    def decrypt_sensitive_data(self, encrypted_data: str) -> dict:
        """æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®å¾©å·åŒ–"""
        encrypted_bytes = base64.b64decode(encrypted_data.encode())
        decrypted = self.fernet.decrypt(encrypted_bytes)
        return json.loads(decrypted.decode())
        
    def hash_password(self, password: str) -> str:
        """ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒã‚·ãƒ¥åŒ–"""
        salt = bcrypt.gensalt()
        return bcrypt.hashpw(password.encode(), salt).decode()
        
    def verify_password(self, password: str, hashed: str) -> bool:
        """ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰æ¤œè¨¼"""
        return bcrypt.checkpw(password.encode(), hashed.encode())
```

== ğŸ“Š ç›£è¦–ãƒ»ãƒ­ã‚°è¨­è¨ˆ

=== ğŸ“ˆ æ§‹é€ åŒ–ãƒ­ã‚°è¨­è¨ˆ

```python
# Structured logging configuration
LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'json': {
            'class': 'pythonjsonlogger.jsonlogger.JsonFormatter',
            'format': '%(asctime)s %(name)s %(levelname)s %(message)s'
        }
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'formatter': 'json',
            'level': 'INFO'
        },
        'file': {
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': 'logs/kanshichan.log',
            'formatter': 'json',
            'maxBytes': 104857600,  # 100MB
            'backupCount': 10
        }
    },
    'loggers': {
        'kanshichan': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
            'propagate': False
        }
    }
}

# Structured logging example
logger.info("AI processing completed", extra={
    'event': 'ai_processing',
    'processing_time': 0.045,
    'fps': 28.5,
    'objects_detected': 2,
    'model_type': 'yolov8n',
    'device': 'cuda:0',
    'memory_usage': 2.1,
    'confidence_scores': [0.87, 0.92]
})
```

== ğŸ”— é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

=== ğŸ“– å¿…é ˆå‚ç…§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
* **<<backend-architecture>>**: ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
* **<<database-schema>>**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆè©³ç´°
* **<<development-guide>>**: é–‹ç™ºæ‰‹é †ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
* **<<testing-strategy>>**: ãƒ†ã‚¹ãƒˆè¨­è¨ˆã¨å“è³ªä¿è¨¼

=== ğŸ› ï¸ é–‹ç™ºè€…å‘ã‘ãƒªã‚½ãƒ¼ã‚¹
* **<<ai-ml-specifications>>**: AI/MLæŠ€è¡“è©³ç´°ä»•æ§˜
* **<<rest-api-reference>>**: REST APIä»•æ§˜
* **<<websocket-api>>**: WebSocket APIä»•æ§˜
* **<<performance-optimization>>**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æ‰‹æ³•

=== ğŸ“Š é‹ç”¨ãƒ»ä¿å®ˆé–¢é€£
* **<<configuration-guide>>**: è¨­å®šç®¡ç†è©³ç´°
* **<<operations-monitoring>>**: é‹ç”¨ç›£è¦–æ‰‹é †
* **<<troubleshooting-guide>>**: ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
* **<<security-specifications>>**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è©³ç´°ä»•æ§˜

[NOTE]
====
ğŸ”„ **è¨­è¨ˆã®é€²åŒ–**

æœ¬è¨­è¨ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯å®Ÿè£…ã®é€²è¡Œã¨é‹ç”¨å®Ÿç¸¾ã«åŸºã¥ã„ã¦
ç¶™ç¶šçš„ã«æ›´æ–°ãƒ»æ”¹å–„ã•ã‚Œã¾ã™ã€‚

**å¤‰æ›´ç®¡ç†**: Git commit history ã§è¨­è¨ˆå¤‰æ›´ã‚’è¿½è·¡ +
**ãƒ¬ãƒ“ãƒ¥ãƒ¼**: å››åŠæœŸã”ã¨ã®è¨­è¨ˆãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿæ–½ +
**ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**: team@kanshichan.dev

**é‡è¦**: å®Ÿè£…æ™‚ã¯æœ€æ–°ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å‚ç…§ã—ã¦ãã ã•ã„
====

---

**ğŸ“ Contact**: team@kanshichan.dev +
**ğŸ”— Repository**: https://github.com/kanshichan/backend +
**ğŸ“… Last Updated**: {docdate} +
**ğŸ“ Document Version**: {revnumber} 