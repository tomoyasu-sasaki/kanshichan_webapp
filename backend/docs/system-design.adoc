=  🔧 監視ちゃん(KanshiChan) システム設計詳細
:toc: left
:toc-title: 目次
:toclevels: 4
:numbered:
:source-highlighter: highlight.js
:icons: font
:doctype: book
:version: 1.0.0
:author: KanshiChan Development Team
:email: team@kanshichan.dev
:revnumber: 1.0
:revdate: {docdate}
:experimental:

== 📖 概要

監視ちゃん（KanshiChan）バックエンドシステムの詳細設計ドキュメントです。
システムアーキテクチャの具体的な実装設計、クラス構造、シーケンス図、データベース設計等を包括的に説明します。

[NOTE]
====
📋 **ドキュメント情報**

* **対象読者**: 開発者、設計者、技術リード、新規参加開発者
* **前提知識**: Python/Flask、React/TypeScript、AI/ML基礎、システム設計
* **設計レベル**: 詳細設計（実装可能レベル）
* **更新頻度**: 実装変更に伴い随時更新
* **最終更新**: {docdate}

**関連ドキュメント**: <<backend-architecture>>, <<development-guide>>, <<database-schema>>
====

== 🏗️ システム全体設計

=== 🎯 設計原則

[cols="2,3", options="header"]
|===
|設計原則 |詳細説明
|**単一責任原則** |各クラス・モジュールは単一の責任のみを持つ
|**依存性注入** |設定管理、AI最適化等の依存関係は注入により管理
|**レイヤード分離** |Web層、Service層、Core層の明確な分離
|**イベント駆動** |WebSocketによるリアルタイム状態更新
|**メモリ効率** |AI処理における適切なリソース管理
|**エラー処理** |階層化された例外処理と詳細ログ出力
|===

=== 🔄 全体フロー概要

[mermaid]
....
graph TB
    subgraph "🌐 Web Interface"
        WEB[Flask Web Server]
        WS[WebSocket Handler]
        API[REST API Endpoints]
    end
    
    subgraph "⚙️ Service Layer"
        ALERT[Alert Manager]
        TTS[TTS Service]
        SCHEDULE[Schedule Manager]
        LLM[LLM Service]
        LINE[LINE Service]
    end
    
    subgraph "🧠 Core AI Engine"
        MONITOR[Monitor]
        DETECTOR[Object Detector]
        FRAME_PROC[Frame Processor]
        AI_OPT[AI Optimizer]
        MEM_MGR[Memory Manager]
    end
    
    subgraph "📹 Input Layer"
        CAMERA[Camera Manager]
        STATE[State Manager]
    end
    
    subgraph "💾 Data Layer"
        REDIS[Redis Cache]
        CONFIG[Config Manager]
        LOGGER[Logger]
    end
    
    subgraph "🔊 Output Layer"
        SOUND[Sound Service]
        NOTIF[Notification]
        STREAM[Status Broadcast]
    end
    
    %% Web to Service connections
    WEB --> ALERT
    WEB --> SCHEDULE
    WS --> STREAM
    API --> TTS
    API --> LLM
    
    %% Service to Core connections
    ALERT --> MONITOR
    SCHEDULE --> MONITOR
    TTS --> SOUND
    LINE --> NOTIF
    
    %% Core processing flow
    CAMERA --> FRAME_PROC
    FRAME_PROC --> AI_OPT
    AI_OPT --> DETECTOR
    DETECTOR --> MONITOR
    MONITOR --> STATE
    
    %% Memory and optimization
    AI_OPT --> MEM_MGR
    DETECTOR --> MEM_MGR
    MEM_MGR --> REDIS
    
    %% Configuration and logging
    CONFIG --> MONITOR
    CONFIG --> DETECTOR
    LOGGER --> REDIS
    
    %% Output generation
    MONITOR --> STREAM
    MONITOR --> SOUND
    STATE --> STREAM
    
    classDef web fill:#e3f2fd
    classDef service fill:#e8f5e8
    classDef core fill:#fff3e0
    classDef input fill:#f3e5f5
    classDef data fill:#fce4ec
    classDef output fill:#e8eaf6
    
    class WEB,WS,API web
    class ALERT,TTS,SCHEDULE,LLM,LINE service
    class MONITOR,DETECTOR,FRAME_PROC,AI_OPT,MEM_MGR core
    class CAMERA,STATE input
    class REDIS,CONFIG,LOGGER data
    class SOUND,NOTIF,STREAM output
....

== 🧠 Core層設計

=== 🎯 Monitorクラス設計

[mermaid]
....
classDiagram
    class Monitor {
        -config_manager: ConfigManager
        -object_detector: ObjectDetector
        -frame_processor: FrameProcessor
        -state_manager: StateManager
        -alert_manager: AlertManager
        -status_broadcaster: StatusBroadcaster
        -ai_optimizer: AIOptimizer
        -memory_manager: MemoryManager
        -logger: Logger
        
        +__init__(config_manager: ConfigManager)
        +start_monitoring(): void
        +stop_monitoring(): void
        +process_frame(frame: ndarray): DetectionResult
        +update_status(): void
        +handle_detection_result(result: DetectionResult): void
        +check_absence_alert(): void
        +check_smartphone_alert(): void
        -_initialize_components(): void
        -_setup_optimization(): void
        -_cleanup_resources(): void
    }
    
    class ObjectDetector {
        -yolo_model: YOLO
        -mediapipe_detector: MediaPipeDetector
        -ai_optimizer: AIOptimizer
        -confidence_threshold: float
        -device: str
        
        +__init__(config_manager: ConfigManager)
        +detect_objects(frame: ndarray): DetectionResult
        +detect_person(frame: ndarray): PersonDetection
        +detect_smartphone(frame: ndarray): SmartphoneDetection
        +initialize_models(): void
        +cleanup_models(): void
        -_optimize_inference(frame: ndarray): ndarray
        -_merge_detections(yolo_result, mp_result): DetectionResult
    }
    
    class AIOptimizer {
        -frame_skipper: FrameSkipper
        -batch_processor: BatchProcessor
        -gpu_manager: GPUManager
        -performance_monitor: PerformanceMonitor
        
        +optimize_yolo_inference(model, frame): Optional[Any]
        +optimize_mediapipe_inference(detector, frame): Optional[Any]
        +should_skip_frame(): bool
        +get_optimal_batch_size(): int
        +optimize_gpu_memory(): void
        +get_performance_stats(): dict
    }
    
    class MemoryManager {
        -frame_cache: LRUCache
        -model_cache: LRUCache
        -gc_threshold: int
        -max_memory_usage: float
        
        +cache_frame(key: str, frame: ndarray): void
        +get_cached_frame(key: str): Optional[ndarray]
        +cache_detection_result(key: str, result: DetectionResult): void
        +cleanup_cache(): void
        +monitor_memory_usage(): float
        +trigger_gc_if_needed(): void
    }
    
    Monitor --> ObjectDetector
    Monitor --> AIOptimizer
    Monitor --> MemoryManager
    ObjectDetector --> AIOptimizer
    ObjectDetector --> MemoryManager
    AIOptimizer --> MemoryManager
....

=== 🔍 検出システムクラス図

[mermaid]
....
classDiagram
    class DetectionResult {
        +person_detected: bool
        +smartphone_detected: bool
        +person_confidence: float
        +smartphone_confidence: float
        +person_bbox: tuple
        +smartphone_bbox: tuple
        +processing_time: float
        +timestamp: datetime
        +frame_id: str
        
        +to_dict(): dict
        +is_valid(): bool
        +merge(other: DetectionResult): DetectionResult
    }
    
    class YOLODetector {
        -model: YOLO
        -device: str
        -confidence_threshold: float
        -iou_threshold: float
        
        +__init__(model_path: str, device: str)
        +detect(frame: ndarray): YOLOResult
        +preprocess_frame(frame: ndarray): ndarray
        +postprocess_results(results): List[Detection]
        +optimize_for_inference(): void
    }
    
    class MediaPipeDetector {
        -pose_detector: PoseDetector
        -hand_detector: HandDetector
        -model_complexity: int
        -min_detection_confidence: float
        
        +__init__(config: dict)
        +detect_pose(frame: ndarray): PoseResult
        +detect_hands(frame: ndarray): HandResult
        +infer_smartphone_usage(pose, hands): bool
        +calculate_confidence(detections): float
    }
    
    class FrameProcessor {
        -input_size: tuple
        -color_space: str
        -preprocessing_pipeline: List[Callable]
        
        +preprocess(frame: ndarray): ndarray
        +resize_frame(frame: ndarray, target_size: tuple): ndarray
        +normalize_frame(frame: ndarray): ndarray
        +apply_filters(frame: ndarray): ndarray
        +validate_frame(frame: ndarray): bool
    }
    
    ObjectDetector --> YOLODetector
    ObjectDetector --> MediaPipeDetector
    ObjectDetector --> FrameProcessor
    YOLODetector --> DetectionResult
    MediaPipeDetector --> DetectionResult
    FrameProcessor --> DetectionResult
....

== 🌐 Service層設計

=== 📢 Alert・通知システム

[mermaid]
....
classDiagram
    class AlertManager {
        -alert_config: dict
        -active_alerts: List[Alert]
        -sound_service: SoundService
        -tts_service: TTSService
        -line_service: LineService
        -logger: Logger
        
        +__init__(config_manager: ConfigManager)
        +trigger_alert(alert_type: AlertType, context: dict): void
        +clear_alert(alert_id: str): void
        +get_active_alerts(): List[Alert]
        +schedule_alert(alert: Alert, delay: int): void
        -_create_alert(alert_type: AlertType): Alert
        -_play_alert_sound(alert: Alert): void
        -_send_notifications(alert: Alert): void
    }
    
    class Alert {
        +id: str
        +type: AlertType
        +message: str
        +severity: int
        +timestamp: datetime
        +context: dict
        +is_active: bool
        
        +to_dict(): dict
        +should_repeat(): bool
        +get_notification_channels(): List[str]
    }
    
    class TTSService {
        -engine: ZonosTTS
        -voice_config: dict
        -audio_queue: Queue
        -emotion_manager: EmotionManager
        
        +__init__(config: dict)
        +synthesize_speech(text: str, emotion: str): AudioData
        +play_tts_alert(message: str): void
        +set_voice_parameters(params: dict): void
        +get_available_voices(): List[str]
        -_process_audio_queue(): void
    }
    
    class SoundService {
        -audio_device: AudioDevice
        -sound_cache: dict
        -volume_level: float
        
        +play_sound(sound_file: str): void
        +play_tts_audio(audio_data: AudioData): void
        +set_volume(level: float): void
        +stop_all_sounds(): void
        +load_sound_files(): void
    }
    
    class LineService {
        -line_token: str
        -api_client: LineAPIClient
        -message_queue: Queue
        
        +send_message(message: str): bool
        +send_status_update(status: dict): bool
        +validate_token(): bool
        +get_quota_status(): dict
    }
    
    AlertManager --> Alert
    AlertManager --> TTSService
    AlertManager --> SoundService
    AlertManager --> LineService
    TTSService --> SoundService
....

=== 📊 Schedule・状態管理システム

[mermaid]
....
classDiagram
    class ScheduleManager {
        -schedules: List[Schedule]
        -schedule_checker: ScheduleChecker
        -timezone: str
        -config_manager: ConfigManager
        
        +__init__(config_manager: ConfigManager)
        +load_schedules(): void
        +add_schedule(schedule: Schedule): void
        +remove_schedule(schedule_id: str): void
        +check_current_schedule(): Optional[Schedule]
        +get_next_schedule(): Optional[Schedule]
        +is_monitoring_time(): bool
    }
    
    class Schedule {
        +id: str
        +name: str
        +start_time: time
        +end_time: time
        +days_of_week: List[int]
        +alert_enabled: bool
        +monitoring_enabled: bool
        +created_at: datetime
        +updated_at: datetime
        
        +is_active_now(): bool
        +is_active_on_day(day: int): bool
        +get_next_occurrence(): datetime
        +to_dict(): dict
    }
    
    class StateManager {
        -current_state: MonitoringState
        -state_history: List[StateTransition]
        -absence_start_time: Optional[datetime]
        -smartphone_start_time: Optional[datetime]
        -max_history_size: int
        
        +update_state(detection_result: DetectionResult): void
        +get_current_state(): MonitoringState
        +get_absence_duration(): int
        +get_smartphone_usage_duration(): int
        +reset_timers(): void
        +get_state_history(): List[StateTransition]
        -_transition_state(new_state: MonitoringState): void
        -_record_transition(transition: StateTransition): void
    }
    
    class MonitoringState {
        <<enumeration>>
        PRESENT
        ABSENT
        SMARTPHONE_DETECTED
        UNKNOWN
    }
    
    class StateTransition {
        +from_state: MonitoringState
        +to_state: MonitoringState
        +timestamp: datetime
        +trigger: str
        +confidence: float
        
        +to_dict(): dict
    }
    
    ScheduleManager --> Schedule
    StateManager --> MonitoringState
    StateManager --> StateTransition
....

== 🌐 Web層設計

=== 🔗 REST API設計

[mermaid]
....
classDiagram
    class FlaskApp {
        -app: Flask
        -socketio: SocketIO
        -monitor: Monitor
        -config_manager: ConfigManager
        
        +create_app(): Flask
        +register_blueprints(): void
        +setup_error_handlers(): void
        +setup_middleware(): void
        +run(): void
    }
    
    class APIRoutes {
        +register_routes(app: Flask): void
        +health_check(): Response
        +get_status(): Response
        +get_detection_history(): Response
        +update_config(): Response
        +trigger_manual_alert(): Response
        +get_schedules(): Response
        +create_schedule(): Response
    }
    
    class TTSRoutes {
        +synthesis_text(): Response
        +get_voices(): Response
        +upload_voice_sample(): Response
        +clone_voice(): Response
        +stream_audio(): Response
        +get_synthesis_history(): Response
    }
    
    class WebSocketHandler {
        -socketio: SocketIO
        -status_broadcaster: StatusBroadcaster
        -connected_clients: Set[str]
        
        +handle_connect(): void
        +handle_disconnect(): void
        +broadcast_status(status: dict): void
        +broadcast_alert(alert: Alert): void
        +handle_client_message(data: dict): void
        -_authenticate_client(token: str): bool
    }
    
    class StatusBroadcaster {
        -websocket_handler: WebSocketHandler
        -broadcast_interval: int
        -last_status: dict
        
        +start_broadcasting(): void
        +stop_broadcasting(): void
        +broadcast_detection_status(status: dict): void
        +broadcast_performance_stats(stats: dict): void
        -_should_broadcast(new_status: dict): bool
    }
    
    FlaskApp --> APIRoutes
    FlaskApp --> TTSRoutes
    FlaskApp --> WebSocketHandler
    WebSocketHandler --> StatusBroadcaster
....

=== 📡 WebSocket通信フロー

[mermaid]
....
sequenceDiagram
    participant C as Client
    participant WS as WebSocket Handler
    participant SB as Status Broadcaster
    participant M as Monitor
    participant D as Object Detector
    participant S as State Manager
    
    C->>WS: connect()
    WS->>C: connection_established
    
    loop Real-time monitoring
        M->>D: process_frame()
        D->>M: detection_result
        M->>S: update_state(result)
        S->>M: state_changed
        M->>SB: broadcast_status(status)
        SB->>WS: new_status_available
        WS->>C: status_update (WebSocket)
    end
    
    alt Alert triggered
        M->>SB: broadcast_alert(alert)
        SB->>WS: alert_triggered
        WS->>C: alert_notification
    end
    
    C->>WS: manual_alert_request
    WS->>M: trigger_manual_alert()
    M->>WS: alert_triggered
    WS->>C: alert_confirmation
    
    C->>WS: disconnect()
    WS->>SB: client_disconnected
....

== 💾 データ層設計

=== 📊 データモデル設計

[mermaid]
....
erDiagram
    DETECTION_LOG {
        string id PK
        datetime timestamp
        boolean person_detected
        boolean smartphone_detected
        float person_confidence
        float smartphone_confidence
        json person_bbox
        json smartphone_bbox
        float processing_time
        string frame_id
        json metadata
    }
    
    BEHAVIOR_LOG {
        string id PK
        datetime timestamp
        string state
        int duration_seconds
        string trigger
        float confidence
        json context
        string session_id
    }
    
    ALERT_LOG {
        string id PK
        datetime timestamp
        string alert_type
        string message
        int severity
        boolean is_resolved
        datetime resolved_at
        json context
        string triggered_by
    }
    
    SCHEDULE {
        string id PK
        string name
        time start_time
        time end_time
        json days_of_week
        boolean alert_enabled
        boolean monitoring_enabled
        datetime created_at
        datetime updated_at
        json metadata
    }
    
    PERFORMANCE_LOG {
        string id PK
        datetime timestamp
        float fps
        float cpu_usage
        float memory_usage
        float gpu_usage
        int cache_hits
        int cache_misses
        json system_info
    }
    
    TTS_SYNTHESIS_LOG {
        string id PK
        datetime timestamp
        string text
        string voice_id
        string emotion
        float synthesis_time
        int audio_duration_ms
        string file_path
        json parameters
    }
    
    USER_SESSION {
        string session_id PK
        datetime start_time
        datetime end_time
        int total_detections
        int absence_count
        int smartphone_usage_count
        json summary_stats
    }
    
    DETECTION_LOG ||--o{ BEHAVIOR_LOG : triggers
    BEHAVIOR_LOG ||--o{ ALERT_LOG : generates
    SCHEDULE ||--o{ ALERT_LOG : scheduled_by
    USER_SESSION ||--o{ DETECTION_LOG : contains
    USER_SESSION ||--o{ BEHAVIOR_LOG : includes
....

=== 🗄️ Redisキャッシュ設計

```python
# Redis Schema Design
CACHE_SCHEMAS = {
    # Session data
    'session:{session_id}': {
        'ttl': 86400,  # 24 hours
        'data': {
            'user_id': str,
            'start_time': datetime,
            'current_state': str,
            'detection_count': int
        }
    },
    
    # Frame cache (short-term)
    'frame:{frame_id}': {
        'ttl': 300,  # 5 minutes
        'data': {
            'frame_data': bytes,
            'timestamp': datetime,
            'preprocessing_done': bool
        }
    },
    
    # Detection results cache
    'detection:{frame_id}': {
        'ttl': 3600,  # 1 hour
        'data': {
            'result': dict,
            'confidence': float,
            'processing_time': float
        }
    },
    
    # Configuration cache
    'config:current': {
        'ttl': -1,  # Persistent
        'data': {
            'ai_config': dict,
            'alert_config': dict,
            'schedule_config': dict
        }
    },
    
    # Performance metrics
    'metrics:current': {
        'ttl': 60,  # 1 minute
        'data': {
            'fps': float,
            'cpu_usage': float,
            'memory_usage': float,
            'gpu_usage': float
        }
    }
}
```

== 🔄 プロセスフロー設計

=== 🎯 メイン監視ループ

[mermaid]
....
flowchart TD
    START([監視開始])
    
    INIT[システム初期化]
    LOAD_CONFIG[設定読み込み]
    INIT_AI[AIモデル初期化]
    START_CAMERA[カメラ起動]
    
    LOOP_START{監視ループ開始}
    CAPTURE[フレーム取得]
    
    FRAME_CHECK{フレーム有効?}
    SKIP_CHECK{スキップ判定}
    
    PREPROCESS[前処理実行]
    AI_DETECT[AI検出実行]
    POST_PROCESS[後処理・結果統合]
    
    STATE_UPDATE[状態更新]
    ALERT_CHECK{アラート条件?}
    TRIGGER_ALERT[アラート発動]
    
    BROADCAST[状態配信]
    CACHE_UPDATE[キャッシュ更新]
    
    SCHEDULE_CHECK{スケジュール確認}
    PERFORMANCE[パフォーマンス監視]
    
    MEMORY_CHECK{メモリ使用量確認}
    CLEANUP[メモリクリーンアップ]
    
    CONTINUE{継続?}
    STOP_MONITOR[監視停止]
    CLEANUP_FINAL[最終クリーンアップ]
    END([終了])
    
    START --> INIT
    INIT --> LOAD_CONFIG
    LOAD_CONFIG --> INIT_AI
    INIT_AI --> START_CAMERA
    START_CAMERA --> LOOP_START
    
    LOOP_START --> CAPTURE
    CAPTURE --> FRAME_CHECK
    
    FRAME_CHECK -->|有効| SKIP_CHECK
    FRAME_CHECK -->|無効| LOOP_START
    
    SKIP_CHECK -->|処理| PREPROCESS
    SKIP_CHECK -->|スキップ| STATE_UPDATE
    
    PREPROCESS --> AI_DETECT
    AI_DETECT --> POST_PROCESS
    POST_PROCESS --> STATE_UPDATE
    
    STATE_UPDATE --> ALERT_CHECK
    ALERT_CHECK -->|条件満たす| TRIGGER_ALERT
    ALERT_CHECK -->|条件満たさない| BROADCAST
    TRIGGER_ALERT --> BROADCAST
    
    BROADCAST --> CACHE_UPDATE
    CACHE_UPDATE --> SCHEDULE_CHECK
    SCHEDULE_CHECK --> PERFORMANCE
    PERFORMANCE --> MEMORY_CHECK
    
    MEMORY_CHECK -->|正常| CONTINUE
    MEMORY_CHECK -->|閾値超過| CLEANUP
    CLEANUP --> CONTINUE
    
    CONTINUE -->|継続| LOOP_START
    CONTINUE -->|停止| STOP_MONITOR
    
    STOP_MONITOR --> CLEANUP_FINAL
    CLEANUP_FINAL --> END
    
    classDef startEnd fill:#e8f5e8
    classDef process fill:#e3f2fd
    classDef decision fill:#fff3e0
    classDef alert fill:#ffebee
    
    class START,END startEnd
    class INIT,LOAD_CONFIG,INIT_AI,PREPROCESS,AI_DETECT,POST_PROCESS process
    class FRAME_CHECK,SKIP_CHECK,ALERT_CHECK,MEMORY_CHECK,CONTINUE decision
    class TRIGGER_ALERT alert
....

=== 🧠 AI推論最適化フロー

[mermaid]
....
flowchart TD
    FRAME_INPUT[入力フレーム]
    
    AI_OPT_START[AI最適化開始]
    PERF_CHECK[パフォーマンス確認]
    
    FRAME_SKIP_DECISION{フレームスキップ判定}
    FRAME_SKIP[スキップ実行]
    
    GPU_CHECK{GPU利用可能?}
    GPU_OPTIMIZE[GPU最適化]
    CPU_FALLBACK[CPU フォールバック]
    
    BATCH_CHECK{バッチ処理可能?}
    BATCH_PROCESS[バッチ推論]
    SINGLE_PROCESS[単一フレーム推論]
    
    YOLO_INFERENCE[YOLO推論]
    MP_INFERENCE[MediaPipe推論]
    
    RESULT_MERGE[結果統合]
    CONFIDENCE_CHECK{信頼度確認}
    
    CACHE_STORE[結果キャッシュ]
    PERFORMANCE_LOG[パフォーマンスログ]
    
    MEMORY_MONITOR[メモリ監視]
    GC_TRIGGER{GC実行判定}
    MEMORY_CLEANUP[メモリクリーンアップ]
    
    RESULT_OUTPUT[推論結果出力]
    
    FRAME_INPUT --> AI_OPT_START
    AI_OPT_START --> PERF_CHECK
    PERF_CHECK --> FRAME_SKIP_DECISION
    
    FRAME_SKIP_DECISION -->|スキップ| FRAME_SKIP
    FRAME_SKIP_DECISION -->|処理| GPU_CHECK
    FRAME_SKIP --> RESULT_OUTPUT
    
    GPU_CHECK -->|利用可能| GPU_OPTIMIZE
    GPU_CHECK -->|利用不可| CPU_FALLBACK
    
    GPU_OPTIMIZE --> BATCH_CHECK
    CPU_FALLBACK --> BATCH_CHECK
    
    BATCH_CHECK -->|可能| BATCH_PROCESS
    BATCH_CHECK -->|不可| SINGLE_PROCESS
    
    BATCH_PROCESS --> YOLO_INFERENCE
    SINGLE_PROCESS --> YOLO_INFERENCE
    
    YOLO_INFERENCE --> MP_INFERENCE
    MP_INFERENCE --> RESULT_MERGE
    
    RESULT_MERGE --> CONFIDENCE_CHECK
    CONFIDENCE_CHECK --> CACHE_STORE
    CACHE_STORE --> PERFORMANCE_LOG
    
    PERFORMANCE_LOG --> MEMORY_MONITOR
    MEMORY_MONITOR --> GC_TRIGGER
    
    GC_TRIGGER -->|実行| MEMORY_CLEANUP
    GC_TRIGGER -->|不要| RESULT_OUTPUT
    MEMORY_CLEANUP --> RESULT_OUTPUT
    
    classDef input fill:#e8f5e8
    classDef optimization fill:#e3f2fd
    classDef inference fill:#fff3e0
    classDef decision fill:#f3e5f5
    classDef output fill:#fce4ec
    
    class FRAME_INPUT input
    class AI_OPT_START,GPU_OPTIMIZE,CPU_FALLBACK,BATCH_PROCESS optimization
    class YOLO_INFERENCE,MP_INFERENCE,RESULT_MERGE inference
    class FRAME_SKIP_DECISION,GPU_CHECK,BATCH_CHECK,CONFIDENCE_CHECK,GC_TRIGGER decision
    class RESULT_OUTPUT,CACHE_STORE,PERFORMANCE_LOG output
....

== 🔧 例外処理・エラーハンドリング設計

=== 📋 例外階層構造

[mermaid]
....
classDiagram
    class KanshiChanError {
        +error_code: str
        +message: str
        +details: dict
        +timestamp: datetime
        
        +to_dict(): dict
        +to_response(): Response
    }
    
    class AIModelError {
        +model_type: str
        +model_path: str
    }
    
    class InferenceError {
        +frame_id: str
        +inference_time: float
    }
    
    class OptimizationError {
        +optimization_type: str
        +performance_impact: str
    }
    
    class CameraError {
        +device_id: int
        +device_status: str
    }
    
    class ConfigurationError {
        +config_key: str
        +expected_type: type
        +actual_value: Any
    }
    
    class AlertError {
        +alert_type: str
        +notification_channels: List[str]
    }
    
    class TTSError {
        +voice_id: str
        +text_length: int
        +synthesis_time: float
    }
    
    KanshiChanError <|-- AIModelError
    KanshiChanError <|-- CameraError
    KanshiChanError <|-- ConfigurationError
    KanshiChanError <|-- AlertError
    
    AIModelError <|-- InferenceError
    AIModelError <|-- OptimizationError
    AlertError <|-- TTSError
....

=== 🔄 エラー処理フロー

```python
# Exception handling pattern
from utils.exceptions import wrap_exception, create_error_response

class ObjectDetector:
    def detect_objects(self, frame: np.ndarray) -> Dict[str, Any]:
        try:
            # AI推論実行
            results = self._run_inference(frame)
            return self._process_results(results)
            
        except torch.cuda.OutOfMemoryError as e:
            # GPU メモリ不足の場合
            optimization_error = wrap_exception(
                e, OptimizationError,
                "GPU memory insufficient, falling back to CPU",
                error_code="OPT_001",
                details={
                    'gpu_memory_used': torch.cuda.memory_allocated(),
                    'fallback_action': 'switch_to_cpu'
                }
            )
            logger.warning(f"GPU memory issue: {optimization_error.to_dict()}")
            
            # CPU にフォールバック
            return self._run_cpu_inference(frame)
            
        except cv2.error as e:
            # OpenCV エラー
            inference_error = wrap_exception(
                e, InferenceError,
                "Frame processing failed",
                error_code="INF_002",
                details={
                    'frame_shape': frame.shape if frame is not None else None,
                    'frame_dtype': str(frame.dtype) if frame is not None else None
                }
            )
            logger.error(f"OpenCV error: {inference_error.to_dict()}")
            raise inference_error
            
        except Exception as e:
            # 予期しないエラー
            model_error = wrap_exception(
                e, AIModelError,
                "Unexpected error during object detection",
                error_code="AI_999",
                details={'unexpected_error': True}
            )
            logger.error(f"Unexpected detection error: {model_error.to_dict()}", exc_info=True)
            raise model_error
```

== ⚡ パフォーマンス最適化設計

=== 📊 メモリ管理システム

[mermaid]
....
classDiagram
    class MemoryManager {
        -frame_cache: LRUCache[str, ndarray]
        -result_cache: LRUCache[str, DetectionResult]
        -model_cache: LRUCache[str, Any]
        -gc_threshold: float
        -max_memory_usage: float
        -memory_monitor: MemoryMonitor
        
        +cache_frame(key: str, frame: ndarray): void
        +get_cached_frame(key: str): Optional[ndarray]
        +cache_detection_result(key: str, result: DetectionResult): void
        +get_cached_result(key: str): Optional[DetectionResult]
        +cleanup_expired_cache(): void
        +force_garbage_collection(): void
        +get_memory_stats(): dict
        -_should_trigger_gc(): bool
        -_calculate_cache_efficiency(): float
    }
    
    class LRUCache {
        -max_size: int
        -current_size: int
        -cache_dict: dict
        -access_order: deque
        
        +get(key: str): Optional[Any]
        +put(key: str, value: Any): void
        +remove(key: str): bool
        +clear(): void
        +get_stats(): CacheStats
        -_evict_lru(): void
    }
    
    class MemoryMonitor {
        -process: psutil.Process
        -gpu_monitor: GPUMonitor
        -thresholds: dict
        
        +get_system_memory(): float
        +get_process_memory(): float
        +get_gpu_memory(): float
        +is_memory_critical(): bool
        +get_memory_breakdown(): dict
    }
    
    class CacheStats {
        +hits: int
        +misses: int
        +evictions: int
        +hit_rate: float
        +memory_usage: int
        
        +to_dict(): dict
    }
    
    MemoryManager --> LRUCache
    MemoryManager --> MemoryMonitor
    LRUCache --> CacheStats
....

=== ⚡ フレームスキップ最適化

```python
class FrameSkipper:
    def __init__(self, config_manager: ConfigManager):
        self.config = config_manager.get_ai_config()
        self.performance_monitor = PerformanceMonitor()
        self.skip_count = 0
        self.total_frames = 0
        
    def should_skip_frame(self) -> bool:
        """フレームスキップ判定ロジック"""
        current_fps = self.performance_monitor.get_current_fps()
        target_fps = self.config.get('target_fps', 15.0)
        
        # CPU/GPU使用率に基づく動的調整
        cpu_usage = self.performance_monitor.get_cpu_usage()
        gpu_usage = self.performance_monitor.get_gpu_usage()
        
        # アダプティブスキップ戦略
        if current_fps < target_fps * 0.8:  # FPS が目標の80%以下
            if cpu_usage > 80 or gpu_usage > 85:
                skip_probability = min(0.5, (cpu_usage - 60) / 40)
                return random.random() < skip_probability
                
        return False
        
    def get_skip_stats(self) -> dict:
        """スキップ統計の取得"""
        return {
            'skip_rate': self.skip_count / max(self.total_frames, 1),
            'total_frames': self.total_frames,
            'skipped_frames': self.skip_count,
            'performance_impact': self._calculate_performance_impact()
        }
```

== 🔒 セキュリティ設計

=== 🛡️ 認証・認可システム

[mermaid]
....
sequenceDiagram
    participant C as Client
    participant AUTH as Auth Middleware
    participant JWT as JWT Handler
    participant API as API Endpoint
    participant RBAC as RBAC Manager
    
    C->>AUTH: Request with Token
    AUTH->>JWT: Validate Token
    
    alt Token Valid
        JWT->>AUTH: Token Claims
        AUTH->>RBAC: Check Permissions
        
        alt Has Permission
            RBAC->>AUTH: Access Granted
            AUTH->>API: Forward Request
            API->>AUTH: Response
            AUTH->>C: Authorized Response
        else No Permission
            RBAC->>AUTH: Access Denied
            AUTH->>C: 403 Forbidden
        end
        
    else Token Invalid
        JWT->>AUTH: Invalid Token
        AUTH->>C: 401 Unauthorized
    end
....

=== 🔐 データ暗号化・保護

```python
class SecurityManager:
    def __init__(self, config_manager: ConfigManager):
        self.config = config_manager.get_security_config()
        self.fernet = self._initialize_encryption()
        
    def encrypt_sensitive_data(self, data: dict) -> str:
        """機密データの暗号化"""
        json_data = json.dumps(data)
        encrypted = self.fernet.encrypt(json_data.encode())
        return base64.b64encode(encrypted).decode()
        
    def decrypt_sensitive_data(self, encrypted_data: str) -> dict:
        """機密データの復号化"""
        encrypted_bytes = base64.b64decode(encrypted_data.encode())
        decrypted = self.fernet.decrypt(encrypted_bytes)
        return json.loads(decrypted.decode())
        
    def hash_password(self, password: str) -> str:
        """パスワードハッシュ化"""
        salt = bcrypt.gensalt()
        return bcrypt.hashpw(password.encode(), salt).decode()
        
    def verify_password(self, password: str, hashed: str) -> bool:
        """パスワード検証"""
        return bcrypt.checkpw(password.encode(), hashed.encode())
```

== 📊 監視・ログ設計

=== 📈 構造化ログ設計

```python
# Structured logging configuration
LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'json': {
            'class': 'pythonjsonlogger.jsonlogger.JsonFormatter',
            'format': '%(asctime)s %(name)s %(levelname)s %(message)s'
        }
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'formatter': 'json',
            'level': 'INFO'
        },
        'file': {
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': 'logs/kanshichan.log',
            'formatter': 'json',
            'maxBytes': 104857600,  # 100MB
            'backupCount': 10
        }
    },
    'loggers': {
        'kanshichan': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
            'propagate': False
        }
    }
}

# Structured logging example
logger.info("AI processing completed", extra={
    'event': 'ai_processing',
    'processing_time': 0.045,
    'fps': 28.5,
    'objects_detected': 2,
    'model_type': 'yolov8n',
    'device': 'cuda:0',
    'memory_usage': 2.1,
    'confidence_scores': [0.87, 0.92]
})
```

== 🔗 関連ドキュメント

=== 📖 必須参照ドキュメント
* **<<backend-architecture>>**: システム全体アーキテクチャ
* **<<database-schema>>**: データベース設計詳細
* **<<development-guide>>**: 開発手順とベストプラクティス
* **<<testing-strategy>>**: テスト設計と品質保証

=== 🛠️ 開発者向けリソース
* **<<ai-ml-specifications>>**: AI/ML技術詳細仕様
* **<<rest-api-reference>>**: REST API仕様
* **<<websocket-api>>**: WebSocket API仕様
* **<<performance-optimization>>**: パフォーマンス最適化手法

=== 📊 運用・保守関連
* **<<configuration-guide>>**: 設定管理詳細
* **<<operations-monitoring>>**: 運用監視手順
* **<<troubleshooting-guide>>**: トラブルシューティング
* **<<security-specifications>>**: セキュリティ詳細仕様

[NOTE]
====
🔄 **設計の進化**

本設計ドキュメントは実装の進行と運用実績に基づいて
継続的に更新・改善されます。

**変更管理**: Git commit history で設計変更を追跡 +
**レビュー**: 四半期ごとの設計レビュー実施 +
**フィードバック**: team@kanshichan.dev

**重要**: 実装時は最新のドキュメントバージョンを参照してください
====

---

**📞 Contact**: team@kanshichan.dev +
**🔗 Repository**: https://github.com/kanshichan/backend +
**📅 Last Updated**: {docdate} +
**📝 Document Version**: {revnumber} 