= ğŸ§  ç›£è¦–ã¡ã‚ƒã‚“(KanshiChan) è¡Œå‹•åˆ†æã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜æ›¸
:toc: left
:toc-title: ç›®æ¬¡
:toclevels: 4
:numbered:
:source-highlighter: highlight.js
:icons: font
:doctype: book
:version: 1.0.0
:author: KanshiChan AI/ML Team
:email: ai-team@kanshichan.dev
:revnumber: 1.0
:revdate: {docdate}
:experimental:

== ğŸ“‹ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±

[cols="1,3", options="header"]
|===
|é …ç›® |è©³ç´°
|**ä½œæˆè€…** |KanshiChan AI/MLé–‹ç™ºãƒãƒ¼ãƒ 
|**æœ€çµ‚æ›´æ–°æ—¥** |{docdate}
|**å¯¾è±¡èª­è€…** |AI/MLã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã€ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ
|**æ–‡æ›¸ãƒãƒ¼ã‚¸ãƒ§ãƒ³** |{revnumber}
|**ã‚·ã‚¹ãƒ†ãƒ ãƒãƒ¼ã‚¸ãƒ§ãƒ³** |KanshiChan v2.0
|**ãƒ¬ãƒ“ãƒ¥ãƒ¼çŠ¶æ³** |åˆç‰ˆä½œæˆå®Œäº†
|===

[IMPORTANT]
====
ğŸ¯ **ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç›®çš„**

ç›£è¦–ã¡ã‚ƒã‚“ï¼ˆKanshiChanï¼‰ã®è¡Œå‹•åˆ†æã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦ã€AI/MLæ©Ÿèƒ½ã®è©³ç´°å®Ÿè£…ã€ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€å¥åº·è©•ä¾¡æŒ‡æ¨™ã€ãŠã‚ˆã³å€‹äººåŒ–ã‚¨ãƒ³ã‚¸ãƒ³ã®æŠ€è¡“ä»•æ§˜ã‚’åŒ…æ‹¬çš„ã«è§£èª¬ã—ã¾ã™ã€‚

**æƒ³å®šèª­è€…**: AI/MLã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã€ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ
====

== ğŸŒŸ ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

=== ğŸ“– è¡Œå‹•åˆ†æã‚·ã‚¹ãƒ†ãƒ ã¨ã¯

ç›£è¦–ã¡ã‚ƒã‚“ã®è¡Œå‹•åˆ†æã‚·ã‚¹ãƒ†ãƒ ã¯ã€YOLOv8ã¨MediaPipeã«ã‚ˆã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½œæ¥­ãƒ‘ã‚¿ãƒ¼ãƒ³ã€é›†ä¸­åº¦ã€å¥åº·çŠ¶æ…‹ã‚’åˆ†æã™ã‚‹é«˜åº¦ãªAI/MLã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚

=== ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

[mermaid]
....
graph TB
    subgraph "ğŸ” ãƒ‡ãƒ¼ã‚¿åé›†å±¤"
        A1[YOLOv8æ¤œå‡ºå™¨]
        A2[MediaPipeå§¿å‹¢æ¤œå‡º]
        A3[ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³]
    end
    
    subgraph "ğŸ“Š ãƒ‡ãƒ¼ã‚¿å‡¦ç†å±¤"
        B1[BehaviorLog<br/>ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«]
        B2[ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†<br/>ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³]
        B3[ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°]
    end
    
    subgraph "ğŸ§  åˆ†æã‚¨ãƒ³ã‚¸ãƒ³å±¤"
        C1[AdvancedBehaviorAnalyzer<br/>é«˜åº¦è¡Œå‹•åˆ†æ]
        C2[PatternRecognizer<br/>ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜]
        C3[UserProfileBuilder<br/>å€‹äººåŒ–ã‚¨ãƒ³ã‚¸ãƒ³]
    end
    
    subgraph "ğŸ“ˆ åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"
        D1[æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ]
        D2[é›†ä¸­åº¦è©³ç´°åˆ†æ]
        D3[å¥åº·è©•ä¾¡åˆ†æ]
        D4[æ´»å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ]
        D5[äºˆæ¸¬åˆ†æ]
    end
    
    subgraph "ğŸ¯ å‡ºåŠ›ãƒ»æ´»ç”¨å±¤"
        E1[ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ <br/>WebSocketé…ä¿¡]
        E2[REST API<br/>ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ]
        E3[ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ]
        E4[æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³]
    end
    
    A1 --> B1
    A2 --> B1
    A3 --> B1
    B1 --> B2
    B2 --> B3
    B3 --> C1
    B3 --> C2
    B3 --> C3
    
    C1 --> D1
    C1 --> D2
    C1 --> D3
    C1 --> D4
    C2 --> D5
    C3 --> D5
    
    D1 --> E1
    D2 --> E2
    D3 --> E3
    D4 --> E4
    D5 --> E4
    
    classDef dataLayer fill:#e1f5fe
    classDef processLayer fill:#f3e5f5
    classDef analysisLayer fill:#e8f5e8
    classDef moduleLayer fill:#fff3e0
    classDef outputLayer fill:#fce4ec
    
    class A1,A2,A3 dataLayer
    class B1,B2,B3 processLayer
    class C1,C2,C3 analysisLayer
    class D1,D2,D3,D4,D5 moduleLayer
    class E1,E2,E3,E4 outputLayer
....

=== ğŸ”§ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

[cols="2,3,2", options="header"]
|===
|ã‚«ãƒ†ã‚´ãƒª |æŠ€è¡“ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒª |ãƒãƒ¼ã‚¸ãƒ§ãƒ³
|**æ©Ÿæ¢°å­¦ç¿’** |YOLOv8 (ultralytics) |>=8.3.87
|**ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³** |MediaPipe |>=0.10.21
|**æ•°å€¤è¨ˆç®—** |NumPy |>=1.26.4
|**ãƒ‡ãƒ¼ã‚¿å‡¦ç†** |Pandas |>=2.0.0
|**æ·±å±¤å­¦ç¿’** |PyTorch |>=2.5.1
|**ç”»åƒå‡¦ç†** |OpenCV |>=4.11
|**çµ±è¨ˆåˆ†æ** |SciPy |>=1.11.0
|===

== ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ä»•æ§˜

=== ğŸ—ƒï¸ BehaviorLogãƒ¢ãƒ‡ãƒ«

è¡Œå‹•åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®ä¸­æ ¸ã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼š

[source,python]
----
class BehaviorLog(BaseModel):
    """è¡Œå‹•ãƒ­ã‚°ãƒ¢ãƒ‡ãƒ« - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ‡ãƒ¼ã‚¿ã®è¨˜éŒ²"""
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä»˜ãï¼‰
    timestamp = Column(DateTime, nullable=False, index=True)
    
    # YOLOv8æ¤œå‡ºçµæœ
    detected_objects = Column(JSON, nullable=True)
    object_count = Column(JSON, nullable=True)
    
    # MediaPipeé›†ä¸­åº¦ãƒ»å§¿å‹¢ãƒ‡ãƒ¼ã‚¿
    focus_level = Column(Float, nullable=True)  # 0.0-1.0
    posture_data = Column(JSON, nullable=True)
    face_landmarks = Column(JSON, nullable=True)
    
    # ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ä½¿ç”¨çŠ¶æ³
    smartphone_detected = Column(Boolean, default=False)
    smartphone_duration = Column(Float, nullable=True)
    
    # çŠ¶æ…‹åˆ¤å®šçµæœ
    presence_status = Column(String(20), nullable=True)  # present/absent/break
    attention_status = Column(String(20), nullable=True)  # focused/distracted/unknown
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±
    session_id = Column(String(50), nullable=True, index=True)
    work_category = Column(String(50), nullable=True)
----

=== ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿æ§‹é€ è¨­è¨ˆ

[mermaid]
....
erDiagram
    BEHAVIOR_LOG {
        datetime timestamp PK
        json detected_objects
        json object_count
        float focus_level
        json posture_data
        boolean smartphone_detected
        string presence_status
        string attention_status
        string session_id
        string work_category
    }
    
    BEHAVIOR_TIMELINE {
        string timeline_id PK
        date timeline_date
        string session_id FK
        json timeline_events
        json state_transitions
        json pattern_analysis
    }
    
    USER_PROFILE {
        string user_id PK
        json behavioral_patterns
        json preferences
        json optimization_settings
        datetime last_updated
    }
    
    ANALYSIS_RESULT {
        string analysis_id PK
        datetime timestamp
        string analysis_type
        json results
        float confidence_score
    }
    
    BEHAVIOR_LOG ||--o{ BEHAVIOR_TIMELINE : builds
    BEHAVIOR_LOG ||--o{ ANALYSIS_RESULT : generates
    USER_PROFILE ||--o{ ANALYSIS_RESULT : customizes
....

== ğŸ§  AdvancedBehaviorAnalyzer è©³ç´°ä»•æ§˜

=== ğŸ“‹ ã‚¯ãƒ©ã‚¹æ¦‚è¦

`AdvancedBehaviorAnalyzer`ã¯ã€åŸºæœ¬çš„ãª`BehaviorAnalyzer`ã‚’æ‹¡å¼µã—ãŸé«˜åº¦åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚

[source,python]
----
class AdvancedBehaviorAnalyzer:
    """é«˜åº¦è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã‚¨ãƒ³ã‚¸ãƒ³
    
    æ—¢å­˜ã®BehaviorAnalyzerã‚’æ‹¡å¼µã—ã€ã‚ˆã‚Šè©³ç´°ã§é«˜åº¦ãªåˆ†ææ©Ÿèƒ½ã‚’æä¾›
    """
    
    def __init__(self, config: Dict[str, Any]):
        # åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        self.focus_thresholds = {
            'high': config.get('focus_threshold_high', 0.8),
            'medium': config.get('focus_threshold_medium', 0.6),
            'low': config.get('focus_threshold_low', 0.4)
        }
        
        self.health_params = {
            'max_sitting_minutes': config.get('max_sitting_minutes', 60),
            'min_movement_frequency': config.get('min_movement_frequency', 0.1),
            'eye_strain_threshold': config.get('eye_strain_threshold', 45)
        }
----

=== ğŸ” ä¸»è¦åˆ†æãƒ¡ã‚½ãƒƒãƒ‰

==== ğŸ“Š æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ

[source,python]
----
def analyze_time_series_patterns(self, logs: List[BehaviorLog], 
                               analysis_window: str = "daily") -> Dict[str, Any]:
    """æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    
    Args:
        logs: è¡Œå‹•ãƒ­ã‚°ãƒªã‚¹ãƒˆ
        analysis_window: åˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆhourly/daily/weekly/monthlyï¼‰
        
    Returns:
        dict: æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æçµæœ
    """
    # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
    df = self._prepare_timeseries_data(logs)
    
    # å­£ç¯€æ€§ãƒ»å‘¨æœŸæ€§æ¤œå‡º
    seasonality_analysis = self._detect_seasonality(df, analysis_window)
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    trend_analysis = self._analyze_trends(df)
    
    # å¤‰åŒ–ç‚¹æ¤œå‡º
    change_points = self._detect_change_points(df)
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡
    patterns = self._classify_patterns(df, seasonality_analysis, trend_analysis)
    
    # äºˆæ¸¬ç”Ÿæˆ
    predictions = self._generate_predictions(df, patterns)
----

==== ğŸ¯ é›†ä¸­åº¦è©³ç´°åˆ†æ

é›†ä¸­åº¦ã®è©³ç´°åˆ†æã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èªçŸ¥çŠ¶æ…‹ã‚’æ·±ãç†è§£ï¼š

[source,python]
----
def analyze_focus_detailed(self, logs: List[BehaviorLog]) -> Dict[str, Any]:
    """é›†ä¸­åº¦è©³ç´°åˆ†æ"""
    
    # é›†ä¸­ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®æŠ½å‡º
    focus_sessions = self._extract_focus_sessions(logs)
    
    # é›†ä¸­åº¦ãƒ¬ãƒ™ãƒ«åˆ†é¡
    level_classification = self._classify_focus_levels(logs)
    
    # é›†ä¸­ç¶™ç¶šæ™‚é–“åˆ†æ
    duration_analysis = self._analyze_focus_duration(focus_sessions)
    
    # é›†ä¸­é˜»å®³è¦å› ç‰¹å®š
    distraction_analysis = self._analyze_focus_distractions(logs)
    
    # æœ€é©é›†ä¸­æ™‚é–“å¸¯æ¨å®š
    optimal_periods = self._estimate_optimal_focus_periods(logs)
----

==== ğŸ¥ å¥åº·è©•ä¾¡åˆ†æ

å§¿å‹¢ã¨å¥åº·çŠ¶æ…‹ã®ç·åˆè©•ä¾¡ï¼š

[source,python]
----
def analyze_health_assessment(self, logs: List[BehaviorLog]) -> Dict[str, Any]:
    """å§¿å‹¢ãƒ»å¥åº·åˆ†æ"""
    
    # å§¿å‹¢ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    posture_analysis = self._analyze_posture_patterns(logs)
    
    # é•·æ™‚é–“åŒä¸€å§¿å‹¢æ¤œå‡º
    sitting_analysis = self._analyze_prolonged_sitting(logs)
    
    # é‹å‹•ãƒ»ä¼‘æ†©ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    movement_analysis = self._analyze_movement_patterns(logs)
    
    # ã‚¢ã‚¤ã‚¹ãƒˆãƒ¬ã‚¤ãƒ³è©•ä¾¡
    eye_strain_analysis = self._analyze_eye_strain_risk(logs)
    
    # ç·åˆå¥åº·ãƒªã‚¹ã‚¯è©•ä¾¡
    health_assessment = self._calculate_health_assessment(
        posture_analysis, sitting_analysis, movement_analysis, eye_strain_analysis
    )
----

=== ğŸ“ åˆ†ææŒ‡æ¨™ã¨ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹

==== ğŸ¯ FocusSession ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹

[source,python]
----
@dataclass
class FocusSession:
    """é›†ä¸­ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    start_time: datetime
    end_time: datetime
    duration_minutes: float
    average_focus: float
    focus_level: FocusLevel  # HIGH/MEDIUM/LOW/SCATTERED
    interruptions: int
    quality_score: float
    distractions: List[str]
----

==== ğŸ¥ HealthAssessment ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹

[source,python]
----
@dataclass
class HealthAssessment:
    """å¥åº·è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    posture_score: float
    movement_frequency: float
    eye_strain_risk: float
    overall_risk: HealthRiskLevel  # LOW/MODERATE/HIGH/CRITICAL
    recommendations: List[str]
    break_intervals: List[int]  # æ¨å¥¨ä¼‘æ†©é–“éš”ï¼ˆåˆ†ï¼‰
----

==== ğŸ“Š ProductivityMetrics ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹

[source,python]
----
@dataclass
class ProductivityMetrics:
    """ç”Ÿç”£æ€§æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    efficiency_score: float
    focus_consistency: float
    optimal_work_periods: List[Tuple[int, int]]  # (é–‹å§‹æ™‚é–“, çµ‚äº†æ™‚é–“) ãƒšã‚¢
    distractions_per_hour: float
    break_effectiveness: float
----

== ğŸ” PatternRecognizer æ©Ÿèƒ½ä»•æ§˜

=== ğŸ¯ æ¦‚è¦

`PatternRecognizer`ã¯æ©Ÿæ¢°å­¦ç¿’ã‚’æ´»ç”¨ã—ãŸé«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚

[source,python]
----
class PatternRecognizer:
    """ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã‚¨ãƒ³ã‚¸ãƒ³
    
    æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã—ãŸè¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è­˜åˆ¥ã¨äºˆæ¸¬
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.clustering_config = config.get('clustering', {})
        self.pattern_thresholds = config.get('pattern_thresholds', {})
        self.learning_rate = config.get('learning_rate', 0.01)
----

=== ğŸ“Š ä¸»è¦æ©Ÿèƒ½

==== ğŸ”® æ™‚é–“çš„ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜

[source,python]
----
def recognize_temporal_patterns(self, logs: List[BehaviorLog]) -> Dict[str, Any]:
    """æ™‚é–“çš„ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜
    
    Returns:
        dict: èªè­˜ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³
            - cyclical_patterns: å‘¨æœŸçš„ãƒ‘ã‚¿ãƒ¼ãƒ³
            - trend_patterns: ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³
            - anomaly_patterns: ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³
    """
----

==== ğŸ¯ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æ

[source,python]
----
def perform_clustering_analysis(self, logs: List[BehaviorLog]) -> Dict[str, Any]:
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æã«ã‚ˆã‚‹è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡
    
    æ©Ÿæ¢°å­¦ç¿’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆK-means, DBSCANï¼‰ã‚’ä½¿ç”¨
    """
----

==== ğŸ§  ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’

[source,python]
----
def learn_user_patterns(self, logs: List[BehaviorLog], 
                       user_id: Optional[str] = None) -> Dict[str, Any]:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­¦ç¿’
    
    å€‹äººã®è¡Œå‹•ç‰¹æ€§ã‚’å­¦ç¿’ã—ã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸåˆ†æã‚’æä¾›
    """
----

=== ğŸ“ˆ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœãƒ¢ãƒ‡ãƒ«

[source,python]
----
@dataclass
class BehaviorCluster:
    """è¡Œå‹•ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    cluster_id: int
    cluster_type: str  # "high_focus", "distracted", "break_period", etc.
    center: List[float]  # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä¸­å¿ƒåº§æ¨™
    size: int  # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°
    variance: float  # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…åˆ†æ•£
    typical_behaviors: List[str]  # å…¸å‹çš„ãªè¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³
    time_periods: List[Tuple[int, int]]  # ç™ºç”Ÿæ™‚é–“å¸¯
----

== ğŸ‘¤ UserProfileBuilder å€‹äººåŒ–ã‚¨ãƒ³ã‚¸ãƒ³

=== ğŸ¯ æ¦‚è¦

`UserProfileBuilder`ã¯å€‹äººã®è¡Œå‹•ç‰¹æ€§ã‚’å­¦ç¿’ã—ã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸåˆ†æã‚’æä¾›ã™ã‚‹å€‹äººåŒ–ã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚

[source,python]
----
class UserProfileBuilder:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ§‹ç¯‰ã‚µãƒ¼ãƒ“ã‚¹
    
    å€‹äººç‰¹æ€§åˆ†æã€å­¦ç¿’å±¥æ­´ç®¡ç†ã€å‹•çš„ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.profile_update_threshold = config.get('profile_update_threshold', 0.1)
        self.learning_window_days = config.get('learning_window_days', 30)
----

=== ğŸ“Š ä¸»è¦æ©Ÿèƒ½

==== ğŸ” åŸºæœ¬ç‰¹æ€§åˆ†æ

[source,python]
----
def analyze_basic_characteristics(self, logs: List[BehaviorLog]) -> Dict[str, Any]:
    """åŸºæœ¬ç‰¹æ€§åˆ†æ
    
    Returns:
        - é›†ä¸­ãƒ‘ã‚¿ãƒ¼ãƒ³ç‰¹æ€§
        - æ™‚é–“å¸¯åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        - è¡Œå‹•ä¸€è²«æ€§æŒ‡æ¨™
    """
----

==== ğŸ“ˆ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å‹•çš„æ›´æ–°

[source,python]
----
def update_profile_dynamically(self, user_id: str, 
                             new_logs: List[BehaviorLog]) -> Dict[str, Any]:
    """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å‹•çš„æ›´æ–°
    
    æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¶™ç¶šçš„ã«æ›´æ–°
    """
----

== ğŸ”§ API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

=== ğŸ“¡ é«˜åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æAPI

[source,http]
----
GET /api/analysis/advanced-patterns
----

**Query Parameters:**

[cols="2,2,1,3", options="header"]
|===
|ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ |å‹ |å¿…é ˆ |èª¬æ˜
|`timeframe` |string |âœ… |åˆ†ææœŸé–“ (hourly/daily/weekly/monthly)
|`user_id` |string |âŒ |ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
|`pattern_type` |string |âŒ |ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ— (cyclical/trending/seasonal/all)
|===

**Responseä¾‹:**

[source,json]
----
{
  "status": "success",
  "data": {
    "timeframe": "daily",
    "pattern_type": "all",
    "total_logs": 1440,
    "timeseries_analysis": {
      "seasonality": {
        "detected": true,
        "period": 120,
        "strength": 0.85
      },
      "trends": {
        "focus_trend": "improving",
        "slope": 0.02,
        "r_squared": 0.78
      }
    },
    "pattern_recognition": {
      "cyclical_patterns": [
        {
          "pattern_type": "morning_focus_peak",
          "confidence": 0.92,
          "time_range": [9, 11]
        }
      ]
    }
  }
}
----

=== ğŸ“Š é›†ä¸­åº¦è©³ç´°åˆ†æAPI

[source,http]
----
GET /api/analysis/focus-detailed
----

**Responseä¾‹:**

[source,json]
----
{
  "status": "success",
  "data": {
    "focus_sessions": [
      {
        "start_time": "2024-01-15T09:00:00Z",
        "end_time": "2024-01-15T10:30:00Z",
        "duration_minutes": 90,
        "average_focus": 0.85,
        "focus_level": "HIGH",
        "interruptions": 2,
        "quality_score": 0.88
      }
    ],
    "quality_metrics": {
      "overall_quality": 0.82,
      "consistency_score": 0.75,
      "efficiency_ratio": 0.90
    },
    "recommendations": [
      "åˆå‰ä¸­ã®é«˜é›†ä¸­æ™‚é–“ã‚’æ´»ç”¨ã—ãŸé‡è¦ã‚¿ã‚¹ã‚¯ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã‚’æ¨å¥¨",
      "13:00-15:00ã®é›†ä¸­åº¦ä½ä¸‹æ™‚æœŸã«ã¯è»½ä½œæ¥­ã‚’å‰²ã‚Šå½“ã¦"
    ]
  }
}
----

=== ğŸ¥ å¥åº·è©•ä¾¡API

[source,http]
----
GET /api/analysis/health-assessment
----

**Responseä¾‹:**

[source,json]
----
{
  "status": "success",
  "data": {
    "health_assessment": {
      "posture_score": 0.72,
      "movement_frequency": 0.15,
      "eye_strain_risk": 0.68,
      "overall_risk": "MODERATE"
    },
    "break_recommendations": [
      {
        "type": "posture_break",
        "interval_minutes": 45,
        "duration_minutes": 5
      },
      {
        "type": "eye_rest",
        "interval_minutes": 20,
        "duration_minutes": 2
      }
    ]
  }
}
----

== âš™ï¸ è¨­å®šãƒ»æœ€é©åŒ–

=== ğŸ“‹ åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š

[source,yaml]
----
# config/config.yaml - è¡Œå‹•åˆ†æé–¢é€£è¨­å®š

advanced_analyzer:
  # é›†ä¸­åº¦é–¾å€¤è¨­å®š
  focus_threshold_high: 0.8
  focus_threshold_medium: 0.6
  focus_threshold_low: 0.4
  
  # å¥åº·è©•ä¾¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
  max_sitting_minutes: 60
  min_movement_frequency: 0.1
  eye_strain_threshold: 45
  
  # ç”Ÿç”£æ€§é‡ã¿ä»˜ã‘
  productivity_weights:
    focus_consistency: 0.3
    efficiency: 0.25
    break_timing: 0.2
    distraction_control: 0.25

pattern_recognizer:
  # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è¨­å®š
  clustering:
    algorithm: "kmeans"  # kmeans, dbscan
    n_clusters: 5
    min_samples: 10
  
  # ãƒ‘ã‚¿ãƒ¼ãƒ³é–¾å€¤
  pattern_thresholds:
    cyclical_confidence: 0.7
    trend_significance: 0.05
    anomaly_threshold: 2.0

user_profile_builder:
  # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°è¨­å®š
  profile_update_threshold: 0.1
  learning_window_days: 30
  adaptation_rate: 0.05
----

=== ğŸ”§ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

==== ğŸ“Š ãƒ‡ãƒ¼ã‚¿å‡¦ç†æœ€é©åŒ–

[source,python]
----
# ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥
class AdvancedBehaviorAnalyzer:
    def __init__(self, config: Dict[str, Any]):
        # åˆ†æã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.analysis_cache = {}
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³å±¥æ­´ï¼ˆå¾ªç’°ãƒãƒƒãƒ•ã‚¡ï¼‰
        self.pattern_history = deque(maxlen=1000)
        
        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
        self._setup_memory_optimization()
----

==== âš¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†ææœ€é©åŒ–

[source,python]
----
def _optimize_realtime_analysis(self):
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æã®æœ€é©åŒ–"""
    
    # ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«åˆ†æ
    # å…¨ãƒ‡ãƒ¼ã‚¿å†è¨ˆç®—ã‚’é¿ã‘ã€æ–°ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å‡¦ç†
    
    # ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹åŠ¹ç‡åŒ–
    # è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’ã¾ã¨ã‚ã¦å‡¦ç†
    
    # éåŒæœŸå‡¦ç†ã«ã‚ˆã‚‹å¿œç­”æ€§å‘ä¸Š
    # é‡ã„åˆ†æã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
----

== ğŸ“ˆ åˆ†æçµæœã®æ´»ç”¨

=== ğŸ¯ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æãƒ•ãƒ­ãƒ¼

[mermaid]
....
sequenceDiagram
    participant Frontend as ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
    participant WebSocket as WebSocket
    participant Analyzer as åˆ†æã‚¨ãƒ³ã‚¸ãƒ³
    participant Cache as ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    participant DB as ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
    
    Frontend->>WebSocket: åˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    WebSocket->>Analyzer: analyze_real_time()
    
    alt ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ
        Analyzer->>Cache: get_cached_result()
        Cache-->>Analyzer: cached_data
    else ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹
        Analyzer->>DB: get_recent_logs()
        DB-->>Analyzer: behavior_logs
        Analyzer->>Analyzer: perform_analysis()
        Analyzer->>Cache: cache_result()
    end
    
    Analyzer-->>WebSocket: analysis_result
    WebSocket-->>Frontend: real_time_update
....

=== ğŸ“Š åˆ†æçµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

==== ğŸ“‹ åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

[source,python]
----
def generate_comprehensive_report(self, logs: List[BehaviorLog], 
                                timeframe: str = "daily") -> Dict[str, Any]:
    """åŒ…æ‹¬çš„åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    
    # å„ç¨®åˆ†æã®å®Ÿè¡Œ
    timeseries_analysis = self.analyze_time_series_patterns(logs, timeframe)
    focus_analysis = self.analyze_focus_detailed(logs)
    health_analysis = self.analyze_health_assessment(logs)
    activity_analysis = self.analyze_activity_patterns(logs)
    
    # çµ±åˆè©•ä¾¡ã‚¹ã‚³ã‚¢ç®—å‡º
    overall_score = self._calculate_overall_score(
        focus_analysis, health_analysis, activity_analysis
    )
    
    # å„ªå…ˆåº¦ä»˜ãæ¨å¥¨äº‹é …ç”Ÿæˆ
    prioritized_recommendations = self._generate_prioritized_recommendations(
        focus_analysis, health_analysis, activity_analysis
    )
    
    return {
        'executive_summary': executive_summary,
        'overall_score': overall_score,
        'detailed_analysis': {
            'timeseries': timeseries_analysis,
            'focus': focus_analysis,
            'health': health_analysis,
            'activity': activity_analysis
        },
        'recommendations': prioritized_recommendations
    }
----

=== ğŸ¯ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ

[source,python]
----
def _generate_prioritized_recommendations(self, focus_analysis, 
                                        health_analysis, activity_analysis):
    """å„ªå…ˆåº¦ä»˜ãæ¨å¥¨äº‹é …ç”Ÿæˆ"""
    
    recommendations = []
    
    # å¥åº·ãƒªã‚¹ã‚¯ãŒæœ€å„ªå…ˆ
    if health_analysis['health_assessment']['overall_risk'] == 'HIGH':
        recommendations.append({
            'priority': 'CRITICAL',
            'category': 'health',
            'action': 'å³åº§ã«ä¼‘æ†©ã‚’å–ã‚Šã€å§¿å‹¢ã‚’æ”¹å–„ã—ã¦ãã ã•ã„',
            'reason': 'é•·æ™‚é–“ã®ä¸è‰¯å§¿å‹¢ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ'
        })
    
    # é›†ä¸­åº¦æ”¹å–„ææ¡ˆ
    if focus_analysis['quality_metrics']['overall_quality'] < 0.6:
        recommendations.append({
            'priority': 'HIGH',
            'category': 'productivity',
            'action': 'é›†ä¸­æ™‚é–“å¸¯ã®æ´»ç”¨ã‚’æ¨å¥¨',
            'reason': 'åˆå‰ä¸­ã®é›†ä¸­åº¦ãŒæœ€ã‚‚é«˜ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™'
        })
    
    return recommendations
----

== ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ»æ¤œè¨¼

=== ğŸ”¬ å˜ä½“ãƒ†ã‚¹ãƒˆ

[source,python]
----
import pytest
from unittest.mock import Mock, patch
from services.ai_ml.advanced_behavior_analyzer import AdvancedBehaviorAnalyzer

class TestAdvancedBehaviorAnalyzer:
    
    def test_analyze_time_series_patterns(self):
        """æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã®ãƒ†ã‚¹ãƒˆ"""
        config = {'advanced_analyzer': {}}
        analyzer = AdvancedBehaviorAnalyzer(config)
        
        # ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        mock_logs = self._create_mock_behavior_logs()
        
        # åˆ†æå®Ÿè¡Œ
        result = analyzer.analyze_time_series_patterns(mock_logs, "daily")
        
        # çµæœæ¤œè¨¼
        assert 'seasonality' in result
        assert 'trends' in result
        assert 'patterns' in result
    
    def test_focus_detailed_analysis(self):
        """é›†ä¸­åº¦è©³ç´°åˆ†æã®ãƒ†ã‚¹ãƒˆ"""
        # ãƒ†ã‚¹ãƒˆå®Ÿè£…
        pass
    
    def test_health_assessment(self):
        """å¥åº·è©•ä¾¡åˆ†æã®ãƒ†ã‚¹ãƒˆ"""
        # ãƒ†ã‚¹ãƒˆå®Ÿè£…
        pass
----

=== ğŸ“Š çµ±åˆãƒ†ã‚¹ãƒˆ

[source,python]
----
class TestBehaviorAnalysisIntegration:
    
    def test_end_to_end_analysis_pipeline(self):
        """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        
        # 1. ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        logs = self._generate_realistic_behavior_data()
        
        # 2. å…¨åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã®å®Ÿè¡Œ
        analyzer = AdvancedBehaviorAnalyzer(config)
        recognizer = PatternRecognizer(config)
        profile_builder = UserProfileBuilder(config)
        
        # 3. åˆ†æçµæœã®ä¸€è²«æ€§ç¢ºèª
        analysis_result = analyzer.generate_comprehensive_report(logs)
        pattern_result = recognizer.recognize_temporal_patterns(logs)
        profile_result = profile_builder.analyze_basic_characteristics(logs)
        
        # 4. çµæœçµ±åˆã®ç¢ºèª
        assert self._validate_analysis_consistency(
            analysis_result, pattern_result, profile_result
        )
----

== ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼

=== ğŸ›¡ï¸ ãƒ‡ãƒ¼ã‚¿ä¿è­·

[WARNING]
====
**ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ã®é‡è¦æ€§**

è¡Œå‹•åˆ†æã‚·ã‚¹ãƒ†ãƒ ã¯å€‹äººã®è©³ç´°ãªè¡Œå‹•ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†ãŸã‚ã€ä»¥ä¸‹ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ãŒå¿…é ˆã§ã™ï¼š

* **ãƒ‡ãƒ¼ã‚¿åŒ¿ååŒ–**: å€‹äººè­˜åˆ¥æƒ…å ±ã®é™¤å»
* **æš—å·åŒ–**: ä¿å­˜ãƒ»è»¢é€æ™‚ã®æš—å·åŒ–
* **ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡**: åˆ†æè€…ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
* **ãƒ‡ãƒ¼ã‚¿ä¿æŒæœŸé–“**: å¿…è¦æœ€å°é™ã®æœŸé–“ã®ã¿ä¿æŒ
====

[source,python]
----
class PrivacyProtectedAnalyzer:
    """ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·åˆ†æå™¨"""
    
    def anonymize_behavior_data(self, logs: List[BehaviorLog]) -> List[BehaviorLog]:
        """è¡Œå‹•ãƒ‡ãƒ¼ã‚¿ã®åŒ¿ååŒ–"""
        
        for log in logs:
            # å€‹äººè­˜åˆ¥å¯èƒ½ãªæƒ…å ±ã®é™¤å»
            log.face_landmarks = self._anonymize_face_data(log.face_landmarks)
            log.session_id = self._hash_session_id(log.session_id)
        
        return logs
    
    def encrypt_analysis_results(self, results: Dict[str, Any]) -> str:
        """åˆ†æçµæœã®æš—å·åŒ–"""
        # AESæš—å·åŒ–å®Ÿè£…
        pass
----

== ğŸ“š ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

=== â— ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–

[cols="2,3,3", options="header"]
|===
|å•é¡Œ |åŸå›  |è§£æ±ºç­–
|**åˆ†æçµæœãŒç©º** |ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¾ãŸã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ãŒå³ã—ã™ãã‚‹ |ãƒ‡ãƒ¼ã‚¿æœŸé–“ã‚’æ‹¡å¤§ã€é–¾å€¤ã‚’èª¿æ•´
|**ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡éå¤š** |å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®ä¸€æ‹¬å‡¦ç† |ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã—ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
|**åˆ†æé€Ÿåº¦ãŒé…ã„** |éæœ€é©åŒ–ã‚¯ã‚¨ãƒª |ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç¢ºèªã€ã‚¯ã‚¨ãƒªæœ€é©åŒ–
|**ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ç²¾åº¦ä½ä¸‹** |å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸è¶³ |ãƒ‡ãƒ¼ã‚¿åé›†æœŸé–“ã‚’å»¶é•·ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
|===

=== ğŸ”§ ãƒ‡ãƒãƒƒã‚°æ–¹æ³•

[source,python]
----
# ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ DEBUG ã«è¨­å®š
import logging
logging.getLogger('services.ai_ml.advanced_behavior_analyzer').setLevel(logging.DEBUG)

# åˆ†æãƒ—ãƒ­ã‚»ã‚¹ã®å¯è¦–åŒ–
def debug_analysis_pipeline(logs: List[BehaviorLog]):
    """åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ‡ãƒãƒƒã‚°"""
    
    analyzer = AdvancedBehaviorAnalyzer(config)
    
    # å„ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè¡Œæ™‚é–“æ¸¬å®š
    with timer("data_preparation"):
        df = analyzer._prepare_timeseries_data(logs)
    
    with timer("seasonality_detection"):
        seasonality = analyzer._detect_seasonality(df, "daily")
    
    # ä¸­é–“çµæœã®ç¢ºèª
    logger.debug(f"Processed {len(df)} data points")
    logger.debug(f"Seasonality detected: {seasonality['detected']}")
----

== ğŸ“– å‚è€ƒè³‡æ–™

=== ğŸ”— é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

* <<detection-system.adoc#,ç‰©ä½“ãƒ»å§¿å‹¢æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜æ›¸>>
* <<ai-ml-specifications.adoc#,AI/MLæŠ€è¡“ä»•æ§˜æ›¸>>
* <<rest-api-reference.adoc#,REST API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹>>
* <<database-schema.adoc#,ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒè¨­è¨ˆæ›¸>>

=== ğŸ“š æŠ€è¡“å‚è€ƒæ–‡çŒ®

* YOLOv8 å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: https://docs.ultralytics.com/
* MediaPipe å…¬å¼ã‚¬ã‚¤ãƒ‰: https://mediapipe.dev/
* æ™‚ç³»åˆ—åˆ†ææ‰‹æ³•: å­£ç¯€æ€§åˆ†è§£ã€å¤‰åŒ–ç‚¹æ¤œå‡º
* æ©Ÿæ¢°å­¦ç¿’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°: K-means, DBSCAN

=== ğŸ¤ é–‹ç™ºãƒãƒ¼ãƒ ã‚³ãƒ³ã‚¿ã‚¯ãƒˆ

[cols="2,3", options="header"]
|===
|å½¹å‰² |é€£çµ¡å…ˆ
|**AI/MLã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ** |ai-architect@kanshichan.dev
|**ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ** |data-scientist@kanshichan.dev
|**æŠ€è¡“ã‚µãƒãƒ¼ãƒˆ** |tech-support@kanshichan.dev
|===

---

**ğŸ“ Contact**: ai-team@kanshichan.dev +
**ğŸ”— Repository**: https://github.com/kanshichan/backend +
**ğŸ“… Last Updated**: {docdate} +
**ğŸ“ Document Version**: {revnumber}