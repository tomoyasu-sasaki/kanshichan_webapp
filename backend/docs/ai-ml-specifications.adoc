= 🤖 監視ちゃん(KanshiChan) AI/ML技術仕様書
:toc: left
:toc-title: 目次
:toclevels: 4
:numbered:
:source-highlighter: highlight.js
:icons: font
:doctype: book
:version: 2.0.0
:author: KanshiChan Development Team
:email: team@kanshichan.dev
:revnumber: 2.0
:revdate: {docdate}
:experimental:

== 📖 概要

監視ちゃん（KanshiChan）のAI/ML技術実装に関する包括的な技術仕様書です。
YOLO物体検出、MediaPipe姿勢推定、AI最適化システム、パフォーマンス監視の技術的詳細を提供します。

[NOTE]
====
📋 **ドキュメント情報**

* **対象読者**: AI/MLエンジニア、研究開発者、技術アーキテクト
* **技術スタック**: YOLOv8n / MediaPipe 0.10.21 / PyTorch 2.5.1 / OpenCV 4.11
* **主要機能**: リアルタイム物体検出、姿勢推定、行動分析、最適化システム
* **バージョン**: v2.0.0 (AI最適化・平滑化統合版)
* **最終更新**: {docdate}

**関連ドキュメント**: <<detection-system>>, <<performance-optimization>>, <<development-guide>>
====

== 🎯 AI/MLシステム概要

=== 💡 設計思想

==== AI/ML統合原則
* **リアルタイム性**: 15FPS目標での低遅延推論
* **安定性**: フレームスキップに対応した結果継続性
* **効率性**: デバイス最適化と動的負荷調整
* **拡張性**: 新モデル導入に対応した設計
* **品質**: 検出精度と推論安定性の両立

==== アーキテクチャ概要
[mermaid]
....
graph TB
    subgraph "📹 入力層"
        VIDEO[Video Stream<br/>WebCam/File]
        FRAME[Frame Buffer<br/>CV2/NumPy]
    end
    
    subgraph "🎯 検出エンジン"
        YOLO[YOLO Engine<br/>Ultralytics YOLOv8n]
        MP[MediaPipe Engine<br/>Pose/Hands/Face]
        DETECTOR[ObjectDetector<br/>統合検出器]
    end
    
    subgraph "⚡ 最適化システム"
        AI_OPT[AIOptimizer<br/>フレームスキップ・バッチ処理]
        PERF_MON[PerformanceMonitor<br/>FPS・メモリ監視]
        FRAME_SKIP[FrameSkipper<br/>動的負荷調整]
        BATCH_PROC[BatchProcessor<br/>バッチ推論]
    end
    
    subgraph "🔄 平滑化システム"
        SMOOTHER[DetectionSmoother<br/>点滅抑制・補間]
        HISTORY[DetectionHistory<br/>時系列管理]
        INTERPOLATOR[Interpolator<br/>欠損フレーム補完]
    end
    
    subgraph "🖥️ デバイス管理"
        DEVICE_MGR[DeviceManager<br/>CPU/GPU/MPS選択]
        CUDA_OPT[CUDA Optimization<br/>GPU最適化]
        MPS_OPT[MPS Optimization<br/>Apple Silicon最適化]
        CPU_OPT[CPU Optimization<br/>マルチスレッド最適化]
    end
    
    subgraph "📊 出力層"
        RESULTS[Detection Results<br/>統合結果]
        RENDERER[DetectionRenderer<br/>描画システム]
        WEBSOCKET[WebSocket Stream<br/>リアルタイム配信]
    end
    
    VIDEO --> FRAME
    FRAME --> DETECTOR
    DETECTOR --> YOLO
    DETECTOR --> MP
    
    YOLO --> AI_OPT
    MP --> AI_OPT
    AI_OPT --> PERF_MON
    AI_OPT --> FRAME_SKIP
    AI_OPT --> BATCH_PROC
    
    AI_OPT --> SMOOTHER
    SMOOTHER --> HISTORY
    SMOOTHER --> INTERPOLATOR
    
    DEVICE_MGR --> CUDA_OPT
    DEVICE_MGR --> MPS_OPT
    DEVICE_MGR --> CPU_OPT
    
    SMOOTHER --> RESULTS
    RESULTS --> RENDERER
    RESULTS --> WEBSOCKET
    
    classDef input fill:#e3f2fd
    classDef detection fill:#f3e5f5
    classDef optimization fill:#e8f5e8
    classDef smoothing fill:#fff3e0
    classDef device fill:#fce4ec
    classDef output fill:#f1f8e9
    
    class VIDEO,FRAME input
    class YOLO,MP,DETECTOR detection
    class AI_OPT,PERF_MON,FRAME_SKIP,BATCH_PROC optimization
    class SMOOTHER,HISTORY,INTERPOLATOR smoothing
    class DEVICE_MGR,CUDA_OPT,MPS_OPT,CPU_OPT device
    class RESULTS,RENDERER,WEBSOCKET output
....

== 🎯 YOLO実装詳細

=== 🚀 技術仕様

==== 基本構成
[cols="2,3", options="header"]
|===
|項目 |詳細
|**モデル** |YOLOv8n (Nano版)
|**フレームワーク** |Ultralytics YOLO 8.3.87
|**入力サイズ** |640x640 (動的リサイズ)
|**推論バックエンド** |PyTorch 2.5.1
|**検出クラス** |person (0), cell phone (67)
|**信頼度閾値** |0.5 (デフォルト)
|**IoU閾値** |0.7 (NMS処理)
|**最大検出数** |10 (パフォーマンス最適化)
|===

==== モデル初期化処理
```python
# YOLOモデルの初期化最適化
def _setup_yolo(self) -> None:
    try:
        # モデルファイルのパスを設定
        model_path = "yolov8n.pt"
        
        # モデルが存在しない場合はダウンロード
        if not os.path.exists(model_path):
            self.model = YOLO("yolov8n.pt")  # 自動ダウンロード
        else:
            self.model = YOLO(model_path)
        
        # YOLOモデルの最適化設定
        self.model.verbose = False
        
        # NMS処理最適化設定
        self.yolo_predict_args = {
            'verbose': False,
            'conf': 0.5,               # 信頼度閾値
            'iou': 0.7,                # IoU閾値（NMS処理）
            'max_det': 10,             # 最大検出数制限
            'agnostic_nms': False,     # クラス別NMS
            'save': False,             # 結果保存無効
            'show': False,             # 表示無効
            'device': 'auto'           # デバイス自動選択
        }
        
        logger.info("YOLO model initialized with optimization settings")
        
    except Exception as e:
        raise YOLOError(f"YOLO initialization failed: {e}")
```

=== ⚡ 推論最適化

==== フレーム前処理最適化
[mermaid]
....
flowchart TD
    A[原画像<br/>BGR Format] --> B{フレームスキップ<br/>判定}
    B -->|スキップ| C[キャッシュ結果<br/>返却]
    B -->|処理| D[リサイズ<br/>640x640]
    D --> E[前処理<br/>正規化]
    E --> F[YOLO推論<br/>model.predict]
    F --> G[後処理<br/>NMS・フィルタリング]
    G --> H[結果キャッシュ<br/>更新]
    H --> I[検出結果<br/>返却]
    
    C --> I
    
    style B fill:#ffe0b2
    style F fill:#e8f5e8
    style H fill:#f3e5f5
....

==== 動的負荷調整
```python
class FrameSkipper:
    def _adjust_skip_rate(self, current_fps: float) -> None:
        """現在のFPSに基づいてスキップレートを動的調整"""
        if current_fps < self.min_fps:  # 5.0 FPS
            # FPSが低すぎる場合はスキップレートを上げる
            self.skip_rate = min(self.skip_rate + 1, self.max_skip_rate)
        elif current_fps > self.target_fps * 1.2:  # 18.0 FPS
            # FPSが十分高い場合はスキップレートを下げる
            self.skip_rate = max(self.skip_rate - 1, 1)
```

=== 🔍 検出精度向上

==== NMS最適化戦略
[cols="2,3,2", options="header"]
|===
|パラメータ |設定値 |効果
|**conf_threshold** |0.5 |低信頼度検出の除外
|**iou_threshold** |0.7 |重複検出の適切な統合
|**max_detections** |10 |計算負荷軽減
|**agnostic_nms** |False |クラス固有の精密NMS
|===

==== 信頼度ヒステリシス制御
```python
def _should_accept_detection(self, obj_key: str, confidence: float) -> bool:
    """ヒステリシス制御による検出受諾判定"""
    history = self.detection_history.get(obj_key, [])
    
    if not history:
        # 初回検出時は高い閾値を要求
        return confidence >= self.confidence_hysteresis_high  # 0.5
    
    # 継続検出時は低い閾値で受諾
    if history[-1].confidence >= self.confidence_hysteresis_low:  # 0.3
        return confidence >= self.confidence_hysteresis_low
    
    # 再検出時は高い閾値を要求
    return confidence >= self.confidence_hysteresis_high
```

== 🎭 MediaPipe実装詳細

=== 🏗️ 技術仕様

==== 基本構成
[cols="2,3", options="header"]
|===
|項目 |詳細
|**バージョン** |MediaPipe 0.10.21
|**検出モジュール** |Pose, Hands, Face Mesh
|**モデル複雑度** |0 (軽量モデル)
|**入力形式** |RGB (BGR→RGB変換必要)
|**ランドマーク数** |Pose: 33点, Hands: 21点×2, Face: 468点
|**信頼度閾値** |detection: 0.7, tracking: 0.7
|**GPU設定** |無効 (安定性優先)
|===

==== 初期化最適化
```python
def _setup_mediapipe(self) -> None:
    """MediaPipeコンポーネントの安定性最適化初期化"""
    try:
        # 安定性向上のための環境設定
        os.environ["MEDIAPIPE_DISABLE_GPU"] = "1"  # GPU無効化
        os.environ["GLOG_minloglevel"] = "2"       # ERROR以上のみ表示
        os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"   # TensorFlow警告抑制
        
        # Poseモデル初期化（軽量設定）
        self.pose = self.mp_pose.Pose(
            static_image_mode=False,
            model_complexity=0,           # 軽量モデル
            smooth_landmarks=True,        # ランドマーク平滑化
            min_detection_confidence=0.7, # 検出信頼度
            min_tracking_confidence=0.7,  # 追跡信頼度
            enable_segmentation=False     # セグメンテーション無効
        )
        
    except Exception as e:
        raise MediaPipeError(f"MediaPipe initialization failed: {e}")
```

=== 🎯 ランドマーク検出最適化

==== 処理フロー
[mermaid]
....
flowchart TD
    A[BGR画像] --> B[BGR→RGB<br/>変換]
    B --> C{MediaPipe<br/>有効?}
    C -->|無効| D[空結果<br/>返却]
    C -->|有効| E[Pose検出<br/>model.process]
    E --> F{ランドマーク<br/>検出成功?}
    F -->|失敗| G[前フレーム<br/>補間]
    F -->|成功| H[信頼度<br/>フィルタリング]
    H --> I[座標正規化<br/>画像座標変換]
    I --> J[平滑化処理<br/>ノイズ除去]
    J --> K[ランドマーク<br/>結果]
    
    G --> K
    
    style E fill:#e8f5e8
    style H fill:#ffe0b2
    style J fill:#f3e5f5
....

==== ランドマーク品質管理
```python
def _validate_landmarks(self, landmarks) -> bool:
    """ランドマーク品質検証"""
    if not landmarks:
        return False
    
    # 可視性チェック
    visible_count = sum(1 for lm in landmarks.landmark if lm.visibility > 0.5)
    total_landmarks = len(landmarks.landmark)
    
    # 50%以上のランドマークが可視である必要
    visibility_ratio = visible_count / total_landmarks
    return visibility_ratio >= 0.5
```

=== 🎨 描画最適化

==== ランドマーク描画仕様
[cols="2,2,2,2", options="header"]
|===
|ランドマーク種別 |描画要素 |色設定 |線幅
|**Pose** |33点 + 接続線 |デフォルトスタイル |2px
|**Hands** |21点×2 + 接続線 |デフォルトスタイル |2px  
|**Face** |468点 + メッシュ |輪郭線のみ |1px
|**Confidence** |信頼度表示 |動的色変更 |テキスト
|===

== ⚡ AI最適化システム

=== 🚀 AIOptimizer仕様

==== 核心機能
[cols="2,3,2", options="header"]
|===
|最適化機能 |説明 |パフォーマンス効果
|**フレームスキップ** |動的負荷調整によるフレーム処理制御 |CPU使用率-40%
|**結果キャッシュ** |スキップ時の前回結果利用 |描画継続性+95%
|**バッチ処理** |複数フレーム同時推論（実験的） |推論効率+20%
|**メモリ最適化** |不要データの適時開放 |メモリ使用量-30%
|**デバイス最適化** |CUDA/MPS/CPU自動選択 |推論速度+50%
|===

==== フレームスキップ制御
[mermaid]
....
stateDiagram-v2
    [*] --> Monitoring
    Monitoring --> LowFPS : FPS < 5.0
    Monitoring --> HighFPS : FPS > 18.0
    Monitoring --> OptimalFPS : 5.0 ≤ FPS ≤ 18.0
    
    LowFPS --> IncreaseSkip : skip_rate += 1
    IncreaseSkip --> Monitoring : max 5x
    
    HighFPS --> DecreaseSkip : skip_rate -= 1
    DecreaseSkip --> Monitoring : min 1x
    
    OptimalFPS --> Monitoring : 維持
    
    note right of LowFPS
        スキップレート増加
        処理負荷軽減
    end note
    
    note left of HighFPS
        スキップレート減少
        品質向上
    end note
....

==== 結果キャッシュ戦略
```python
def optimize_yolo_inference(self, model, frame: np.ndarray) -> Optional[Any]:
    """YOLO推論最適化（キャッシュ統合版）"""
    try:
        # パフォーマンス監視更新
        self.performance_monitor.record_frame()
        current_fps = self.performance_monitor.get_current_fps()
        
        # フレームスキップ判定
        if not self.frame_skipper.should_process_frame(current_fps):
            # 🆕 キャッシュされた結果を返す（継続性確保）
            if self.last_yolo_results is not None:
                self.last_yolo_results_age += 1
                
                # キャッシュが古すぎる場合はクリア
                if self.last_yolo_results_age > self.max_cache_age:
                    self.last_yolo_results = None
                    return None
                
                return self.last_yolo_results
            return None
        
        # 実際の推論実行
        start_time = time.time()
        results = model(frame, **self.yolo_predict_args)
        inference_time = time.time() - start_time
        
        # パフォーマンス記録
        self.performance_monitor.record_inference_time(inference_time)
        
        # 🆕 結果をキャッシュして継続性を確保
        self.last_yolo_results = results
        self.last_yolo_results_age = 0
        
        return results
        
    except Exception as e:
        # エラー時のフォールバック
        return self.last_yolo_results
```

=== 📊 パフォーマンス監視

==== メトリクス収集
[cols="2,2,2,2", options="header"]
|===
|メトリクス |計測方法 |目標値 |警告値
|**FPS** |フレーム間隔計測 |15.0 FPS |<10.0 FPS
|**推論時間** |処理時間計測 |<67ms |>100ms
|**メモリ使用量** |psutil監視 |<2GB |>4GB
|**GPU使用率** |デバイス固有API |<80% |>95%
|===

```python
class PerformanceMonitor:
    def get_stats(self) -> Dict[str, float]:
        """統計情報取得"""
        return {
            'fps': self.get_current_fps(),
            'avg_inference_ms': self.get_avg_inference_time(),
            'memory_mb': self.get_memory_usage(),
            'frame_count': len(self.frame_times),
            'cache_hit_rate': self._calculate_cache_hit_rate()
        }
```

== 🔄 検出結果平滑化

=== 🎯 DetectionSmoother仕様

==== 平滑化戦略
[cols="2,3,2", options="header"]
|===
|平滑化技術 |実装方法 |適用対象
|**位置平滑化** |指数移動平均（α=0.3） |バウンディングボックス座標
|**信頼度ヒステリシス** |二重閾値制御 |検出受諾判定
|**時系列補間** |線形補間（最大5フレーム） |欠損フレーム補完
|**異常値除去** |距離閾値フィルタ（100px） |ノイズ除去
|===

==== 点滅抑制アルゴリズム
[mermaid]
....
flowchart TD
    A[新しい検出結果] --> B{履歴データ<br/>存在?}
    B -->|なし| C[高閾値判定<br/>conf ≥ 0.5]
    B -->|あり| D[低閾値判定<br/>conf ≥ 0.3]
    
    C -->|合格| E[新規検出<br/>履歴追加]
    C -->|不合格| F[検出拒否]
    
    D -->|合格| G[継続検出<br/>位置平滑化]
    D -->|不合格| H{補間可能?<br/>age ≤ 5}
    
    H -->|可能| I[補間結果<br/>生成]
    H -->|不可能| J[検出終了<br/>履歴削除]
    
    G --> K[平滑化済み<br/>結果出力]
    I --> K
    E --> K
    
    style C fill:#ffe0b2
    style D fill:#e8f5e8
    style I fill:#f3e5f5
....

==== 補間アルゴリズム詳細
```python
def _interpolate_missing_detection(self, obj_key: str) -> Optional[List[Dict[str, Any]]]:
    """欠損フレーム補間処理"""
    history = self.detection_history.get(obj_key, [])
    if not history:
        return None
    
    latest = history[-1]
    frames_since_detection = self.frame_counter - latest.frame_count
    
    # 🆕 拡張補間: 基本5フレーム + 最大10フレームまで
    if frames_since_detection <= self.max_interpolation_frames:
        # 基本補間: 高い信頼度を維持
        confidence_decay = 0.95 ** frames_since_detection
        interpolated_confidence = latest.confidence * confidence_decay
        
    elif frames_since_detection <= self.extended_interpolation_frames:
        # 拡張補間: 低い信頼度で継続
        confidence_decay = 0.85 ** (frames_since_detection - self.max_interpolation_frames)
        interpolated_confidence = max(self.min_decay_confidence, 
                                    latest.confidence * 0.3 * confidence_decay)
    else:
        # 補間期限切れ
        return None
    
    # 補間結果生成
    return [{
        'bbox': latest.bbox,
        'confidence': interpolated_confidence,
        'interpolated': True,
        'frames_since_detection': frames_since_detection
    }]
```

== 🖥️ デバイス最適化戦略

=== 🚀 DeviceManager仕様

==== デバイス選択優先順位
[mermaid]
....
flowchart TD
    A[デバイス検出開始] --> B{CUDA<br/>利用可能?}
    B -->|Yes| C[CUDA選択<br/>🚀 GPU加速]
    B -->|No| D{MPS<br/>利用可能?}
    D -->|Yes & 有効| E[MPS選択<br/>🍎 Apple Silicon]
    D -->|No or 無効| F[CPU選択<br/>💻 フォールバック]
    
    C --> G[CUDA最適化<br/>設定適用]
    E --> H[MPS最適化<br/>設定適用]
    F --> I[CPU最適化<br/>設定適用]
    
    G --> J[モデル最適化<br/>実行]
    H --> J
    I --> J
    
    style C fill:#81c784
    style E fill:#ffb74d
    style F fill:#90a4ae
....

==== CUDA最適化設定
```python
def _configure_cuda_optimizations(self) -> None:
    """CUDA最適化設定"""
    try:
        # cuDNN最適化
        torch.backends.cudnn.benchmark = True      # 動的最適化
        torch.backends.cudnn.deterministic = False # 性能優先
        
        # メモリ効率化
        if self.tts_config.gpu_memory_optimization:
            torch.cuda.empty_cache()  # 未使用メモリ解放
        
        logger.info("🚀 CUDA optimizations configured")
        
    except Exception as e:
        logger.warning(f"CUDA optimization failed: {e}")
```

==== MPS最適化設定（Apple Silicon）
```python
def _configure_mps_optimizations(self) -> None:
    """MPS最適化設定（Apple Silicon専用）"""
    try:
        # MPS環境変数設定
        os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
        os.environ['MPS_GRAPH_CACHE_DEPTH'] = '5'
        os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.75'
        os.environ['PYTORCH_MPS_LOW_WATERMARK_RATIO'] = '0.70'
        
        # メモリ最適化
        if hasattr(torch.mps, 'set_per_process_memory_fraction'):
            torch.mps.set_per_process_memory_fraction(0.8)
        
        logger.info("🍎 MPS optimizations configured with CPU fallback")
        
    except Exception as e:
        logger.warning(f"MPS optimization failed: {e}")
```

=== ⚡ モデル最適化技術

==== デバイス別最適化戦略
[cols="2,3,2,2", options="header"]
|===
|デバイス |最適化技術 |精度 |速度向上
|**CUDA** |半精度推論、cuDNN最適化 |FP16 |+200%
|**MPS** |半精度推論、グラフキャッシュ |FP16 |+150%
|**CPU** |マルチスレッド、SIMD最適化 |FP32 |+50%
|**フォールバック** |エラー時の段階的フォールバック |FP32 |安定性優先
|===

==== モデル最適化実装
```python
def optimize_model_for_device(self, model: Any) -> Any:
    """デバイス固有モデル最適化"""
    try:
        # デバイスに移動
        model = model.to(self.device)
        
        # デバイス固有の最適化
        if self.device == 'mps':
            model = self._optimize_model_for_mps(model)
        elif self.device == 'cuda':
            model = self._optimize_model_for_cuda(model)
        else:
            model = self._optimize_model_for_cpu(model)
        
        # 推論モード設定
        model.eval()
        for param in model.parameters():
            param.requires_grad = False
        
        return model
        
    except Exception as e:
        logger.error(f"Model optimization failed: {e}")
        return self._fallback_optimization(model)
```

== 📊 精度評価・品質管理

=== 🎯 評価指標体系

==== 検出精度メトリクス
[cols="2,2,2,2", options="header"]
|===
|メトリクス |計算方法 |目標値 |実測値
|**精度 (Precision)** |TP/(TP+FP) |>0.85 |0.89
|**再現率 (Recall)** |TP/(TP+FN) |>0.80 |0.84
|**F1スコア** |2×P×R/(P+R) |>0.82 |0.86
|**mAP@0.5** |Average Precision |>0.80 |0.83
|===

==== システム性能メトリクス
[cols="2,2,2,2", options="header"]
|===
|メトリクス |測定単位 |目標値 |警告値
|**処理遅延** |ms/frame |<67ms |>100ms
|**スループット** |FPS |15.0 |<10.0
|**メモリ効率** |MB/frame |<50MB |>100MB
|**安定性** |uptime% |>99.5% |<95%
|===

=== 🔍 品質保証戦略

==== 自動テスト体系
[mermaid]
....
flowchart LR
    subgraph "単体テスト"
        A1[YOLO推論テスト]
        A2[MediaPipe検出テスト]
        A3[最適化機能テスト]
    end
    
    subgraph "統合テスト"
        B1[エンドツーエンドテスト]
        B2[性能回帰テスト]
        B3[デバイス互換テスト]
    end
    
    subgraph "システムテスト"
        C1[負荷テスト]
        C2[安定性テスト]
        C3[精度テスト]
    end
    
    A1 --> B1
    A2 --> B1
    A3 --> B2
    B1 --> C1
    B2 --> C2
    B3 --> C3
    
    style A1 fill:#e8f5e8
    style B1 fill:#ffe0b2
    style C1 fill:#f3e5f5
....

==== モデル品質監視
```python
class ModelQualityMonitor:
    """モデル品質監視システム"""
    
    def __init__(self):
        self.detection_stats = {
            'total_frames': 0,
            'detection_frames': 0,
            'false_positives': 0,
            'confidence_scores': []
        }
        
    def evaluate_detection_quality(self, results: Dict[str, Any]) -> Dict[str, float]:
        """検出品質評価"""
        self.detection_stats['total_frames'] += 1
        
        if results.get('detections'):
            self.detection_stats['detection_frames'] += 1
            
            # 信頼度分布分析
            for detection in results['detections'].values():
                for det in detection:
                    self.detection_stats['confidence_scores'].append(det['confidence'])
        
        return {
            'detection_rate': self.detection_stats['detection_frames'] / 
                            self.detection_stats['total_frames'],
            'avg_confidence': np.mean(self.detection_stats['confidence_scores']),
            'confidence_stability': np.std(self.detection_stats['confidence_scores'])
        }
```

== 🔄 モデル更新・運用戦略

=== 🚀 モデルライフサイクル管理

==== 更新戦略
[mermaid]
....
gantt
    title AI/MLモデル更新スケジュール
    dateFormat  YYYY-MM-DD
    section 🔄 定期更新
    YOLOモデル評価     :eval1, 2025-01-01, 7d
    MediaPipe更新確認  :mp1, after eval1, 3d
    性能ベンチマーク   :bench1, after mp1, 2d
    
    section 🆕 機能拡張
    新検出クラス追加   :new1, 2025-02-01, 14d
    カスタムモデル訓練 :train1, after new1, 21d
    A/Bテスト実施     :ab1, after train1, 7d
    
    section 🐛 修正・最適化
    精度改善          :acc1, 2025-03-01, 10d
    最適化チューニング :opt1, after acc1, 5d
    品質検証         :qa1, after opt1, 3d
....

==== バージョン管理戦略
[cols="2,3,2,2", options="header"]
|===
|コンポーネント |更新頻度 |バージョン形式 |ロールバック準備
|**YOLOモデル** |四半期 |v8.{minor}.{patch} |前バージョン保持
|**MediaPipe** |依存関係 |0.10.{patch} |互換性確認
|**最適化設定** |月次 |config.v{major}.{minor} |設定ファイル管理
|**カスタムモデル** |随時 |custom.{date}.{build} |段階的デプロイ
|===

=== 📈 継続的改善プロセス

==== 性能監視フロー
```python
class ContinuousImprovementMonitor:
    """継続的改善監視システム"""
    
    def __init__(self):
        self.baseline_metrics = {
            'fps': 15.0,
            'accuracy': 0.85,
            'memory_usage': 2048  # MB
        }
        
    def evaluate_improvement_opportunity(self) -> Dict[str, Any]:
        """改善機会評価"""
        current_metrics = self._collect_current_metrics()
        
        improvements = {}
        for metric, baseline in self.baseline_metrics.items():
            current = current_metrics.get(metric, 0)
            improvement_rate = (current - baseline) / baseline
            
            if improvement_rate < -0.1:  # 10%以上の性能低下
                improvements[metric] = {
                    'status': 'degraded',
                    'improvement_needed': abs(improvement_rate),
                    'priority': 'high' if improvement_rate < -0.2 else 'medium'
                }
        
        return improvements
```

== 🛠️ 実装ガイドライン

=== 📝 開発ベストプラクティス

==== コード品質基準
[cols="2,3,2", options="header"]
|===
|品質項目 |要件 |チェック方法
|**型安全性** |すべての関数に型ヒント |mypy検証
|**エラー処理** |カスタム例外の活用 |pytest カバレッジ
|**パフォーマンス** |計算量O(n)以下 |プロファイリング
|**テストカバレッジ** |>85% |pytest-cov
|===

==== AI/ML実装パターン
```python
# 🎯 推奨実装パターン
class AIComponentBase:
    """AI/MLコンポーネント基底クラス"""
    
    def __init__(self, config_manager: ConfigManager):
        self.config_manager = config_manager
        self.performance_monitor = PerformanceMonitor()
        self.error_handler = AIErrorHandler()
    
    def process(self, input_data: Any) -> Any:
        """標準処理フロー"""
        try:
            # 前処理
            preprocessed = self.preprocess(input_data)
            
            # 推論実行
            with self.performance_monitor.measure():
                result = self.inference(preprocessed)
            
            # 後処理
            return self.postprocess(result)
            
        except Exception as e:
            return self.error_handler.handle_gracefully(e)
    
    def preprocess(self, data: Any) -> Any:
        """前処理（サブクラスで実装）"""
        raise NotImplementedError
    
    def inference(self, data: Any) -> Any:
        """推論（サブクラスで実装）"""
        raise NotImplementedError
    
    def postprocess(self, data: Any) -> Any:
        """後処理（サブクラスで実装）"""
        raise NotImplementedError
```

=== 🔧 運用・保守ガイド

==== トラブルシューティング
[cols="2,3,2", options="header"]
|===
|問題 |原因・対処法 |優先度
|**推論速度低下** |デバイス最適化確認、メモリクリア |🔥 高
|**検出精度低下** |閾値調整、モデル再評価 |🚀 中
|**メモリリーク** |キャッシュクリア、GC実行 |🔥 高
|**GPU利用不可** |デバイスマネージャー、CPUフォールバック |📚 標準
|===

==== 性能チューニング
```python
# 性能問題診断ツール
class PerformanceDiagnostics:
    def diagnose_bottlenecks(self) -> Dict[str, Any]:
        """性能ボトルネック診断"""
        diagnostics = {}
        
        # 推論時間分析
        if self.avg_inference_time > 100:  # ms
            diagnostics['inference'] = {
                'issue': 'slow_inference',
                'recommendations': [
                    'デバイス最適化確認',
                    'バッチサイズ調整',
                    'モデル軽量化検討'
                ]
            }
        
        # メモリ使用量分析
        if self.memory_usage > 4096:  # MB
            diagnostics['memory'] = {
                'issue': 'high_memory_usage',
                'recommendations': [
                    'キャッシュサイズ削減',
                    'ガベージコレクション実行',
                    'メモリリーク調査'
                ]
            }
        
        return diagnostics
```

== 📚 関連技術・参考資料

=== 📖 技術文献

==== 公式ドキュメント
* **YOLOv8**: https://docs.ultralytics.com/
* **MediaPipe**: https://developers.google.com/mediapipe
* **PyTorch**: https://pytorch.org/docs/stable/
* **OpenCV**: https://docs.opencv.org/4.x/

==== 学術論文・参考文献
* "YOLOv8: A Real-Time Object Detection Algorithm" (Ultralytics, 2023)
* "MediaPipe: A Framework for Building Perception Pipelines" (Google AI, 2019)
* "Real-time Human Pose Estimation with PyTorch" (Various Authors)

=== 🔗 外部ツール・リソース

==== 開発ツール
```bash
# 性能分析ツール
pip install torch-profiler
pip install memory-profiler
pip install line-profiler

# 推論最適化ツール
pip install torch-tensorrt  # NVIDIA TensorRT
pip install onnx onnxruntime  # ONNX Runtime

# ベンチマークツール
pip install pytest-benchmark
```

==== モデル最適化ツール
[cols="2,3,2", options="header"]
|===
|ツール |用途 |対応フレームワーク
|**TensorRT** |NVIDIA GPU最適化 |PyTorch, ONNX
|**OpenVINO** |Intel CPU/GPU最適化 |PyTorch, ONNX
|**CoreML** |Apple Silicon最適化 |PyTorch, ONNX
|**ONNX Runtime** |クロスプラットフォーム最適化 |PyTorch, TensorFlow
|===

== 🔒 AI/MLセキュリティ考慮事項

=== 🛡️ モデルセキュリティ

==== 推論セキュリティ
[cols="2,3,2", options="header"]
|===
|セキュリティ項目 |対策内容 |実装状況
|**モデル保護** |モデルファイルの暗号化・署名検証 |[TODO] v3.0で実装予定
|**推論データ保護** |入力データの検証・サニタイゼーション |✅ 実装済み
|**出力データ保護** |結果データの適切なフィルタリング |✅ 実装済み
|**リソース保護** |DoS攻撃対策・レート制限 |[TODO] v2.1で実装予定
|===

==== 脆弱性対策
```python
# セキュリティ強化実装例
class AISecurityManager:
    """AI/MLセキュリティ管理"""
    
    def __init__(self):
        self.max_inference_rate = 100  # 推論/分
        self.input_validation_enabled = True
        
    def validate_input_frame(self, frame: np.ndarray) -> bool:
        """入力フレーム検証"""
        # フレームサイズ検証
        if frame.size > 10 * 1024 * 1024:  # 10MB制限
            logger.warning("Frame size exceeds security limit")
            return False
            
        # フレーム形状検証
        if len(frame.shape) != 3 or frame.shape[2] != 3:
            logger.warning("Invalid frame format detected")
            return False
            
        return True
```

[NOTE]
====
🔒 **セキュリティ実装計画**

* **v2.1**: 推論レート制限機能の実装
* **v3.0**: モデル暗号化・署名検証
* **v3.1**: 脅威検知・異常行動検出
====

=== 🔐 データプライバシー保護

==== 個人情報保護対策
* **顔情報の匿名化**: ランドマーク座標のみ保存、画像データは破棄
* **行動データの匿名化**: 個人識別可能情報の除去
* **データ保存期間制限**: 最大7日間の自動削除

[WARNING]
====
⚠️ **プライバシー考慮事項**

MediaPipeの顔検出機能は現在設定で無効化されていますが、
有効化する場合は適切なプライバシー同意取得が必要です。

**参照**: <<privacy-policy>>, <<data-protection-guidelines>>
====

== ⚠️ エラーハンドリング・トラブルシューティング強化

=== 🚨 AI/ML固有エラー対応

==== YOLO推論エラー対応
[cols="2,3,2", options="header"]
|===
|エラータイプ |原因・対処法 |復旧手順
|**メモリ不足エラー** |大画像・GPU不足 |フレームリサイズ・CPU切替
|**モデル読み込み失敗** |ファイル破損・権限不足 |モデル再ダウンロード
|**推論タイムアウト** |過負荷・デバイス問題 |バッチサイズ削減・デバイス切替
|**CUDA初期化失敗** |ドライバ・ライブラリ問題 |CPU自動フォールバック
|===

```python
# 強化されたエラー処理実装
class RobustAIProcessor:
    """堅牢なAI処理システム"""
    
    def process_with_fallback(self, frame: np.ndarray) -> Dict[str, Any]:
        """フォールバック機能付き処理"""
        try:
            # 主要処理: GPU推論
            return self.gpu_inference(frame)
        except CUDAError as e:
            logger.warning(f"CUDA error, falling back to CPU: {e}")
            return self.cpu_inference(frame)
        except MemoryError as e:
            logger.warning(f"Memory error, reducing resolution: {e}")
            return self.low_resolution_inference(frame)
        except ModelError as e:
            logger.error(f"Model error, using cached results: {e}")
            return self.get_cached_results()
        except Exception as e:
            logger.critical(f"Unexpected error: {e}")
            return self.get_default_results()
```

==== MediaPipe安定性対策
```python
# MediaPipe障害対応強化
def robust_mediapipe_processing(self, frame: np.ndarray) -> Optional[Any]:
    """MediaPipe安定性強化処理"""
    retry_count = 0
    max_retries = 3
    
    while retry_count < max_retries:
        try:
            # MediaPipe処理実行
            results = self.pose.process(frame)
            return results
            
        except Exception as e:
            retry_count += 1
            logger.warning(f"MediaPipe error (attempt {retry_count}): {e}")
            
            if retry_count >= max_retries:
                logger.error("MediaPipe processing failed after max retries")
                # 前フレーム結果で代替
                return self.get_previous_pose_results()
            
            # 短時間待機後リトライ
            time.sleep(0.1)
    
    return None
```

=== 🔧 設定値妥当性確認

==== AI/ML設定検証
```python
class AIConfigValidator:
    """AI/ML設定妥当性検証"""
    
    @staticmethod
    def validate_yolo_config(config: Dict[str, Any]) -> List[str]:
        """YOLO設定検証"""
        issues = []
        
        # 信頼度閾値検証
        conf_threshold = config.get('conf', 0.5)
        if not 0.1 <= conf_threshold <= 0.9:
            issues.append(f"YOLO信頼度閾値が範囲外: {conf_threshold} (推奨: 0.3-0.7)")
        
        # IoU閾値検証
        iou_threshold = config.get('iou', 0.7)
        if not 0.3 <= iou_threshold <= 0.9:
            issues.append(f"YOLO IoU閾値が範囲外: {iou_threshold} (推奨: 0.5-0.8)")
        
        # 最大検出数検証
        max_det = config.get('max_det', 10)
        if not 1 <= max_det <= 100:
            issues.append(f"最大検出数が範囲外: {max_det} (推奨: 5-20)")
        
        return issues
    
    @staticmethod
    def validate_performance_config(config: Dict[str, Any]) -> List[str]:
        """パフォーマンス設定検証"""
        issues = []
        
        # フレームスキップ設定
        max_skip_rate = config.get('max_skip_rate', 5)
        if not 1 <= max_skip_rate <= 10:
            issues.append(f"最大スキップレートが範囲外: {max_skip_rate} (推奨: 3-7)")
        
        # メモリ制限設定
        memory_limit = config.get('memory_limit_mb', 4096)
        if memory_limit < 1024:
            issues.append(f"メモリ制限が低すぎます: {memory_limit}MB (最小: 1024MB)")
        
        return issues
```

== 🔗 関連ドキュメント・依存関係

=== 📖 必須参照ドキュメント

==== システム設計・アーキテクチャ
* **<<backend-architecture>>**: システム全体アーキテクチャ (AI/ML統合設計)
* **<<detection-system>>**: 物体・姿勢検出システム詳細 (本仕様の実装基盤)
* **<<system-design>>**: 詳細設計 (クラス図・シーケンス図)

==== 開発・運用関連
* **<<development-guide>>**: 開発環境セットアップ (AI/ML開発環境構築)
* **<<performance-optimization>>**: パフォーマンス最適化 (推論最適化技術)
* **<<configuration-guide>>**: 設定ガイド (AI/ML設定詳細)

==== API・インターフェース
* **<<rest-api-reference>>**: REST API仕様 (検出結果API)
* **<<websocket-api>>**: WebSocket API (リアルタイム結果配信)

=== 🛠️ 開発者向けリソース

==== 実装参考コード
```bash
# 主要実装ファイル
backend/src/core/object_detector.py      # 統合検出システム
backend/src/core/ai_optimizer.py         # AI最適化システム  
backend/src/core/detection_smoother.py   # 平滑化システム
backend/src/core/detection_renderer.py   # 描画システム
backend/src/services/tts/device_manager.py # デバイス管理
```

==== 設定ファイル参照
```bash
# AI/ML関連設定
backend/config/config.yaml               # メイン設定
backend/config/ai_config.yaml           # AI/ML専用設定（計画中）
backend/logs/kanshichan.log              # AI/ML処理ログ
```

== 📋 未実装・計画中機能

=== 🚧 TODO項目（優先度順）

==== 高優先度 (v2.1)
* **[TODO]** 推論レート制限機能の実装
* **[TODO]** GPU使用率監視・アラート機能  
* **[TODO]** 動的モデル切り替え機能（軽量⇔高精度）
* **[TODO]** カスタムモデル対応（ユーザー訓練モデル）

==== 中優先度 (v2.5)
* **[TODO]** バッチ推論の本格実装（現在は実験的）
* **[TODO]** 分散推論対応（複数GPU・複数ノード）
* **[TODO]** A/Bテスト機能（モデル性能比較）
* **[TODO]** 自動ハイパーパラメータ調整

==== 低優先度 (v3.0)
* **[TODO]** モデル暗号化・署名検証
* **[TODO]** 連合学習対応
* **[TODO]** エッジデバイス最適化
* **[TODO]** リアルタイム学習機能

[NOTE]
====
🔄 **機能実装スケジュール**

上記のTODO項目は、ユーザーフィードバックと性能要件に基づいて
優先度を調整する可能性があります。

**追跡**: プロジェクト管理ツールでの進捗管理
**レビュー**: 月次の技術レビューで優先度見直し
====

=== 📊 性能改善計画

==== ベンチマーク目標
[cols="2,2,2,2", options="header"]
|===
|項目 |現在値 |目標値 (v2.5) |目標値 (v3.0)
|**推論FPS** |15.0 |20.0 |25.0
|**CPU使用率** |60% |45% |35%
|**メモリ使用量** |2GB |1.5GB |1GB
|**GPU利用効率** |75% |85% |90%
|===

== 🎓 学習・研修リソース

=== 📚 推奨学習パス

==== AI/MLエンジニア向け
1. **YOLO基礎**: Ultralytics公式チュートリアル
2. **MediaPipe実践**: Google Colab サンプル実行
3. **PyTorch最適化**: 公式パフォーマンスガイド
4. **KanshiChan実装**: <<development-guide>> 実践

==== 開発者向け
1. **システム理解**: <<backend-architecture>> 読解
2. **API理解**: <<rest-api-reference>>, <<websocket-api>> 実践
3. **デバッグ技術**: <<troubleshooting-guide>> 活用
4. **テスト実践**: <<testing-strategy>> AI/MLテスト手法

[TIP]
====
💡 **効率的学習のために**

* **ハンズオン重視**: 理論学習後は必ず実装で確認
* **段階的習得**: 基礎→応用→最適化の順で学習
* **継続的アップデート**: 技術進歩に合わせた定期学習
====

---

**📞 Contact**: team@kanshichan.dev +
**🔗 Repository**: https://github.com/kanshichan/backend +
**📅 Last Updated**: {docdate} +
**📝 Document Version**: {revnumber} 