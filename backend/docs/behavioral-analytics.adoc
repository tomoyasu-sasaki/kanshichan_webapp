= 🧠 監視ちゃん(KanshiChan) 行動分析エンジン
:toc: left
:toc-title: 目次
:toclevels: 3
:numbered:
:source-highlighter: highlight.js
:icons: font
:doctype: book
:author: KanshiChan Development Team
:email: team@kanshichan.dev
:revnumber: 1.0
:revdate: {docdate}
:experimental:

[NOTE]
====
📋 **ドキュメント情報**

* **作成者**: KanshiChan Development Team
* **最終更新日**: {docdate}
* **対象読者**: データサイエンティスト、AI/MLエンジニア、システムアーキテクト
* **前提知識**: 機械学習、時系列分析、行動パターン分析
* **関連ドキュメント**: <<ai-ml-specifications.adoc>>, <<detection-system.adoc>>, <<behavior-analysis.adoc>>
====

== 📖 概要

監視ちゃん（KanshiChan）の行動分析エンジンは、ユーザーの作業パターン、集中状態、デバイス使用行動を学習・分析し、
個人最適化されたフィードバックと予測を提供するAIシステムです。

=== 🎯 分析目標

* **集中パターン学習**: 個人の最適な作業リズム発見
* **予測分析**: 集中度低下・中断の事前予測
* **行動最適化**: データ駆動による習慣改善提案
* **パーソナライゼーション**: 個人特性に適応した支援

== 🏗️ アーキテクチャ概要

=== システム全体構成

[mermaid]
....
graph TB
    subgraph "データ収集層"
        DETECT[物体検出<br/>YOLO + MediaPipe]
        SENSOR[センサーデータ<br/>カメラ・音声]
        USER[ユーザー入力<br/>設定・フィードバック]
    end
    
    subgraph "前処理層"
        CLEAN[データクリーニング]
        FEATURE[特徴量抽出]
        NORMAL[正規化・標準化]
    end
    
    subgraph "分析エンジン"
        PATTERN[パターン分析]
        PREDICT[予測モデル]
        CLUSTER[クラスタリング]
        ANOMALY[異常検知]
    end
    
    subgraph "学習層"
        ONLINE[オンライン学習]
        BATCH[バッチ学習]
        TRANSFER[転移学習]
    end
    
    subgraph "出力層"
        INSIGHT[インサイト生成]
        RECOMMEND[レコメンド]
        ALERT[アラート生成]
        VISUAL[可視化]
    end
    
    subgraph "フィードバック"
        FEEDBACK[ユーザーフィードバック]
        ADAPT[適応学習]
    end
    
    DETECT --> CLEAN
    SENSOR --> CLEAN
    USER --> CLEAN
    
    CLEAN --> FEATURE
    FEATURE --> NORMAL
    
    NORMAL --> PATTERN
    NORMAL --> PREDICT
    NORMAL --> CLUSTER
    NORMAL --> ANOMALY
    
    PATTERN --> ONLINE
    PREDICT --> BATCH
    CLUSTER --> TRANSFER
    
    ONLINE --> INSIGHT
    BATCH --> RECOMMEND
    TRANSFER --> ALERT
    ANOMALY --> VISUAL
    
    INSIGHT --> FEEDBACK
    RECOMMEND --> FEEDBACK
    ALERT --> FEEDBACK
    VISUAL --> FEEDBACK
    
    FEEDBACK --> ADAPT
    ADAPT --> ONLINE
....

=== データフロー

**リアルタイム分析パイプライン**
```python
# src/services/analysis/realtime_pipeline.py
import asyncio
import numpy as np
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import pandas as pd

@dataclass
class BehaviorEvent:
    """行動イベント"""
    timestamp: datetime
    event_type: str  # 'presence', 'smartphone_use', 'posture_change'
    confidence: float
    duration: Optional[float] = None
    metadata: Optional[Dict] = None

@dataclass
class AnalysisResult:
    """分析結果"""
    timestamp: datetime
    focus_score: float  # 0-100
    stress_level: float  # 0-100
    productivity_index: float  # 0-100
    predicted_break_time: Optional[datetime]
    recommendations: List[str]

class RealtimeAnalyticsPipeline:
    """リアルタイム行動分析パイプライン"""
    
    def __init__(self, config_manager):
        self.config_manager = config_manager
        self.event_buffer: List[BehaviorEvent] = []
        self.buffer_size = 1000
        self.analysis_window = timedelta(minutes=10)
        
        # 分析コンポーネント
        self.focus_analyzer = FocusAnalyzer()
        self.pattern_detector = PatternDetector()
        self.predictor = BehaviorPredictor()
        
    async def process_detection_event(self, detection_data: Dict) -> Optional[AnalysisResult]:
        """検出イベントの処理"""
        # 検出データから行動イベント生成
        event = self._create_behavior_event(detection_data)
        
        # バッファに追加
        self._add_to_buffer(event)
        
        # 分析実行（一定間隔）
        if self._should_analyze():
            return await self._analyze_current_window()
            
        return None
        
    def _create_behavior_event(self, detection_data: Dict) -> BehaviorEvent:
        """検出データから行動イベント生成"""
        timestamp = datetime.now()
        
        # 人物検出状態
        person_detected = detection_data.get('person_detected', False)
        smartphone_detected = detection_data.get('smartphone_detected', False)
        
        if not person_detected:
            return BehaviorEvent(
                timestamp=timestamp,
                event_type='absence',
                confidence=detection_data.get('confidence', 0.0)
            )
        elif smartphone_detected:
            return BehaviorEvent(
                timestamp=timestamp,
                event_type='smartphone_use',
                confidence=detection_data.get('smartphone_confidence', 0.0),
                metadata={'device_angle': detection_data.get('device_angle')}
            )
        else:
            return BehaviorEvent(
                timestamp=timestamp,
                event_type='focused_work',
                confidence=detection_data.get('confidence', 0.0),
                metadata={'posture': detection_data.get('posture_info')}
            )
            
    async def _analyze_current_window(self) -> AnalysisResult:
        """現在のウィンドウデータを分析"""
        window_events = self._get_analysis_window()
        
        # 各種分析の並行実行
        focus_task = asyncio.create_task(self.focus_analyzer.analyze(window_events))
        pattern_task = asyncio.create_task(self.pattern_detector.detect_patterns(window_events))
        prediction_task = asyncio.create_task(self.predictor.predict_next_behavior(window_events))
        
        focus_score = await focus_task
        patterns = await pattern_task
        predictions = await prediction_task
        
        return AnalysisResult(
            timestamp=datetime.now(),
            focus_score=focus_score,
            stress_level=self._calculate_stress_level(window_events, patterns),
            productivity_index=self._calculate_productivity(window_events),
            predicted_break_time=predictions.get('next_break'),
            recommendations=self._generate_recommendations(focus_score, patterns)
        )
```

== 🔍 行動パターン分析

=== パターン検出アルゴリズム

**時系列パターン分析**
```python
# src/services/analysis/pattern_detector.py
import numpy as np
import pandas as pd
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
from typing import Dict, List, Tuple
import matplotlib.pyplot as plt
from datetime import datetime, timedelta

class PatternDetector:
    """行動パターン検出器"""
    
    def __init__(self):
        self.scaler = StandardScaler()
        self.cluster_model = DBSCAN(eps=0.3, min_samples=5)
        self.pattern_history = []
        
    async def detect_patterns(self, events: List[BehaviorEvent]) -> Dict[str, Any]:
        """行動パターンの検出"""
        if len(events) < 10:
            return {'patterns': [], 'confidence': 0.0}
            
        # 特徴量抽出
        features = self._extract_temporal_features(events)
        
        # パターンクラスタリング
        clusters = await self._cluster_behaviors(features)
        
        # パターン解釈
        interpreted_patterns = self._interpret_clusters(clusters, events)
        
        return {
            'patterns': interpreted_patterns,
            'confidence': self._calculate_pattern_confidence(interpreted_patterns),
            'dominant_pattern': self._find_dominant_pattern(interpreted_patterns)
        }
        
    def _extract_temporal_features(self, events: List[BehaviorEvent]) -> np.ndarray:
        """時系列特徴量抽出"""
        df = pd.DataFrame([{
            'timestamp': event.timestamp,
            'event_type': event.event_type,
            'confidence': event.confidence,
            'hour': event.timestamp.hour,
            'minute': event.timestamp.minute,
            'weekday': event.timestamp.weekday()
        } for event in events])
        
        # 時間ベース特徴量
        features = []
        
        for _, event in df.iterrows():
            # 基本特徴量
            base_features = [
                event['hour'] / 24.0,  # 時刻正規化
                event['minute'] / 60.0,  # 分正規化
                event['weekday'] / 7.0,  # 曜日正規化
                event['confidence']
            ]
            
            # イベントタイプOne-Hot
            event_one_hot = [
                1.0 if event['event_type'] == 'focused_work' else 0.0,
                1.0 if event['event_type'] == 'smartphone_use' else 0.0,
                1.0 if event['event_type'] == 'absence' else 0.0
            ]
            
            features.append(base_features + event_one_hot)
            
        return np.array(features)
        
    async def _cluster_behaviors(self, features: np.ndarray) -> np.ndarray:
        """行動クラスタリング"""
        # 正規化
        features_scaled = self.scaler.fit_transform(features)
        
        # DBSCAN クラスタリング
        cluster_labels = self.cluster_model.fit_predict(features_scaled)
        
        return cluster_labels
        
    def _interpret_clusters(self, clusters: np.ndarray, events: List[BehaviorEvent]) -> List[Dict]:
        """クラスター解釈"""
        unique_clusters = np.unique(clusters)
        interpreted_patterns = []
        
        for cluster_id in unique_clusters:
            if cluster_id == -1:  # ノイズクラスター
                continue
                
            cluster_events = [events[i] for i, c in enumerate(clusters) if c == cluster_id]
            
            pattern = self._analyze_cluster_pattern(cluster_events)
            interpreted_patterns.append({
                'cluster_id': int(cluster_id),
                'pattern_type': pattern['type'],
                'description': pattern['description'],
                'frequency': len(cluster_events),
                'confidence': pattern['confidence'],
                'time_range': pattern['time_range'],
                'characteristics': pattern['characteristics']
            })
            
        return interpreted_patterns
        
    def _analyze_cluster_pattern(self, cluster_events: List[BehaviorEvent]) -> Dict:
        """クラスターパターン分析"""
        if not cluster_events:
            return {'type': 'unknown', 'description': 'No events', 'confidence': 0.0}
            
        # 時間分析
        hours = [event.timestamp.hour for event in cluster_events]
        hour_std = np.std(hours)
        
        # イベントタイプ分析
        event_types = [event.event_type for event in cluster_events]
        dominant_type = max(set(event_types), key=event_types.count)
        type_ratio = event_types.count(dominant_type) / len(event_types)
        
        # パターンタイプ判定
        if hour_std < 2 and type_ratio > 0.8:
            pattern_type = 'routine'
            description = f"Regular {dominant_type} around {np.mean(hours):.1f}:00"
        elif dominant_type == 'smartphone_use' and type_ratio > 0.6:
            pattern_type = 'distraction_pattern'
            description = "Frequent smartphone usage pattern"
        elif dominant_type == 'focused_work' and type_ratio > 0.7:
            pattern_type = 'focus_session'
            description = "Extended focus work session"
        else:
            pattern_type = 'mixed'
            description = "Mixed behavior pattern"
            
        return {
            'type': pattern_type,
            'description': description,
            'confidence': type_ratio,
            'time_range': (min(hours), max(hours)),
            'characteristics': {
                'dominant_event': dominant_type,
                'time_consistency': 1.0 - (hour_std / 12.0),
                'event_consistency': type_ratio
            }
        }
```

=== 集中度分析

**リアルタイム集中度計算**
```python
# src/services/analysis/focus_analyzer.py
import numpy as np
from typing import List, Dict, Any
from datetime import datetime, timedelta
from dataclasses import dataclass

@dataclass
class FocusMetrics:
    """集中度メトリクス"""
    raw_score: float
    smoothed_score: float
    trend: str  # 'improving', 'declining', 'stable'
    confidence: float

class FocusAnalyzer:
    """集中度分析器"""
    
    def __init__(self):
        self.focus_history: List[float] = []
        self.smoothing_window = 10
        self.trend_threshold = 5.0
        
    async def analyze(self, events: List[BehaviorEvent]) -> float:
        """集中度分析メイン処理"""
        if not events:
            return 0.0
            
        # 基本集中度計算
        raw_focus = self._calculate_raw_focus(events)
        
        # 履歴ベース平滑化
        smoothed_focus = self._apply_smoothing(raw_focus)
        
        # 集中度履歴更新
        self.focus_history.append(smoothed_focus)
        if len(self.focus_history) > 100:
            self.focus_history.pop(0)
            
        return smoothed_focus
        
    def _calculate_raw_focus(self, events: List[BehaviorEvent]) -> float:
        """生の集中度計算"""
        if not events:
            return 0.0
            
        # イベント重み定義
        event_weights = {
            'focused_work': 1.0,
            'smartphone_use': -0.8,
            'absence': -0.3,
            'posture_change': -0.1
        }
        
        total_weight = 0.0
        total_time = 0.0
        
        # 時間重み付け集中度計算
        for i, event in enumerate(events):
            weight = event_weights.get(event.event_type, 0.0)
            confidence = event.confidence
            
            # 時間による減衰（最新ほど重要）
            time_decay = self._calculate_time_decay(event.timestamp)
            
            # 継続性ボーナス
            continuity_bonus = self._calculate_continuity_bonus(events, i)
            
            adjusted_weight = weight * confidence * time_decay * continuity_bonus
            total_weight += adjusted_weight
            total_time += time_decay
            
        if total_time == 0:
            return 0.0
            
        # 正規化 (0-100スケール)
        raw_score = (total_weight / total_time + 1.0) * 50.0
        return max(0.0, min(100.0, raw_score))
        
    def _calculate_time_decay(self, timestamp: datetime) -> float:
        """時間減衰係数計算"""
        now = datetime.now()
        age_minutes = (now - timestamp).total_seconds() / 60.0
        
        # 指数減衰（半減期: 30分）
        decay = np.exp(-age_minutes / 30.0)
        return decay
        
    def _calculate_continuity_bonus(self, events: List[BehaviorEvent], index: int) -> float:
        """継続性ボーナス計算"""
        if index == 0:
            return 1.0
            
        current_event = events[index]
        previous_event = events[index - 1]
        
        # 同種イベントの継続
        if current_event.event_type == previous_event.event_type:
            # 集中作業の継続には大きなボーナス
            if current_event.event_type == 'focused_work':
                return 1.3
            # その他の継続には小さなペナルティ
            else:
                return 0.9
                
        return 1.0
        
    def _apply_smoothing(self, raw_focus: float) -> float:
        """履歴ベース平滑化"""
        if len(self.focus_history) < self.smoothing_window:
            # 履歴不足時は重み付け平均
            weights = np.linspace(0.1, 1.0, len(self.focus_history) + 1)
            values = self.focus_history + [raw_focus]
            return np.average(values, weights=weights)
        else:
            # 移動平均
            recent_history = self.focus_history[-self.smoothing_window:]
            weights = np.linspace(0.5, 1.0, self.smoothing_window + 1)
            values = recent_history + [raw_focus]
            return np.average(values, weights=weights)
            
    def get_focus_metrics(self) -> FocusMetrics:
        """詳細集中度メトリクス取得"""
        if len(self.focus_history) < 3:
            return FocusMetrics(0.0, 0.0, 'stable', 0.0)
            
        current_score = self.focus_history[-1]
        raw_score = current_score  # 簡略化
        
        # トレンド分析
        trend = self._analyze_trend()
        
        # 信頼度計算
        confidence = self._calculate_confidence()
        
        return FocusMetrics(
            raw_score=raw_score,
            smoothed_score=current_score,
            trend=trend,
            confidence=confidence
        )
        
    def _analyze_trend(self) -> str:
        """集中度トレンド分析"""
        if len(self.focus_history) < 5:
            return 'stable'
            
        recent_values = self.focus_history[-5:]
        
        # 線形回帰による傾き計算
        x = np.arange(len(recent_values))
        slope = np.polyfit(x, recent_values, 1)[0]
        
        if slope > self.trend_threshold:
            return 'improving'
        elif slope < -self.trend_threshold:
            return 'declining'
        else:
            return 'stable'
```

== 🔮 予測モデル

=== 行動予測エンジン

**LSTM ベース予測モデル**
```python
# src/services/analysis/behavior_predictor.py
import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

class BehaviorLSTM(nn.Module):
    """行動予測LSTM モデル"""
    
    def __init__(self, input_size: int = 10, hidden_size: int = 50, num_layers: int = 2, output_size: int = 3):
        super(BehaviorLSTM, self).__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # LSTM レイヤー
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)
        
        # 全結合層
        self.fc = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_size // 2, output_size),
            nn.Softmax(dim=1)
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """順伝播"""
        batch_size = x.size(0)
        
        # 隠れ状態初期化
        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)
        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)
        
        # LSTM 通過
        lstm_out, _ = self.lstm(x, (h0, c0))
        
        # 最後の出力のみ使用
        output = self.fc(lstm_out[:, -1, :])
        
        return output

class BehaviorPredictor:
    """行動予測器"""
    
    def __init__(self, model_path: Optional[str] = None):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = BehaviorLSTM().to(self.device)
        self.scaler = MinMaxScaler()
        self.sequence_length = 20
        self.prediction_classes = ['focused_work', 'smartphone_use', 'absence']
        
        if model_path:
            self.load_model(model_path)
            
    async def predict_next_behavior(self, events: List[BehaviorEvent]) -> Dict[str, Any]:
        """次の行動予測"""
        if len(events) < self.sequence_length:
            return self._default_prediction()
            
        # 特徴量シーケンス作成
        feature_sequence = self._create_feature_sequence(events)
        
        # 予測実行
        predictions = await self._predict_probabilities(feature_sequence)
        
        # 結果解釈
        return self._interpret_predictions(predictions, events[-1].timestamp)
        
    def _create_feature_sequence(self, events: List[BehaviorEvent]) -> np.ndarray:
        """予測用特徴量シーケンス作成"""
        # 最新のsequence_length個のイベントを使用
        recent_events = events[-self.sequence_length:]
        
        features = []
        for event in recent_events:
            feature_vector = [
                event.timestamp.hour / 24.0,  # 時刻
                event.timestamp.minute / 60.0,  # 分
                event.timestamp.weekday() / 7.0,  # 曜日
                event.confidence,  # 信頼度
                1.0 if event.event_type == 'focused_work' else 0.0,
                1.0 if event.event_type == 'smartphone_use' else 0.0,
                1.0 if event.event_type == 'absence' else 0.0,
                self._calculate_session_duration(recent_events, event),
                self._calculate_transition_frequency(recent_events),
                self._calculate_focus_momentum(recent_events[:recent_events.index(event)+1])
            ]
            features.append(feature_vector)
            
        return np.array(features).reshape(1, self.sequence_length, -1)
        
    async def _predict_probabilities(self, feature_sequence: np.ndarray) -> torch.Tensor:
        """確率予測実行"""
        self.model.eval()
        
        with torch.no_grad():
            # テンソル変換
            input_tensor = torch.FloatTensor(feature_sequence).to(self.device)
            
            # 予測実行
            probabilities = self.model(input_tensor)
            
        return probabilities.cpu()
        
    def _interpret_predictions(self, predictions: torch.Tensor, last_timestamp: datetime) -> Dict[str, Any]:
        """予測結果解釈"""
        probs = predictions.numpy()[0]
        
        # 最も可能性の高い行動
        predicted_class_idx = np.argmax(probs)
        predicted_class = self.prediction_classes[predicted_class_idx]
        confidence = float(probs[predicted_class_idx])
        
        # 次の予想時刻
        next_timestamp = last_timestamp + timedelta(minutes=5)
        
        # 特別な予測（休憩時刻等）
        special_predictions = self._generate_special_predictions(probs, last_timestamp)
        
        return {
            'next_behavior': predicted_class,
            'confidence': confidence,
            'probabilities': {
                class_name: float(prob) 
                for class_name, prob in zip(self.prediction_classes, probs)
            },
            'predicted_time': next_timestamp,
            **special_predictions
        }
        
    def _generate_special_predictions(self, probs: np.ndarray, last_timestamp: datetime) -> Dict:
        """特別な予測生成"""
        focus_prob = probs[0]  # focused_work確率
        
        # 休憩推奨時刻予測
        if focus_prob < 0.3:  # 集中度低下予測
            next_break = last_timestamp + timedelta(minutes=15)
        else:
            next_break = last_timestamp + timedelta(minutes=45)
            
        # 注意力低下アラート
        distraction_risk = probs[1]  # smartphone_use確率
        alert_needed = distraction_risk > 0.6
        
        return {
            'next_break': next_break,
            'break_recommendation': 'short' if focus_prob < 0.4 else 'none',
            'distraction_alert': alert_needed,
            'distraction_risk': float(distraction_risk)
        }
```

== 📊 個人化学習

=== ユーザープロファイル構築

**動的プロファイル学習**
```python
# src/services/personalization/user_profile_builder.py
import numpy as np
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
import json

@dataclass
class UserProfile:
    """ユーザープロファイル"""
    user_id: str
    optimal_focus_hours: List[int]  # 最適集中時間帯
    average_session_length: float  # 平均作業セッション長
    break_preferences: Dict[str, float]  # 休憩パターン
    distraction_triggers: List[str]  # 注意散漫要因
    productivity_patterns: Dict[str, Any]  # 生産性パターン
    adaptation_rate: float  # 学習適応速度
    confidence_level: float  # プロファイル信頼度
    last_updated: datetime

class UserProfileBuilder:
    """ユーザープロファイル構築器"""
    
    def __init__(self, config_manager):
        self.config_manager = config_manager
        self.user_profiles: Dict[str, UserProfile] = {}
        self.learning_rate = 0.1
        self.min_data_points = 50
        
    async def update_profile(self, user_id: str, events: List[BehaviorEvent], 
                           feedback: Optional[Dict] = None) -> UserProfile:
        """プロファイル更新"""
        
        # 既存プロファイル取得または新規作成
        profile = self.user_profiles.get(user_id) or self._create_default_profile(user_id)
        
        # 学習データ蓄積
        learning_data = self._extract_learning_data(events)
        
        # プロファイル学習
        updated_profile = await self._learn_from_data(profile, learning_data, feedback)
        
        # プロファイル保存
        self.user_profiles[user_id] = updated_profile
        await self._save_profile(updated_profile)
        
        return updated_profile
        
    def _create_default_profile(self, user_id: str) -> UserProfile:
        """デフォルトプロファイル作成"""
        return UserProfile(
            user_id=user_id,
            optimal_focus_hours=[9, 10, 11, 14, 15, 16],  # 一般的な集中時間
            average_session_length=45.0,  # 45分
            break_preferences={
                'short_break_frequency': 3,  # 3回作業後に短い休憩
                'long_break_duration': 15,   # 15分の長い休憩
                'preferred_break_activities': []
            },
            distraction_triggers=[],
            productivity_patterns={
                'morning_productivity': 0.7,
                'afternoon_productivity': 0.6,
                'weekly_pattern': [0.6, 0.8, 0.8, 0.7, 0.6, 0.3, 0.3]  # 月-日
            },
            adaptation_rate=0.1,
            confidence_level=0.1,
            last_updated=datetime.now()
        )
        
    async def _learn_from_data(self, profile: UserProfile, learning_data: Dict, 
                             feedback: Optional[Dict]) -> UserProfile:
        """データからの学習"""
        
        # 集中時間帯学習
        profile.optimal_focus_hours = await self._learn_optimal_hours(
            profile.optimal_focus_hours, learning_data['hourly_focus']
        )
        
        # セッション長学習
        profile.average_session_length = self._learn_session_length(
            profile.average_session_length, learning_data['session_lengths']
        )
        
        # 生産性パターン学習
        profile.productivity_patterns = await self._learn_productivity_patterns(
            profile.productivity_patterns, learning_data['productivity_data']
        )
        
        # フィードバック適用
        if feedback:
            profile = self._apply_feedback(profile, feedback)
            
        # 信頼度更新
        profile.confidence_level = self._update_confidence(profile, learning_data)
        profile.last_updated = datetime.now()
        
        return profile
        
    async def _learn_optimal_hours(self, current_hours: List[int], 
                                 hourly_focus: Dict[int, float]) -> List[int]:
        """最適時間帯学習"""
        if not hourly_focus:
            return current_hours
            
        # 時間帯別集中度の統計
        hour_scores = []
        for hour in range(24):
            scores = hourly_focus.get(hour, [])
            avg_score = np.mean(scores) if scores else 0.0
            hour_scores.append((hour, avg_score))
            
        # 上位6時間を選択
        sorted_hours = sorted(hour_scores, key=lambda x: x[1], reverse=True)
        new_optimal_hours = [hour for hour, _ in sorted_hours[:6]]
        
        # 現在の設定と新しい学習結果をブレンド
        blended_hours = self._blend_hour_preferences(current_hours, new_optimal_hours)
        
        return sorted(blended_hours)
        
    def _blend_hour_preferences(self, current: List[int], learned: List[int]) -> List[int]:
        """時間設定のブレンド"""
        # 重み付け平均的な考え方でブレンド
        all_hours = set(current + learned)
        
        hour_scores = {}
        for hour in all_hours:
            current_weight = 1.0 if hour in current else 0.0
            learned_weight = 1.0 if hour in learned else 0.0
            
            # 学習結果に重きを置く
            blended_score = (current_weight * 0.3) + (learned_weight * 0.7)
            hour_scores[hour] = blended_score
            
        # 上位6時間を選択
        top_hours = sorted(hour_scores.items(), key=lambda x: x[1], reverse=True)[:6]
        return [hour for hour, _ in top_hours]
        
    def generate_personalized_recommendations(self, user_id: str, 
                                            current_context: Dict) -> List[str]:
        """個人化推奨事項生成"""
        profile = self.user_profiles.get(user_id)
        if not profile:
            return self._default_recommendations()
            
        recommendations = []
        current_hour = datetime.now().hour
        
        # 時間帯ベース推奨
        if current_hour in profile.optimal_focus_hours:
            recommendations.append("This is your optimal focus time. Consider tackling complex tasks.")
        else:
            recommendations.append("Consider lighter tasks or take a break during this time.")
            
        # セッション長ベース推奨
        current_session_length = current_context.get('session_length', 0)
        if current_session_length > profile.average_session_length * 1.2:
            recommendations.append("You've been working longer than usual. Consider a break.")
            
        # 個人パターンベース推奨
        weekday = datetime.now().weekday()
        expected_productivity = profile.productivity_patterns['weekly_pattern'][weekday]
        
        if expected_productivity < 0.5:
            recommendations.append("Today typically shows lower productivity. Set realistic goals.")
        elif expected_productivity > 0.8:
            recommendations.append("Today is typically a high-productivity day. Consider challenging tasks.")
            
        return recommendations
```

== 📈 データ可視化と洞察

=== インサイトダッシュボード

**分析結果可視化**
```python
# src/services/analysis/insight_generator.py
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import base64
import io

class InsightGenerator:
    """インサイト生成器"""
    
    def __init__(self):
        self.insight_templates = self._load_insight_templates()
        
    async def generate_daily_insights(self, user_id: str, 
                                    analysis_data: Dict) -> Dict[str, Any]:
        """日次インサイト生成"""
        
        insights = {
            'summary': await self._generate_summary(analysis_data),
            'focus_analysis': self._analyze_focus_patterns(analysis_data),
            'productivity_insights': self._generate_productivity_insights(analysis_data),
            'recommendations': self._generate_smart_recommendations(analysis_data),
            'visualizations': await self._create_visualizations(analysis_data)
        }
        
        return insights
        
    async def _generate_summary(self, data: Dict) -> Dict[str, Any]:
        """要約生成"""
        total_events = len(data.get('events', []))
        focus_events = [e for e in data.get('events', []) if e.event_type == 'focused_work']
        distraction_events = [e for e in data.get('events', []) if e.event_type == 'smartphone_use']
        
        focus_time = len(focus_events) * 5  # 5分間隔想定
        distraction_time = len(distraction_events) * 5
        
        focus_percentage = (focus_time / (focus_time + distraction_time + 1)) * 100
        
        return {
            'total_monitoring_time': total_events * 5,
            'focus_time_minutes': focus_time,
            'distraction_time_minutes': distraction_time,
            'focus_percentage': round(focus_percentage, 1),
            'productivity_score': self._calculate_productivity_score(data),
            'key_insight': self._generate_key_insight(focus_percentage, data)
        }
        
    def _analyze_focus_patterns(self, data: Dict) -> Dict[str, Any]:
        """集中パターン分析"""
        events = data.get('events', [])
        if not events:
            return {'patterns': [], 'peak_hours': []}
            
        # 時間帯別集中度
        hourly_focus = {}
        for event in events:
            hour = event.timestamp.hour
            if hour not in hourly_focus:
                hourly_focus[hour] = []
                
            focus_score = 100 if event.event_type == 'focused_work' else 0
            hourly_focus[hour].append(focus_score)
            
        # 平均集中度計算
        hourly_avg = {hour: np.mean(scores) for hour, scores in hourly_focus.items()}
        
        # ピーク時間帯特定
        peak_hours = [hour for hour, score in hourly_avg.items() if score > 70]
        
        return {
            'hourly_focus': hourly_avg,
            'peak_hours': sorted(peak_hours),
            'focus_consistency': self._calculate_consistency(hourly_avg),
            'improvement_hours': [hour for hour, score in hourly_avg.items() if score < 30]
        }
        
    async def _create_visualizations(self, data: Dict) -> Dict[str, str]:
        """可視化作成"""
        visualizations = {}
        
        # 集中度推移グラフ
        focus_chart = await self._create_focus_timeline(data)
        visualizations['focus_timeline'] = focus_chart
        
        # 時間帯別ヒートマップ
        heatmap = await self._create_hourly_heatmap(data)
        visualizations['hourly_heatmap'] = heatmap
        
        # 生産性スコア推移
        productivity_chart = await self._create_productivity_chart(data)
        visualizations['productivity_trend'] = productivity_chart
        
        return visualizations
        
    async def _create_focus_timeline(self, data: Dict) -> str:
        """集中度タイムライン作成"""
        events = data.get('events', [])
        if not events:
            return ""
            
        # データ準備
        timestamps = [event.timestamp for event in events]
        focus_scores = [
            100 if event.event_type == 'focused_work' 
            else 0 if event.event_type == 'smartphone_use'
            else 50 for event in events
        ]
        
        # グラフ作成
        plt.figure(figsize=(12, 6))
        plt.plot(timestamps, focus_scores, linewidth=2, alpha=0.8)
        plt.fill_between(timestamps, focus_scores, alpha=0.3)
        
        plt.title('Focus Score Timeline', fontsize=16, fontweight='bold')
        plt.xlabel('Time', fontsize=12)
        plt.ylabel('Focus Score', fontsize=12)
        plt.ylim(0, 100)
        plt.grid(True, alpha=0.3)
        
        # 画像をBase64エンコード
        buffer = io.BytesIO()
        plt.savefig(buffer, format='png', bbox_inches='tight', dpi=150)
        buffer.seek(0)
        image_base64 = base64.b64encode(buffer.read()).decode()
        plt.close()
        
        return f"data:image/png;base64,{image_base64}"
        
    def _generate_smart_recommendations(self, data: Dict) -> List[Dict[str, str]]:
        """スマート推奨生成"""
        recommendations = []
        
        # 分析結果ベース推奨
        focus_analysis = self._analyze_focus_patterns(data)
        
        # 改善時間帯推奨
        if focus_analysis['improvement_hours']:
            recommendations.append({
                'type': 'schedule_optimization',
                'title': 'Schedule Optimization',
                'description': f"Consider lighter tasks during {', '.join(map(str, focus_analysis['improvement_hours']))}:00",
                'priority': 'medium'
            })
            
        # ピーク時間活用推奨
        if focus_analysis['peak_hours']:
            recommendations.append({
                'type': 'peak_utilization',
                'title': 'Peak Performance',
                'description': f"Your peak focus hours are {', '.join(map(str, focus_analysis['peak_hours']))}:00. Schedule important tasks then.",
                'priority': 'high'
            })
            
        # 一貫性改善推奨
        consistency = focus_analysis.get('focus_consistency', 0)
        if consistency < 0.6:
            recommendations.append({
                'type': 'consistency_improvement',
                'title': 'Focus Consistency',
                'description': 'Your focus varies significantly throughout the day. Try establishing regular work patterns.',
                'priority': 'medium'
            })
            
        return recommendations
```

== 🎯 まとめ

監視ちゃんの行動分析エンジンは以下の先進的機能を提供します：

=== 主要実装機能

* ✅ **リアルタイム分析**: 検出データから即座に行動パターン分析
* ✅ **予測モデル**: LSTM ベースの次行動・集中度予測
* ✅ **個人化学習**: ユーザー固有パターンの学習・適応
* ✅ **インサイト生成**: データ駆動による改善提案
* ✅ **可視化ダッシュボード**: 直感的な分析結果表示

=== 分析精度

[cols="2,2,2", options="header"]
|===
|分析項目 |目標精度 |実装技術
|集中度判定 |85%+ |重み付け時系列分析
|行動予測 |80%+ |LSTM + 特徴工学
|パターン検出 |90%+ |DBSCAN クラスタリング
|個人化適応 |継続改善 |オンライン学習
|===

=== 今後の拡張

1. **深層学習強化**: Transformer モデル導入
2. **マルチモーダル分析**: 音声・視線データ統合
3. **長期行動予測**: 週・月単位の行動パターン予測
4. **チーム分析**: 組織レベルでの生産性分析

---

**📞 Contact**: team@kanshichan.dev +
**🔗 Repository**: https://github.com/kanshichan/backend +
**📅 Last Updated**: {docdate} +
**📝 Document Version**: {revnumber} 