= ğŸ“Š ç›£è¦–ã¡ã‚ƒã‚“(KanshiChan) é‹ç”¨ãƒ»ç›£è¦–
:toc: left
:toc-title: ç›®æ¬¡
:toclevels: 3
:numbered:
:source-highlighter: highlight.js
:icons: font
:doctype: book
:author: KanshiChan Development Team
:email: team@kanshichan.dev
:revnumber: 1.0
:revdate: {docdate}
:experimental:

[NOTE]
====
ğŸ“‹ **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±**

* **ä½œæˆè€…**: KanshiChan Development Team
* **æœ€çµ‚æ›´æ–°æ—¥**: {docdate}
* **å¯¾è±¡èª­è€…**: é‹ç”¨ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€ã‚¤ãƒ³ãƒ•ãƒ©ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢
* **å‰æçŸ¥è­˜**: ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ã€ãƒ­ã‚°åˆ†æã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç®¡ç†
* **é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: <<performance-optimization.adoc>>, <<scalability-design.adoc>>, <<troubleshooting-guide.adoc>>
====

== ğŸ“– æ¦‚è¦

ç›£è¦–ã¡ã‚ƒã‚“ï¼ˆKanshiChanï¼‰ã®æœ¬ç•ªé‹ç”¨ã«ãŠã‘ã‚‹ç›£è¦–ãƒ»ä¿å®ˆã‚¬ã‚¤ãƒ‰ã§ã™ã€‚
ã‚·ã‚¹ãƒ†ãƒ å®‰å®šæ€§ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã€éšœå®³å¯¾å¿œã®ãŸã‚ã®åŒ…æ‹¬çš„ãªé‹ç”¨æ‰‹é †ã‚’æä¾›ã—ã¾ã™ã€‚

=== ğŸ¯ é‹ç”¨ç›®æ¨™

* **å¯ç”¨æ€§**: 99.9%ã®ã‚µãƒ¼ãƒ“ã‚¹ç¨¼åƒç‡ç¶­æŒ
* **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“2ç§’ä»¥å†…ï¼ˆ95%ileï¼‰
* **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆé›¶ä»¶æ•°
* **åŠ¹ç‡æ€§**: éšœå®³å¯¾å¿œæ™‚é–“30åˆ†ä»¥å†…å¹³å‡

== ğŸ—ï¸ ç›£è¦–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

=== ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–å…¨ä½“æ§‹æˆ

[mermaid]
....
graph TB
    subgraph "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤"
        APP[KanshiChan Application<br/>Flask + WebSocket]
        AI[AI Processing<br/>YOLO + MediaPipe]
        TTS[TTS Service<br/>Zonos + Audio]
    end
    
    subgraph "ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"
        PROM[Prometheus<br/>ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†]
        NODE[Node Exporter<br/>ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹]
        CUSTOM[Custom Metrics<br/>ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å›ºæœ‰]
    end
    
    subgraph "ãƒ­ã‚°ç®¡ç†"
        FLUENT[Fluentd<br/>ãƒ­ã‚°åé›†]
        ELASTIC[Elasticsearch<br/>ãƒ­ã‚°ä¿å­˜ãƒ»æ¤œç´¢]
        KIBANA[Kibana<br/>ãƒ­ã‚°å¯è¦–åŒ–]
    end
    
    subgraph "ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆ"
        GRAFANA[Grafana<br/>ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰]
        ALERT[AlertManager<br/>ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†]
        SLACK[Slack/Email<br/>é€šçŸ¥]
    end
    
    subgraph "ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"
        HEALTH[Health Checks<br/>ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç›£è¦–]
        UPTIME[Uptime Monitoring<br/>å¤–éƒ¨ç›£è¦–]
    end
    
    APP --> PROM
    AI --> PROM
    TTS --> PROM
    
    APP --> FLUENT
    AI --> FLUENT
    TTS --> FLUENT
    
    NODE --> PROM
    CUSTOM --> PROM
    
    FLUENT --> ELASTIC
    ELASTIC --> KIBANA
    
    PROM --> GRAFANA
    PROM --> ALERT
    ALERT --> SLACK
    
    APP --> HEALTH
    HEALTH --> UPTIME
....

== ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–é …ç›®

=== ä¸»è¦ç›£è¦–ãƒ¡ãƒˆãƒªã‚¯ã‚¹

**ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç›£è¦–**
```yaml
# monitoring/app_metrics.yml
application_metrics:
  performance:
    - name: "request_duration_seconds"
      description: "HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†æ™‚é–“"
      type: "histogram"
      labels: ["method", "endpoint", "status"]
      targets:
        p95: "< 2.0s"
        p99: "< 5.0s"
        
    - name: "active_connections"
      description: "ã‚¢ã‚¯ãƒ†ã‚£ãƒ–WebSocketæ¥ç¶šæ•°"
      type: "gauge"
      targets:
        normal: "< 1000"
        warning: "< 1500"
        critical: "< 2000"
        
  ai_processing:
    - name: "ai_inference_duration_seconds"
      description: "AIæ¨è«–å‡¦ç†æ™‚é–“"
      type: "histogram"
      labels: ["model_type", "gpu_used"]
      targets:
        yolo_inference: "< 0.1s"
        mediapipe_inference: "< 0.05s"
        
    - name: "detection_accuracy"
      description: "æ¤œå‡ºç²¾åº¦"
      type: "gauge"
      labels: ["detection_type"]
      targets:
        person_detection: "> 0.95"
        smartphone_detection: "> 0.90"
        
  memory_usage:
    - name: "memory_usage_bytes"
      description: "ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡"
      type: "gauge"
      targets:
        warning: "< 8GB"
        critical: "< 12GB"
        
    - name: "gpu_memory_usage_bytes"
      description: "GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡"
      type: "gauge"
      targets:
        warning: "< 6GB"
        critical: "< 8GB"
```

**ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ç›£è¦–**
```python
# src/monitoring/system_metrics.py
import psutil
import prometheus_client
from typing import Dict, List
import GPUtil
import time

class SystemMetricsCollector:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
    
    def __init__(self):
        # Prometheus ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®šç¾©
        self.cpu_usage = prometheus_client.Gauge(
            'system_cpu_usage_percent', 'CPUä½¿ç”¨ç‡'
        )
        self.memory_usage = prometheus_client.Gauge(
            'system_memory_usage_bytes', 'ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡'
        )
        self.disk_usage = prometheus_client.Gauge(
            'system_disk_usage_percent', 'ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡', ['device']
        )
        self.gpu_usage = prometheus_client.Gauge(
            'system_gpu_usage_percent', 'GPUä½¿ç”¨ç‡', ['gpu_id']
        )
        self.network_io = prometheus_client.Counter(
            'system_network_io_bytes_total', 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯I/O', ['direction']
        )
        
    def collect_metrics(self) -> Dict[str, float]:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        metrics = {}
        
        # CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        self.cpu_usage.set(cpu_percent)
        metrics['cpu_usage'] = cpu_percent
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
        memory = psutil.virtual_memory()
        self.memory_usage.set(memory.used)
        metrics['memory_usage_percent'] = memory.percent
        metrics['memory_available_gb'] = memory.available / (1024**3)
        
        # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡
        for partition in psutil.disk_partitions():
            try:
                disk_usage = psutil.disk_usage(partition.mountpoint)
                usage_percent = (disk_usage.used / disk_usage.total) * 100
                self.disk_usage.labels(device=partition.device).set(usage_percent)
                metrics[f'disk_usage_{partition.device}'] = usage_percent
            except PermissionError:
                continue
                
        # GPUä½¿ç”¨ç‡
        try:
            gpus = GPUtil.getGPUs()
            for gpu in gpus:
                self.gpu_usage.labels(gpu_id=gpu.id).set(gpu.load * 100)
                metrics[f'gpu_{gpu.id}_usage'] = gpu.load * 100
                metrics[f'gpu_{gpu.id}_memory'] = gpu.memoryUsed
        except Exception as e:
            logger.warning(f"GPU metrics collection failed: {e}")
            
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯I/O
        network_io = psutil.net_io_counters()
        self.network_io.labels(direction='sent').inc(network_io.bytes_sent)
        self.network_io.labels(direction='recv').inc(network_io.bytes_recv)
        
        return metrics

class ApplicationMetricsCollector:
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
    
    def __init__(self, config_manager):
        self.config_manager = config_manager
        
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.detection_count = prometheus_client.Counter(
            'kanshichan_detections_total', 
            'æ¤œå‡ºå›æ•°', 
            ['detection_type', 'confidence_level']
        )
        
        self.processing_time = prometheus_client.Histogram(
            'kanshichan_processing_seconds',
            'å‡¦ç†æ™‚é–“',
            ['operation_type']
        )
        
        self.error_count = prometheus_client.Counter(
            'kanshichan_errors_total',
            'ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿå›æ•°',
            ['error_type', 'severity']
        )
        
    def record_detection(self, detection_type: str, confidence: float):
        """æ¤œå‡ºã‚¤ãƒ™ãƒ³ãƒˆè¨˜éŒ²"""
        confidence_level = 'high' if confidence > 0.8 else 'medium' if confidence > 0.5 else 'low'
        self.detection_count.labels(
            detection_type=detection_type,
            confidence_level=confidence_level
        ).inc()
        
    def record_processing_time(self, operation: str, duration: float):
        """å‡¦ç†æ™‚é–“è¨˜éŒ²"""
        self.processing_time.labels(operation_type=operation).observe(duration)
        
    def record_error(self, error_type: str, severity: str):
        """ã‚¨ãƒ©ãƒ¼è¨˜éŒ²"""
        self.error_count.labels(error_type=error_type, severity=severity).inc()
```

=== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

**ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ**
```python
# src/monitoring/performance_analyzer.py
import asyncio
import time
from typing import Dict, List, Any
from dataclasses import dataclass
from collections import deque
import numpy as np

@dataclass
class PerformanceSnapshot:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ"""
    timestamp: float
    cpu_usage: float
    memory_usage: float
    gpu_usage: float
    active_connections: int
    avg_response_time: float
    detection_fps: float
    error_rate: float

class PerformanceAnalyzer:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æå™¨"""
    
    def __init__(self):
        self.snapshots = deque(maxlen=1440)  # 24æ™‚é–“åˆ†ï¼ˆ1åˆ†é–“éš”ï¼‰
        self.thresholds = {
            'cpu_warning': 80.0,
            'cpu_critical': 95.0,
            'memory_warning': 85.0,
            'memory_critical': 95.0,
            'response_time_warning': 2.0,
            'response_time_critical': 5.0,
            'error_rate_warning': 0.01,
            'error_rate_critical': 0.05
        }
        
    async def analyze_performance(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        current_snapshot = await self._collect_current_snapshot()
        self.snapshots.append(current_snapshot)
        
        analysis = {
            'current': self._analyze_current_performance(current_snapshot),
            'trends': self._analyze_trends(),
            'alerts': self._generate_alerts(current_snapshot),
            'recommendations': self._generate_recommendations()
        }
        
        return analysis
        
    def _analyze_current_performance(self, snapshot: PerformanceSnapshot) -> Dict:
        """ç¾åœ¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢è¨ˆç®—
        cpu_score = max(0, 100 - snapshot.cpu_usage)
        memory_score = max(0, 100 - snapshot.memory_usage)
        response_score = max(0, 100 - (snapshot.avg_response_time * 50))
        error_score = max(0, 100 - (snapshot.error_rate * 10000))
        
        overall_score = np.mean([cpu_score, memory_score, response_score, error_score])
        
        return {
            'overall_score': round(overall_score, 2),
            'cpu_score': round(cpu_score, 2),
            'memory_score': round(memory_score, 2),
            'response_score': round(response_score, 2),
            'error_score': round(error_score, 2),
            'performance_level': self._classify_performance(overall_score)
        }
        
    def _analyze_trends(self) -> Dict:
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        if len(self.snapshots) < 10:
            return {'status': 'insufficient_data'}
            
        recent_snapshots = list(self.snapshots)[-60:]  # ç›´è¿‘1æ™‚é–“
        
        # CPUä½¿ç”¨ç‡ãƒˆãƒ¬ãƒ³ãƒ‰
        cpu_values = [s.cpu_usage for s in recent_snapshots]
        cpu_trend = np.polyfit(range(len(cpu_values)), cpu_values, 1)[0]
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãƒˆãƒ¬ãƒ³ãƒ‰
        memory_values = [s.memory_usage for s in recent_snapshots]
        memory_trend = np.polyfit(range(len(memory_values)), memory_values, 1)[0]
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãƒˆãƒ¬ãƒ³ãƒ‰
        response_values = [s.avg_response_time for s in recent_snapshots]
        response_trend = np.polyfit(range(len(response_values)), response_values, 1)[0]
        
        return {
            'cpu_trend': 'increasing' if cpu_trend > 1 else 'decreasing' if cpu_trend < -1 else 'stable',
            'memory_trend': 'increasing' if memory_trend > 1 else 'decreasing' if memory_trend < -1 else 'stable',
            'response_trend': 'degrading' if response_trend > 0.01 else 'improving' if response_trend < -0.01 else 'stable',
            'prediction': self._predict_performance_issues(cpu_trend, memory_trend, response_trend)
        }
        
    def _generate_alerts(self, snapshot: PerformanceSnapshot) -> List[Dict]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆ"""
        alerts = []
        
        # CPU ã‚¢ãƒ©ãƒ¼ãƒˆ
        if snapshot.cpu_usage > self.thresholds['cpu_critical']:
            alerts.append({
                'type': 'cpu_usage',
                'severity': 'critical',
                'message': f'CPU usage critical: {snapshot.cpu_usage:.1f}%',
                'action': 'immediate_scaling_required'
            })
        elif snapshot.cpu_usage > self.thresholds['cpu_warning']:
            alerts.append({
                'type': 'cpu_usage',
                'severity': 'warning',
                'message': f'CPU usage high: {snapshot.cpu_usage:.1f}%',
                'action': 'consider_scaling'
            })
            
        # ãƒ¡ãƒ¢ãƒªã‚¢ãƒ©ãƒ¼ãƒˆ
        if snapshot.memory_usage > self.thresholds['memory_critical']:
            alerts.append({
                'type': 'memory_usage',
                'severity': 'critical',
                'message': f'Memory usage critical: {snapshot.memory_usage:.1f}%',
                'action': 'restart_required'
            })
            
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚¢ãƒ©ãƒ¼ãƒˆ
        if snapshot.avg_response_time > self.thresholds['response_time_critical']:
            alerts.append({
                'type': 'response_time',
                'severity': 'critical',
                'message': f'Response time critical: {snapshot.avg_response_time:.2f}s',
                'action': 'performance_investigation_required'
            })
            
        return alerts
```

== ğŸ“ ãƒ­ã‚°åˆ†ææ‰‹æ³•

=== ãƒ­ã‚°æ§‹é€ åŒ–ã¨é›†ä¸­ç®¡ç†

**ãƒ­ã‚°è¨­å®š**
```yaml
# config/logging.yml
logging:
  version: 1
  formatters:
    structured:
      format: '{"timestamp": "%(asctime)s", "level": "%(levelname)s", "logger": "%(name)s", "message": "%(message)s", "module": "%(module)s", "function": "%(funcName)s", "line": %(lineno)d}'
      
  handlers:
    console:
      class: logging.StreamHandler
      level: INFO
      formatter: structured
      stream: ext://sys.stdout
      
    file:
      class: logging.handlers.RotatingFileHandler
      level: DEBUG
      formatter: structured
      filename: /var/log/kanshichan/app.log
      maxBytes: 100MB
      backupCount: 10
      
    fluentd:
      class: fluent.handler.FluentHandler
      level: INFO
      tag: kanshichan.application
      host: localhost
      port: 24224
      
  loggers:
    kanshichan:
      level: DEBUG
      handlers: [console, file, fluentd]
      propagate: false
      
  root:
    level: WARNING
    handlers: [console]
```

**ãƒ­ã‚°åˆ†æã‚¯ã‚¨ãƒªä¾‹**
```json
# Elasticsearch/Kibana ã‚¯ã‚¨ãƒªä¾‹

# ã‚¨ãƒ©ãƒ¼ç‡åˆ†æ
{
  "query": {
    "bool": {
      "filter": [
        {"range": {"@timestamp": {"gte": "now-1h"}}},
        {"term": {"level": "ERROR"}}
      ]
    }
  },
  "aggs": {
    "error_count_per_minute": {
      "date_histogram": {
        "field": "@timestamp",
        "interval": "1m"
      }
    },
    "error_types": {
      "terms": {
        "field": "error_type.keyword",
        "size": 10
      }
    }
  }
}

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
{
  "query": {
    "bool": {
      "filter": [
        {"range": {"@timestamp": {"gte": "now-24h"}}},
        {"exists": {"field": "response_time"}}
      ]
    }
  },
  "aggs": {
    "avg_response_time": {
      "avg": {"field": "response_time"}
    },
    "percentiles_response_time": {
      "percentiles": {
        "field": "response_time",
        "percents": [50, 90, 95, 99]
      }
    }
  }
}
```

=== ãƒ­ã‚°åˆ†æè‡ªå‹•åŒ–

**ç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ **
```python
# src/monitoring/log_analyzer.py
import re
from typing import Dict, List, Any
from datetime import datetime, timedelta
import json
from collections import defaultdict, Counter

class LogAnalyzer:
    """ãƒ­ã‚°åˆ†æã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, elasticsearch_client):
        self.es = elasticsearch_client
        self.error_patterns = self._load_error_patterns()
        self.performance_thresholds = {
            'slow_query': 1.0,  # 1ç§’ä»¥ä¸Š
            'high_cpu': 80.0,   # CPU 80%ä»¥ä¸Š
            'memory_leak': 0.1  # 10%/æ™‚é–“ å¢—åŠ 
        }
        
    async def analyze_recent_logs(self, hours: int = 1) -> Dict[str, Any]:
        """ç›´è¿‘ãƒ­ã‚°åˆ†æ"""
        
        # ãƒ­ã‚°å–å¾—
        logs = await self._fetch_logs(hours)
        
        # å„ç¨®åˆ†æå®Ÿè¡Œ
        analysis = {
            'error_analysis': self._analyze_errors(logs),
            'performance_analysis': self._analyze_performance(logs),
            'security_analysis': self._analyze_security_events(logs),
            'anomaly_detection': self._detect_anomalies(logs),
            'summary': self._generate_summary(logs)
        }
        
        return analysis
        
    def _analyze_errors(self, logs: List[Dict]) -> Dict:
        """ã‚¨ãƒ©ãƒ¼åˆ†æ"""
        error_logs = [log for log in logs if log.get('level') == 'ERROR']
        
        if not error_logs:
            return {'status': 'no_errors', 'count': 0}
            
        # ã‚¨ãƒ©ãƒ¼åˆ†é¡
        error_categories = defaultdict(list)
        for log in error_logs:
            category = self._categorize_error(log)
            error_categories[category].append(log)
            
        # é »ç™ºã‚¨ãƒ©ãƒ¼ç‰¹å®š
        frequent_errors = self._identify_frequent_errors(error_logs)
        
        # æ–°è¦ã‚¨ãƒ©ãƒ¼æ¤œå‡º
        new_errors = self._detect_new_errors(error_logs)
        
        return {
            'total_errors': len(error_logs),
            'error_rate': len(error_logs) / len(logs) if logs else 0,
            'categories': dict(error_categories),
            'frequent_errors': frequent_errors,
            'new_errors': new_errors,
            'critical_errors': [log for log in error_logs if 'critical' in log.get('message', '').lower()]
        }
        
    def _analyze_performance(self, logs: List[Dict]) -> Dict:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        perf_logs = [log for log in logs if 'response_time' in log or 'processing_time' in log]
        
        if not perf_logs:
            return {'status': 'no_performance_data'}
            
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“åˆ†æ
        response_times = [log.get('response_time', 0) for log in perf_logs if 'response_time' in log]
        slow_requests = [log for log in perf_logs if log.get('response_time', 0) > self.performance_thresholds['slow_query']]
        
        # AIå‡¦ç†æ™‚é–“åˆ†æ
        ai_times = [log.get('ai_processing_time', 0) for log in perf_logs if 'ai_processing_time' in log]
        
        return {
            'avg_response_time': np.mean(response_times) if response_times else 0,
            'p95_response_time': np.percentile(response_times, 95) if response_times else 0,
            'slow_requests_count': len(slow_requests),
            'slow_requests_ratio': len(slow_requests) / len(perf_logs) if perf_logs else 0,
            'avg_ai_processing_time': np.mean(ai_times) if ai_times else 0,
            'performance_issues': self._identify_performance_issues(perf_logs)
        }
        
    def _detect_anomalies(self, logs: List[Dict]) -> List[Dict]:
        """ç•°å¸¸æ¤œçŸ¥"""
        anomalies = []
        
        # ç•°å¸¸ãªã‚¨ãƒ©ãƒ¼ç‡
        error_rate = len([log for log in logs if log.get('level') == 'ERROR']) / len(logs) if logs else 0
        if error_rate > 0.05:  # 5%ä»¥ä¸Šã®ã‚¨ãƒ©ãƒ¼ç‡
            anomalies.append({
                'type': 'high_error_rate',
                'severity': 'warning',
                'value': error_rate,
                'description': f'Error rate is {error_rate:.2%}, above normal threshold'
            })
            
        # ç•°å¸¸ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“
        response_times = [log.get('response_time', 0) for log in logs if 'response_time' in log]
        if response_times:
            avg_response = np.mean(response_times)
            if avg_response > 2.0:  # å¹³å‡2ç§’ä»¥ä¸Š
                anomalies.append({
                    'type': 'slow_response',
                    'severity': 'warning',
                    'value': avg_response,
                    'description': f'Average response time is {avg_response:.2f}s, above normal threshold'
                })
                
        # ç•°å¸¸ãªAIå‡¦ç†å¤±æ•—
        ai_failures = [log for log in logs if 'ai_error' in log.get('message', '').lower()]
        if len(ai_failures) > 10:  # 10å›ä»¥ä¸Šã®AIå‡¦ç†å¤±æ•—
            anomalies.append({
                'type': 'ai_processing_failures',
                'severity': 'critical',
                'value': len(ai_failures),
                'description': f'{len(ai_failures)} AI processing failures detected'
            })
            
        return anomalies
```

== ğŸš¨ ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

=== Prometheus AlertManagerè¨­å®š

**ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«**
```yaml
# monitoring/alerting_rules.yml
groups:
- name: kanshichan_alerts
  rules:
  
  # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã‚¢ãƒ©ãƒ¼ãƒˆ
  - alert: HighCPUUsage
    expr: system_cpu_usage_percent > 80
    for: 5m
    labels:
      severity: warning
      component: system
    annotations:
      summary: "High CPU usage detected"
      description: "CPU usage is {{ $value }}% for more than 5 minutes"
      
  - alert: CriticalCPUUsage
    expr: system_cpu_usage_percent > 95
    for: 2m
    labels:
      severity: critical
      component: system
    annotations:
      summary: "Critical CPU usage detected"
      description: "CPU usage is {{ $value }}% for more than 2 minutes"
      
  - alert: HighMemoryUsage
    expr: (system_memory_usage_bytes / system_memory_total_bytes) * 100 > 85
    for: 5m
    labels:
      severity: warning
      component: system
    annotations:
      summary: "High memory usage detected"
      description: "Memory usage is {{ $value }}% for more than 5 minutes"
      
  # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ©ãƒ¼ãƒˆ
  - alert: HighErrorRate
    expr: rate(kanshichan_errors_total[5m]) > 0.1
    for: 2m
    labels:
      severity: critical
      component: application
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value }} errors/second"
      
  - alert: SlowResponse
    expr: histogram_quantile(0.95, rate(kanshichan_request_duration_seconds_bucket[5m])) > 2
    for: 3m
    labels:
      severity: warning
      component: application
    annotations:
      summary: "Slow response time detected"
      description: "95th percentile response time is {{ $value }}s"
      
  # AIå‡¦ç†ã‚¢ãƒ©ãƒ¼ãƒˆ
  - alert: AIProcessingFailure
    expr: rate(kanshichan_ai_errors_total[5m]) > 0.05
    for: 3m
    labels:
      severity: warning
      component: ai
    annotations:
      summary: "AI processing failures detected"
      description: "AI processing error rate is {{ $value }} errors/second"
      
  - alert: LowDetectionAccuracy
    expr: kanshichan_detection_accuracy < 0.8
    for: 10m
    labels:
      severity: warning
      component: ai
    annotations:
      summary: "Detection accuracy degraded"
      description: "Detection accuracy is {{ $value }}, below normal threshold"
```

=== é€šçŸ¥è¨­å®š

**AlertManagerè¨­å®š**
```yaml
# monitoring/alertmanager.yml
global:
  slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
  
route:
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'kanshichan-alerts'
  
  routes:
  - match:
      severity: critical
    receiver: 'critical-alerts'
    repeat_interval: 15m
    
  - match:
      component: ai
    receiver: 'ai-team-alerts'
    
receivers:
- name: 'kanshichan-alerts'
  slack_configs:
  - channel: '#kanshichan-monitoring'
    username: 'AlertManager'
    icon_emoji: ':warning:'
    title: 'KanshiChan Alert'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ .Annotations.description }}{{ end }}'
    
- name: 'critical-alerts'
  slack_configs:
  - channel: '#kanshichan-critical'
    username: 'AlertManager'
    icon_emoji: ':rotating_light:'
    title: 'CRITICAL: KanshiChan Alert'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ .Annotations.description }}{{ end }}'
  email_configs:
  - to: 'team@kanshichan.dev'
    subject: 'CRITICAL: KanshiChan Alert'
    body: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ .Annotations.description }}{{ end }}'
    
- name: 'ai-team-alerts'
  slack_configs:
  - channel: '#kanshichan-ai'
    username: 'AlertManager'
    icon_emoji: ':robot_face:'
    title: 'AI System Alert'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ .Annotations.description }}{{ end }}'
```

== ğŸ“ˆ å®¹é‡è¨ˆç”»

=== ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡äºˆæ¸¬

**å®¹é‡è¨ˆç”»ãƒ¢ãƒ‡ãƒ«**
```python
# src/monitoring/capacity_planner.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple
from datetime import datetime, timedelta
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures

class CapacityPlanner:
    """å®¹é‡è¨ˆç”»ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, metrics_store):
        self.metrics_store = metrics_store
        self.growth_models = {}
        
    async def analyze_growth_trends(self, days: int = 30) -> Dict[str, Any]:
        """æˆé•·ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        
        # éå»ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
        historical_data = await self._fetch_historical_metrics(days)
        
        # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æˆé•·äºˆæ¸¬
        predictions = {}
        for metric_name in ['cpu_usage', 'memory_usage', 'storage_usage', 'user_count']:
            trend = self._analyze_metric_trend(historical_data, metric_name)
            prediction = self._predict_future_usage(trend, forecast_days=90)
            predictions[metric_name] = prediction
            
        # å®¹é‡ä¸è¶³äºˆè­¦å‘Š
        capacity_warnings = self._generate_capacity_warnings(predictions)
        
        return {
            'current_usage': self._get_current_usage(),
            'growth_predictions': predictions,
            'capacity_warnings': capacity_warnings,
            'recommended_actions': self._recommend_capacity_actions(predictions)
        }
        
    def _analyze_metric_trend(self, data: pd.DataFrame, metric: str) -> Dict:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        if metric not in data.columns:
            return {'status': 'no_data'}
            
        values = data[metric].values
        timestamps = np.arange(len(values))
        
        # ç·šå½¢ãƒˆãƒ¬ãƒ³ãƒ‰
        linear_model = LinearRegression().fit(timestamps.reshape(-1, 1), values)
        linear_slope = linear_model.coef_[0]
        
        # å¤šé …å¼ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆ2æ¬¡ï¼‰
        poly_features = PolynomialFeatures(degree=2)
        poly_timestamps = poly_features.fit_transform(timestamps.reshape(-1, 1))
        poly_model = LinearRegression().fit(poly_timestamps, values)
        
        # å­£ç¯€æ€§åˆ†æ
        seasonality = self._detect_seasonality(values)
        
        return {
            'linear_slope': linear_slope,
            'linear_model': linear_model,
            'polynomial_model': poly_model,
            'seasonality': seasonality,
            'current_value': values[-1] if len(values) > 0 else 0,
            'avg_value': np.mean(values),
            'volatility': np.std(values)
        }
        
    def _predict_future_usage(self, trend: Dict, forecast_days: int) -> Dict:
        """å°†æ¥ä½¿ç”¨é‡äºˆæ¸¬"""
        if trend.get('status') == 'no_data':
            return {'status': 'no_prediction'}
            
        future_timestamps = np.arange(forecast_days)
        
        # ç·šå½¢äºˆæ¸¬
        linear_prediction = trend['linear_model'].predict(
            future_timestamps.reshape(-1, 1)
        )
        
        # å­£ç¯€æ€§ã‚’è€ƒæ…®ã—ãŸèª¿æ•´
        if trend['seasonality']['detected']:
            seasonal_adjustment = self._apply_seasonal_adjustment(
                linear_prediction, trend['seasonality']
            )
            adjusted_prediction = linear_prediction + seasonal_adjustment
        else:
            adjusted_prediction = linear_prediction
            
        # ä¿¡é ¼åŒºé–“è¨ˆç®—
        confidence_interval = self._calculate_confidence_interval(
            adjusted_prediction, trend['volatility']
        )
        
        return {
            'predicted_values': adjusted_prediction.tolist(),
            'confidence_interval': confidence_interval,
            'peak_usage_day': int(np.argmax(adjusted_prediction)),
            'predicted_peak_value': float(np.max(adjusted_prediction)),
            'growth_rate_percent': trend['linear_slope'] * 100 if trend['linear_slope'] else 0
        }
        
    def _generate_capacity_warnings(self, predictions: Dict) -> List[Dict]:
        """å®¹é‡è­¦å‘Šç”Ÿæˆ"""
        warnings = []
        
        capacity_limits = {
            'cpu_usage': 90.0,      # 90% CPUä½¿ç”¨ç‡
            'memory_usage': 85.0,   # 85% ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
            'storage_usage': 80.0,  # 80% ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨ç‡
            'user_count': 10000     # 10,000 ãƒ¦ãƒ¼ã‚¶ãƒ¼
        }
        
        for metric, prediction in predictions.items():
            if prediction.get('status') == 'no_prediction':
                continue
                
            limit = capacity_limits.get(metric)
            if not limit:
                continue
                
            predicted_values = prediction['predicted_values']
            peak_value = prediction['predicted_peak_value']
            
            # å®¹é‡åˆ¶é™ã«é”ã™ã‚‹æ—¥ã‚’äºˆæ¸¬
            days_to_limit = None
            for day, value in enumerate(predicted_values):
                if value >= limit:
                    days_to_limit = day
                    break
                    
            if days_to_limit is not None and days_to_limit < 60:  # 60æ—¥ä»¥å†…
                severity = 'critical' if days_to_limit < 30 else 'warning'
                warnings.append({
                    'metric': metric,
                    'severity': severity,
                    'days_to_limit': days_to_limit,
                    'predicted_value': predicted_values[days_to_limit],
                    'limit': limit,
                    'message': f'{metric} will reach {limit} limit in {days_to_limit} days'
                })
                
        return warnings
```

== ğŸ”§ å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

=== ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

**è‡ªå‹•ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¿ã‚¹ã‚¯**
```python
# src/maintenance/scheduled_tasks.py
import asyncio
import schedule
import time
from datetime import datetime
from typing import Dict, List
import shutil
import os

class MaintenanceScheduler:
    """å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼"""
    
    def __init__(self, config_manager):
        self.config_manager = config_manager
        self.maintenance_log = []
        
    def setup_schedules(self):
        """ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®š"""
        
        # æ¯æ—¥ã®ã‚¿ã‚¹ã‚¯
        schedule.every().day.at("02:00").do(self.daily_maintenance)
        schedule.every().day.at("03:00").do(self.log_rotation)
        schedule.every().day.at("04:00").do(self.cache_cleanup)
        
        # é€±æ¬¡ã‚¿ã‚¹ã‚¯
        schedule.every().sunday.at("01:00").do(self.weekly_maintenance)
        schedule.every().sunday.at("05:00").do(self.database_optimization)
        
        # æœˆæ¬¡ã‚¿ã‚¹ã‚¯
        schedule.every().month.do(self.monthly_maintenance)
        
    async def daily_maintenance(self):
        """æ—¥æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹"""
        start_time = datetime.now()
        tasks_completed = []
        
        try:
            # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
            disk_usage = await self._check_disk_usage()
            if disk_usage > 80:
                await self._cleanup_old_files()
                tasks_completed.append("disk_cleanup")
                
            # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œçŸ¥
            memory_growth = await self._check_memory_growth()
            if memory_growth > 10:  # 10%ä»¥ä¸Šã®å¢—åŠ 
                await self._restart_memory_intensive_services()
                tasks_completed.append("memory_optimization")
                
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆæ›´æ–°
            await self._update_performance_statistics()
            tasks_completed.append("performance_stats_update")
            
            # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
            health_status = await self._comprehensive_health_check()
            tasks_completed.append("health_check")
            
            self._log_maintenance_completion("daily", tasks_completed, start_time)
            
        except Exception as e:
            logger.error(f"Daily maintenance failed: {e}")
            await self._send_maintenance_alert("daily_maintenance_failed", str(e))
            
    async def weekly_maintenance(self):
        """é€±æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹"""
        start_time = datetime.now()
        tasks_completed = []
        
        try:
            # ãƒ­ã‚°ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
            await self._archive_old_logs()
            tasks_completed.append("log_archival")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæ›´æ–°
            await self._update_database_statistics()
            tasks_completed.append("database_stats_update")
            
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
            security_issues = await self._security_vulnerability_scan()
            if security_issues:
                await self._send_security_alert(security_issues)
            tasks_completed.append("security_scan")
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼
            backup_status = await self._verify_backups()
            tasks_completed.append("backup_verification")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            await self._analyze_weekly_performance_trends()
            tasks_completed.append("performance_trend_analysis")
            
            self._log_maintenance_completion("weekly", tasks_completed, start_time)
            
        except Exception as e:
            logger.error(f"Weekly maintenance failed: {e}")
            await self._send_maintenance_alert("weekly_maintenance_failed", str(e))
            
    async def _check_disk_usage(self) -> float:
        """ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯"""
        total, used, free = shutil.disk_usage("/")
        usage_percent = (used / total) * 100
        return usage_percent
        
    async def _cleanup_old_files(self):
        """å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        cleanup_paths = [
            ("/var/log/kanshichan/", 7),  # 7æ—¥ä»¥ä¸Šã®ãƒ­ã‚°
            ("/tmp/kanshichan/", 1),      # 1æ—¥ä»¥ä¸Šã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
            ("/data/cache/", 3)           # 3æ—¥ä»¥ä¸Šã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        ]
        
        for path, days in cleanup_paths:
            if os.path.exists(path):
                await self._remove_old_files(path, days)
                
    async def _comprehensive_health_check(self) -> Dict:
        """åŒ…æ‹¬çš„ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        health_status = {
            'overall': 'healthy',
            'components': {}
        }
        
        # API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒã‚§ãƒƒã‚¯
        api_health = await self._check_api_endpoints()
        health_status['components']['api'] = api_health
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒã‚§ãƒƒã‚¯
        db_health = await self._check_database_connection()
        health_status['components']['database'] = db_health
        
        # AI ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯
        ai_health = await self._check_ai_models()
        health_status['components']['ai_models'] = ai_health
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãƒã‚§ãƒƒã‚¯
        fs_health = await self._check_filesystem()
        health_status['components']['filesystem'] = fs_health
        
        # å…¨ä½“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
        component_statuses = [comp['status'] for comp in health_status['components'].values()]
        if 'critical' in component_statuses:
            health_status['overall'] = 'critical'
        elif 'warning' in component_statuses:
            health_status['overall'] = 'warning'
            
        return health_status
```

== ğŸ¯ ã¾ã¨ã‚

KanshiChanã®é‹ç”¨ãƒ»ç›£è¦–ä½“åˆ¶ã¯ä»¥ä¸‹ã®åŒ…æ‹¬çš„ã‚·ã‚¹ãƒ†ãƒ ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ï¼š

=== ä¸»è¦å®Ÿè£…é …ç›®

* âœ… **ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ **: Prometheus + Grafana + AlertManager
* âœ… **ãƒ­ã‚°ç®¡ç†**: Fluentd + Elasticsearch + Kibana
* âœ… **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬
* âœ… **ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š**: éšå±¤åŒ–ã‚¢ãƒ©ãƒ¼ãƒˆãƒ»é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
* âœ… **å®¹é‡è¨ˆç”»**: æˆé•·äºˆæ¸¬ãƒ»å®¹é‡è­¦å‘Šã‚·ã‚¹ãƒ†ãƒ 
* âœ… **è‡ªå‹•ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹**: æ—¥æ¬¡/é€±æ¬¡/æœˆæ¬¡ã‚¿ã‚¹ã‚¯è‡ªå‹•åŒ–

=== é‹ç”¨ç›®æ¨™é”æˆçŠ¶æ³

[cols="2,2,2", options="header"]
|===
|é …ç›® |ç›®æ¨™å€¤ |å®Ÿè£…æ©Ÿèƒ½
|ã‚µãƒ¼ãƒ“ã‚¹å¯ç”¨æ€§ |99.9% |âœ… ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ + è‡ªå‹•å¾©æ—§
|ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ |< 2ç§’ (95%ile) |âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦– + ã‚¢ãƒ©ãƒ¼ãƒˆ
|éšœå®³å¯¾å¿œæ™‚é–“ |< 30åˆ†å¹³å‡ |âœ… è‡ªå‹•æ¤œçŸ¥ + æ®µéšçš„ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
|ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ |ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆé›¶ä»¶æ•° |âœ… ãƒ­ã‚°åˆ†æ + ç•°å¸¸æ¤œçŸ¥
|===

=== é‹ç”¨æ‰‹é †

1. **æ—¥å¸¸ç›£è¦–**: Grafanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
2. **ã‚¢ãƒ©ãƒ¼ãƒˆå¯¾å¿œ**: é‡è¦åº¦åˆ¥ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ‰‹é †
3. **å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹**: è‡ªå‹•åŒ–ã•ã‚ŒãŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
4. **å®¹é‡ç®¡ç†**: ç¶™ç¶šçš„ãªæˆé•·äºˆæ¸¬ã¨æ‹¡å¼µè¨ˆç”»

---

**ğŸ“ Contact**: team@kanshichan.dev +
**ğŸ”— Repository**: https://github.com/kanshichan/backend +
**ğŸ“… Last Updated**: {docdate} +
**ğŸ“ Document Version**: {revnumber} 