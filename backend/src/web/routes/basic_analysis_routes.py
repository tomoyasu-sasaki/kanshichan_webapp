"""
Basic Analysis API Routes - åŸºæœ¬è¡Œå‹•åˆ†æAPI

åŸºæœ¬çš„ãªè¡Œå‹•åˆ†ææ©Ÿèƒ½ã®APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç¾¤
ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã€ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã€æ—¥æ¬¡ã‚¤ãƒ³ã‚µã‚¤ãƒˆã€æ¨å¥¨äº‹é …ã‚’æä¾›
"""

import logging
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from flask import Blueprint, request, jsonify, current_app

from models.behavior_log import BehaviorLog
from models.user_profile import UserProfile
from utils.logger import setup_logger
from services.ai_ml.llm_service import LLMService
from services.ai_ml.advice_generator import AdviceGenerator
from services.analysis.behavior_analyzer import BehaviorAnalyzer
from .analysis_helpers import (
    generate_comprehensive_insights,
    calculate_behavior_score,
    detect_behavioral_patterns,
    generate_contextual_recommendations,
    calculate_data_quality_metrics
)

logger = setup_logger(__name__)

# Blueprintå®šç¾©
basic_analysis_bp = Blueprint('basic_analysis', __name__, url_prefix='/api/analysis')


@basic_analysis_bp.route('/status', methods=['GET'])
def get_analysis_status():
    """åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹å–å¾—API
    
    åˆ†æã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®å¥åº·çŠ¶æ…‹ã¨ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ³ã‚’è¿”ã™
    
    Returns:
        JSON: åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹æƒ…å ±
    """
    try:
        # å„ã‚µãƒ¼ãƒ“ã‚¹ã®çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
        analyzer_status = 'active' if _get_behavior_analyzer() else 'inactive'
        llm_status = 'active' if _get_llm_service() else 'inactive'
        advanced_analyzer_status = 'active' if _get_advanced_behavior_analyzer() else 'inactive'
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
        try:
            recent_logs = BehaviorLog.get_recent_logs(hours=1)
            db_status = 'active'
        except Exception:
            db_status = 'error'
        
        # å…¨ä½“å¥åº·åº¦è¨ˆç®—
        active_services = sum([
            1 for status in [analyzer_status, llm_status, advanced_analyzer_status, db_status]
            if status == 'active'
        ])
        health_score = active_services / 4.0
        
        return jsonify({
            'status': 'success',
            'data': {
                'overall_status': 'healthy' if health_score >= 0.75 else 'degraded' if health_score >= 0.5 else 'critical',
                'health_score': health_score,
                'services': {
                    'behavior_analyzer': analyzer_status,
                    'llm_service': llm_status,
                    'advanced_analyzer': advanced_analyzer_status,
                    'database': db_status
                },
                'last_check': datetime.utcnow().isoformat()
            },
            'timestamp': datetime.utcnow().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Error checking analysis status: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'error': 'Failed to check analysis system status',
            'code': 'STATUS_CHECK_ERROR',
            'timestamp': datetime.utcnow().isoformat()
        }), 500


@basic_analysis_bp.route('/trends', methods=['GET'])
def get_behavior_trends():
    """è¡Œå‹•ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—API
    
    æŒ‡å®šæœŸé–“ã®è¡Œå‹•ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æã—ã¦è¿”ã™
    
    Query Parameters:
        timeframe (str): åˆ†ææœŸé–“ (hourly/daily/weekly) - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: daily
        user_id (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ID (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
        
    Returns:
        JSON: è¡Œå‹•ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æçµæœ
    """
    try:
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
        timeframe = request.args.get('timeframe', 'daily')
        user_id = request.args.get('user_id')
        
        if timeframe not in ['hourly', 'daily', 'weekly']:
            return jsonify({
                'status': 'error',
                'error': 'Invalid timeframe. Must be one of: hourly, daily, weekly',
                'code': 'VALIDATION_ERROR',
                'timestamp': datetime.utcnow().isoformat()
            }), 400
        
        # BehaviorAnalyzerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—
        analyzer = _get_behavior_analyzer()
        if not analyzer:
            return jsonify({
                'status': 'error',
                'error': 'BehaviorAnalyzer not available',
                'code': 'SERVICE_UNAVAILABLE',
                'timestamp': datetime.utcnow().isoformat()
            }), 500
        
        # æœŸé–“ã«å¿œã˜ãŸãƒ‡ãƒ¼ã‚¿å–å¾—
        hours_map = {'hourly': 1, 'daily': 24, 'weekly': 168}
        hours = hours_map[timeframe]
        
        # è¡Œå‹•ãƒ­ã‚°å–å¾—
        logs = BehaviorLog.get_recent_logs(hours=hours, user_id=user_id)
        
        # Phase 3.2: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†è¿½åŠ 
        if not logs or len(logs) == 0:
            return jsonify({
                'status': 'success',
                'data': {
                    'message': 'ãƒ‡ãƒ¼ã‚¿åé›†ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚',
                    'data_collection_status': 'active',
                    'estimated_wait_time': '2-5åˆ†',
                    'timeframe': timeframe,
                    'period_hours': hours,
                    'logs_count': 0
                },
                'timestamp': datetime.utcnow().isoformat()
            })
        
        # æœ€å°ãƒ‡ãƒ¼ã‚¿è¦ä»¶ãƒã‚§ãƒƒã‚¯
        if len(logs) < 5:
            return jsonify({
                'status': 'success',
                'data': {
                    'message': f'ãƒ‡ãƒ¼ã‚¿åé›†ä¸­ã§ã™ï¼ˆ{len(logs)}ä»¶åé›†æ¸ˆã¿ï¼‰ã€‚ã‚ˆã‚Šè©³ç´°ãªåˆ†æã«ã¯5ä»¶ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚',
                    'data_collection_status': 'active',
                    'estimated_wait_time': '2-3åˆ†',
                    'timeframe': timeframe,
                    'period_hours': hours,
                    'logs_count': len(logs)
                },
                'timestamp': datetime.utcnow().isoformat()
            })
        
        if not logs:
            return jsonify({
                'status': 'success',
                'data': {
                    'message': f'{timeframe}ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“',
                    'timeframe': timeframe,
                    'period_hours': hours,
                    'logs_count': 0
                },
                'timestamp': datetime.utcnow().isoformat()
            })
        
        # é›†ä¸­åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        focus_analysis = analyzer.analyze_focus_pattern(logs)
        
        # ğŸ†• ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ã®è¿½åŠ ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        total_logs = len(logs)
        present_count = sum(1 for log in logs if log.presence_status == 'present')
        smartphone_count = sum(1 for log in logs if log.smartphone_detected)
        
        # focus_analysisã«ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰äº’æ›ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        if focus_analysis and 'error' not in focus_analysis:
            # æ—¢å­˜ã®basic_statisticsã«è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚ã‚‹
            if 'basic_statistics' not in focus_analysis:
                focus_analysis['basic_statistics'] = {}
            
            # åœ¨å¸­ç‡ã®è¨ˆç®—
            presence_rate = present_count / total_logs if total_logs > 0 else 0
            focus_analysis['presence_rate'] = presence_rate
            
            # ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ä½¿ç”¨ç‡ã®è¨ˆç®—
            smartphone_usage_rate = smartphone_count / total_logs if total_logs > 0 else 0
            focus_analysis['smartphone_usage_rate'] = smartphone_usage_rate
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°ï¼ˆæ™‚é–“åˆ¥çµ±è¨ˆã®æ•°ï¼‰
            hourly_sessions = len(focus_analysis.get('hourly_patterns', {}).get('hourly_statistics', {}))
            focus_analysis['total_sessions'] = hourly_sessions
            
            # å¹³å‡é›†ä¸­åº¦ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰äº’æ›ç”¨ï¼‰
            avg_focus = focus_analysis.get('basic_statistics', {}).get('mean', 0)
            focus_analysis['average_focus'] = avg_focus
            
            # è‰¯ã„å§¿å‹¢ã®å‰²åˆï¼ˆé«˜é›†ä¸­åº¦ã®å‰²åˆã‚’ä»£ç”¨ï¼‰
            good_posture_percentage = focus_analysis.get('basic_statistics', {}).get('high_focus_ratio', 0)
            focus_analysis['good_posture_percentage'] = good_posture_percentage
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰äº’æ›ç”¨ï¼‰
            trend_analysis = focus_analysis.get('trend_analysis', {})
            trend_direction_map = {
                'improving': 'up',
                'declining': 'down',
                'stable': 'stable'
            }
            focus_analysis['trend_direction'] = trend_direction_map.get(
                trend_analysis.get('trend', 'stable'), 'stable'
            )
            focus_analysis['trend_percentage'] = trend_analysis.get('trend_strength', 0)
        
        # ç•°å¸¸æ¤œçŸ¥
        anomalies = analyzer.detect_anomalies(logs)
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
        trend_data = {
            'timeframe': timeframe,
            'period_start': logs[-1].timestamp.isoformat() if logs else None,
            'period_end': logs[0].timestamp.isoformat() if logs else None,
            'total_logs': len(logs),
            'focus_analysis': focus_analysis,
            'anomalies': anomalies,
            'trend_summary': _generate_trend_summary(focus_analysis, timeframe)
        }
        
        return jsonify({
            'status': 'success',
            'data': trend_data,
            'timestamp': datetime.utcnow().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Error getting behavior trends: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'error': 'Failed to analyze behavior trends',
            'code': 'ANALYSIS_ERROR',
            'timestamp': datetime.utcnow().isoformat()
        }), 500


@basic_analysis_bp.route('/insights', methods=['GET'])
def get_daily_insights():
    """ä»Šæ—¥ã®æ´å¯Ÿå–å¾—API
    
    ä»Šæ—¥ã®è¡Œå‹•ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç”Ÿæˆã—ãŸã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’è¿”ã™
    
    Query Parameters:
        user_id (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ID (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
        date (str): å¯¾è±¡æ—¥ä»˜ (YYYY-MM-DDå½¢å¼ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä»Šæ—¥)
        
    Returns:
        JSON: ä»Šæ—¥ã®è¡Œå‹•ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
    """
    try:
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
        user_id = request.args.get('user_id')
        date_str = request.args.get('date', datetime.now().strftime('%Y-%m-%d'))
        
        # æ—¥ä»˜ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        try:
            target_date = datetime.strptime(date_str, '%Y-%m-%d')
        except ValueError:
            return jsonify({
                'status': 'error',
                'error': 'Invalid date format. Use YYYY-MM-DD',
                'code': 'VALIDATION_ERROR',
                'timestamp': datetime.utcnow().isoformat()
            }), 400
        
        # BehaviorAnalyzerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—
        analyzer = _get_behavior_analyzer()
        if not analyzer:
            return jsonify({
                'status': 'error',
                'error': 'BehaviorAnalyzer not available',
                'code': 'SERVICE_UNAVAILABLE',
                'timestamp': datetime.utcnow().isoformat()
            }), 500
        
        # å¯¾è±¡æ—¥ã®è¡Œå‹•ãƒ­ã‚°å–å¾—
        start_time = target_date.replace(hour=0, minute=0, second=0, microsecond=0)
        end_time = start_time + timedelta(days=1)
        
        logs = BehaviorLog.get_logs_by_timerange(
            start_time=start_time,
            end_time=end_time,
            user_id=user_id
        )
        
        # Phase 3.2: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†è¿½åŠ 
        if not logs or len(logs) == 0:
            return jsonify({
                'status': 'success',
                'data': {
                    'message': 'ãƒ‡ãƒ¼ã‚¿åé›†ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚',
                    'data_collection_status': 'active',
                    'estimated_wait_time': '2-5åˆ†',
                    'target_date': date_str,
                    'insights': [],
                    'recommendations': []
                },
                'timestamp': datetime.utcnow().isoformat()
            })
        
        # æœ€å°ãƒ‡ãƒ¼ã‚¿è¦ä»¶ãƒã‚§ãƒƒã‚¯
        if len(logs) < 5:
            return jsonify({
                'status': 'success',
                'data': {
                    'message': f'ãƒ‡ãƒ¼ã‚¿åé›†ä¸­ã§ã™ï¼ˆ{len(logs)}ä»¶åé›†æ¸ˆã¿ï¼‰ã€‚ã‚ˆã‚Šè©³ç´°ãªåˆ†æã«ã¯5ä»¶ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚',
                    'data_collection_status': 'active',
                    'estimated_wait_time': '2-3åˆ†',
                    'target_date': date_str,
                    'insights': [],
                    'recommendations': []
                },
                'timestamp': datetime.utcnow().isoformat()
            })
        
        if not logs:
            return jsonify({
                'status': 'success',
                'data': {
                    'message': f'{date_str}ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“',
                    'target_date': date_str,
                    'insights': [],
                    'recommendations': []
                },
                'timestamp': datetime.utcnow().isoformat()
            })
        
        # ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ
        insights_data = analyzer.generate_insights(timeframe='daily')
        
        # LLMã‚µãƒ¼ãƒ“ã‚¹ã§ã‚ˆã‚Šè©³ç´°ãªã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ
        llm_service = _get_llm_service()
        if llm_service:
            behavior_summary = _create_behavior_summary(logs)
            llm_insights = llm_service.generate_behavior_analysis(
                behavior_summary,
                {'date': date_str, 'user_id': user_id}
            )
            insights_data['llm_analysis'] = llm_insights
        
        return jsonify({
            'status': 'success',
            'data': {
                'target_date': date_str,
                'logs_analyzed': len(logs),
                'insights': insights_data,
                'summary': _generate_daily_summary(insights_data, logs)
            },
            'timestamp': datetime.utcnow().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Error getting daily insights: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'error': 'Failed to generate daily insights',
            'code': 'ANALYSIS_ERROR',
            'timestamp': datetime.utcnow().isoformat()
        }), 500


@basic_analysis_bp.route('/recommendations', methods=['GET'])
def get_recommendations():
    """æ¨å¥¨äº‹é …å–å¾—API
    
    ç¾åœ¨ã®è¡Œå‹•çŠ¶æ³ã«åŸºã¥ãæ¨å¥¨äº‹é …ã‚’ç”Ÿæˆã—ã¦è¿”ã™
    
    Query Parameters:
        user_id (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ID (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
        priority (str): å„ªå…ˆåº¦ãƒ•ã‚£ãƒ«ã‚¿ (high/medium/low)
        limit (int): æœ€å¤§è¿”å´æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5)
        
    Returns:
        JSON: æ¨å¥¨äº‹é …ãƒªã‚¹ãƒˆ
    """
    try:
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
        user_id = request.args.get('user_id')
        priority_filter = request.args.get('priority')
        limit = int(request.args.get('limit', 5))
        
        if priority_filter and priority_filter not in ['high', 'medium', 'low']:
            return jsonify({
                'status': 'error',
                'error': 'Invalid priority. Must be one of: high, medium, low',
                'code': 'VALIDATION_ERROR',
                'timestamp': datetime.utcnow().isoformat()
            }), 400
        
        if limit < 1 or limit > 20:
            return jsonify({
                'status': 'error',
                'error': 'Limit must be between 1 and 20',
                'code': 'VALIDATION_ERROR',
                'timestamp': datetime.utcnow().isoformat()
            }), 400
        
        # æœ€è¿‘ã®è¡Œå‹•ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆéå»1æ™‚é–“ï¼‰
        recent_logs = BehaviorLog.get_recent_logs(hours=1, user_id=user_id)
        
        # AdviceGeneratorã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—
        advice_generator = _get_advice_generator()
        if not advice_generator:
            return jsonify({
                'status': 'error',
                'error': 'AdviceGenerator not available',
                'code': 'SERVICE_UNAVAILABLE',
                'timestamp': datetime.utcnow().isoformat()
            }), 500
        
        # ç¾åœ¨ã®è¡Œå‹•çŠ¶æ³ã‚’åˆ†æ
        current_behavior = _analyze_current_behavior(recent_logs)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
        user_profile = None
        if user_id:
            user_profile = UserProfile.get_by_user_id(user_id)
        
        # ã‚¢ãƒ‰ãƒã‚¤ã‚¹ç”Ÿæˆ
        advice_result = advice_generator.generate_contextual_advice(
            current_behavior, user_id
        )
        
        # æ—¢å­˜ã®åˆ†æçµæœã‹ã‚‰è¿½åŠ æ¨å¥¨äº‹é …å–å¾—
        analyzer = _get_behavior_analyzer()
        if analyzer:
            insights = analyzer.generate_insights(timeframe='daily')
            additional_recommendations = insights.get('recommendations', [])
        else:
            additional_recommendations = []
        
        # æ¨å¥¨äº‹é …ã‚’ã¾ã¨ã‚ã¦å„ªå…ˆåº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        all_recommendations = []
        
        # ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ‰ãƒã‚¤ã‚¹
        if advice_result.get('advice_text'):
            all_recommendations.append({
                'type': 'contextual_advice',
                'priority': advice_result.get('priority', 'medium'),
                'message': advice_result['advice_text'],
                'emotion': advice_result.get('emotion', 'encouraging'),
                'source': 'llm_advice',
                'timestamp': advice_result.get('generation_timestamp')
            })
        
        # åˆ†æãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨äº‹é …
        for rec in additional_recommendations:
            all_recommendations.append({
                'type': rec.get('type', 'behavioral'),
                'priority': rec.get('priority', 'medium'),
                'message': rec.get('message', ''),
                'action': rec.get('action', ''),
                'source': 'behavior_analysis',
                'timestamp': datetime.utcnow().isoformat()
            })
        
        # å„ªå…ˆåº¦ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
        if priority_filter:
            all_recommendations = [
                rec for rec in all_recommendations 
                if rec['priority'] == priority_filter
            ]
        
        # å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆã—ã¦ãƒªãƒŸãƒƒãƒˆé©ç”¨
        priority_order = {'high': 0, 'medium': 1, 'low': 2}
        all_recommendations.sort(
            key=lambda x: priority_order.get(x['priority'], 3)
        )
        
        recommendations = all_recommendations[:limit]
        
        return jsonify({
            'status': 'success',
            'data': {
                'recommendations': recommendations,
                'total_available': len(all_recommendations),
                'filtered_by_priority': priority_filter,
                'current_behavior_summary': current_behavior,
                'user_personalized': user_profile is not None
            },
            'timestamp': datetime.utcnow().isoformat()
        })
        
    except ValueError as e:
        return jsonify({
            'status': 'error',
            'error': f'Invalid parameter: {str(e)}',
            'code': 'VALIDATION_ERROR',
            'timestamp': datetime.utcnow().isoformat()
        }), 400
    except Exception as e:
        logger.error(f"Error getting recommendations: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'error': 'Failed to generate recommendations',
            'code': 'ANALYSIS_ERROR',
            'timestamp': datetime.utcnow().isoformat()
        }), 500


# ========== ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ==========

def _get_behavior_analyzer() -> Optional[BehaviorAnalyzer]:
    """BehaviorAnalyzerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    # Phase 3.2: main.pyã§è¨­å®šã—ãŸBehaviorAnalyzerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—
    return current_app.config.get('behavior_analyzer')


def _get_llm_service() -> Optional[LLMService]:
    """LLMServiceã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    config_manager = current_app.config.get('config_manager')
    if not config_manager:
        return None
    
    try:
        config = config_manager.get_all() if hasattr(config_manager, 'get_all') else {}
        return LLMService(config)
    except Exception as e:
        logger.warning(f"Failed to initialize LLMService: {e}")
        return None


def _get_advice_generator() -> Optional[AdviceGenerator]:
    """AdviceGeneratorã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    config_manager = current_app.config.get('config_manager')
    if not config_manager:
        return None
    
    try:
        config = config_manager.get_all() if hasattr(config_manager, 'get_all') else {}
        llm_service = _get_llm_service()
        analyzer = _get_behavior_analyzer()
        
        if not llm_service or not analyzer:
            return None
            
        return AdviceGenerator(llm_service, analyzer, config)
    except Exception as e:
        logger.warning(f"Failed to initialize AdviceGenerator: {e}")
        return None


def _get_advanced_behavior_analyzer() -> Optional[Any]:
    """AdvancedBehaviorAnalyzerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾— - Phase 5.2ã§å¾©æ—§"""
    try:
        # Phase 5.2: å®Ÿéš›ã«AdvancedBehaviorAnalyzerã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ä½¿ç”¨
        from services.ai_ml.advanced_behavior_analyzer import AdvancedBehaviorAnalyzer
        
        config_manager = current_app.config.get('config_manager')
        if not config_manager:
            logger.warning("ConfigManager not available for AdvancedBehaviorAnalyzer")
            return None
        
        # è¨­å®šå–å¾—
        config = config_manager.get_all() if hasattr(config_manager, 'get_all') else {}
        logger.debug("Creating AdvancedBehaviorAnalyzer instance...")
        
        # AdvancedBehaviorAnalyzerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        advanced_analyzer = AdvancedBehaviorAnalyzer(config)
        logger.info("AdvancedBehaviorAnalyzer initialized successfully")
        return advanced_analyzer
        
    except ImportError as e:
        logger.error(f"Failed to import AdvancedBehaviorAnalyzer: {e}")
        return None
    except Exception as e:
        logger.error(f"Failed to initialize AdvancedBehaviorAnalyzer: {e}", exc_info=True)
        return None


def _generate_trend_summary(focus_analysis: Dict[str, Any], timeframe: str) -> Dict[str, Any]:
    """ãƒˆãƒ¬ãƒ³ãƒ‰ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
    basic_stats = focus_analysis.get('basic_statistics', {})
    trend_analysis = focus_analysis.get('trend_analysis', {})
    
    avg_focus = basic_stats.get('mean', 0)
    trend_direction = trend_analysis.get('trend', 'stable')
    
    return {
        'average_focus_level': round(avg_focus, 2),
        'trend_direction': trend_direction,
        'focus_stability': trend_analysis.get('stability', 'medium'),
        'timeframe': timeframe,
        'summary_text': f"{timeframe}ã®å¹³å‡é›†ä¸­åº¦: {avg_focus:.1f}, å‚¾å‘: {trend_direction}"
    }


def _create_behavior_summary(logs: list) -> Dict[str, Any]:
    """è¡Œå‹•ãƒ­ã‚°ã‹ã‚‰è¡Œå‹•ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ"""
    if not logs:
        return {}
    
    total_logs = len(logs)
    focus_scores = [log.focus_level for log in logs if log.focus_level is not None]
    smartphone_count = sum(1 for log in logs if log.smartphone_detected)
    present_count = sum(1 for log in logs if log.presence_status == 'present')
    
    return {
        'total_entries': total_logs,
        'average_focus': sum(focus_scores) / len(focus_scores) if focus_scores else 0,
        'smartphone_usage_rate': smartphone_count / total_logs if total_logs > 0 else 0,
        'presence_rate': present_count / total_logs if total_logs > 0 else 0,
        'session_duration_minutes': total_logs * 0.5,  # 30ç§’é–“éš”ã¨ä»®å®š
        'period_start': logs[-1].timestamp.isoformat() if logs else None,
        'period_end': logs[0].timestamp.isoformat() if logs else None
    }


def _generate_daily_summary(insights_data: Dict[str, Any], logs: list) -> Dict[str, Any]:
    """æ—¥æ¬¡ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
    productivity_analysis = insights_data.get('productivity_analysis', {})
    focus_analysis = insights_data.get('focus_analysis', {})
    
    # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰æœŸå¾…å€¤ã«å¯¾å¿œã—ãŸfocus_scoreã¨productivity_scoreã‚’è¿½åŠ 
    avg_focus = focus_analysis.get('basic_statistics', {}).get('mean', 0)
    productivity_score = productivity_analysis.get('productivity_score', 0)
    
    # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰è¨ˆç®—ã«ã‚ˆã‚‹ç”Ÿç”£æ€§ã‚¹ã‚³ã‚¢ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    if productivity_score == 0 and logs:
        # ä¸€æ™‚çš„ã« behavior_routes ã®é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        try:
            from . import behavior_routes
            productivity_score = behavior_routes._calculate_productivity_score(logs)
        except Exception:
            productivity_score = 0
    
    return {
        'total_active_time': f"{len(logs) * 0.5:.1f} minutes",
        'productivity_score': productivity_score,
        'average_focus': avg_focus,
        'key_insights_count': len(insights_data.get('key_insights', [])),
        'recommendations_count': len(insights_data.get('recommendations', [])),
        'overall_assessment': _assess_daily_performance(insights_data),
        # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰æœŸå¾…å€¤å¯¾å¿œ
        'insights': {
            'focus_score': avg_focus,
            'productivity_score': productivity_score,
            'key_findings': insights_data.get('key_insights', []),
            'improvement_areas': insights_data.get('recommendations', [])
        }
    }


def _analyze_current_behavior(logs: list) -> Dict[str, Any]:
    """ç¾åœ¨ã®è¡Œå‹•çŠ¶æ³ã‚’åˆ†æ"""
    if not logs:
        return {
            'status': 'no_data',
            'focus_level': 0,
            'session_duration_minutes': 0,
            'smartphone_detected': False,
            'presence_status': 'unknown'
        }
    
    recent_log = logs[0]  # æœ€æ–°ã®ãƒ­ã‚°
    
    return {
        'status': 'active',
        'focus_level': recent_log.focus_level or 0,
        'session_duration_minutes': len(logs) * 0.5,
        'smartphone_detected': recent_log.smartphone_detected,
        'presence_status': recent_log.presence_status,
        'last_update': recent_log.timestamp.isoformat()
    }


def _assess_daily_performance(insights_data: Dict[str, Any]) -> str:
    """æ—¥æ¬¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡"""
    productivity_score = insights_data.get('productivity_analysis', {}).get('productivity_score', 0)
    
    if productivity_score >= 0.7:
        return 'excellent'
    elif productivity_score >= 0.5:
        return 'good'
    elif productivity_score >= 0.3:
        return 'average'
    else:
        return 'needs_improvement' 