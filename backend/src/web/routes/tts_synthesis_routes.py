"""
TTS Synthesis API Routes - éŸ³å£°åˆæˆAPI

ãƒ†ã‚­ã‚¹ãƒˆéŸ³å£°åˆæˆæ©Ÿèƒ½ã®APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç¾¤
åŸºæœ¬åˆæˆã€é«˜é€Ÿåˆæˆã€é«˜åº¦åˆæˆæ©Ÿèƒ½ã‚’æä¾›
"""

import os
import logging
import tempfile
import uuid
import contextlib
import io
import time
from typing import Dict, Any, Optional
from datetime import datetime
from pathlib import Path
from flask import Blueprint, request, jsonify, send_file

from services.tts.tts_service import TTSService
from services.voice_manager import VoiceManager
from utils.logger import setup_logger
from utils.exceptions import (
    AudioError, ServiceUnavailableError, ValidationError
)
from web.websocket import (
    broadcast_audio_notification, queue_audio_for_streaming,
    get_connected_clients_count
)
from .tts_helpers import ensure_tqdm_disabled, get_backend_path

logger = setup_logger(__name__)

# Blueprintå®šç¾©
tts_synthesis_bp = Blueprint('tts_synthesis', __name__, url_prefix='/api/tts')

# ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆtts_helpers.pyã§åˆæœŸåŒ–ï¼‰
tts_service: Optional[TTSService] = None
voice_manager: Optional[VoiceManager] = None


def init_synthesis_services(tts_svc: TTSService, vm: VoiceManager) -> None:
    """éŸ³å£°åˆæˆã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
    
    Args:
        tts_svc: TTSServiceã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        vm: VoiceManagerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    global tts_service, voice_manager
    tts_service = tts_svc
    voice_manager = vm


@tts_synthesis_bp.route('/synthesize', methods=['POST'])
def synthesize_speech():
    """ãƒ†ã‚­ã‚¹ãƒˆéŸ³å£°åˆæˆ
    
    Request Body:
        {
            "text": "åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ",
            "language": "ja",  # optional, default: "ja"
            "emotion": "neutral",  # optional, default: "neutral"
            "speed": 1.0,  # optional, default: 1.0
            "pitch": 1.0,  # optional, default: 1.0
            "speaker_sample_id": "file_id",  # optional, for voice cloning
            "return_url": true,  # optional, default: false
            "save_to_cache": true,  # optional, default: true
            "stream_to_clients": false,  # optional, WebSocketé…ä¿¡ã™ã‚‹ã‹
            "target_clients": []  # optional, ç‰¹å®šã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆIDé…ä¿¡
            
            # ä»¥ä¸‹ã€æ–°è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            "cfg_scale": 0.8,  # optional, æ¡ä»¶ä»˜ãç¢ºç‡ã‚¹ã‚±ãƒ¼ãƒ«
            "min_p": 0.0,  # optional, æœ€å°ç¢ºç‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            "seed": 1234,  # optional, ä¹±æ•°ã‚·ãƒ¼ãƒ‰å€¤
            "audio_prefix": "ãˆã£ã¨ã€",  # optional, éŸ³å£°ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹
            "breath_style": true,  # optional, æ¯ç¶™ãã‚¹ã‚¿ã‚¤ãƒ«
            "whisper_style": false,  # optional, ã•ã•ã‚„ãã‚¹ã‚¿ã‚¤ãƒ«
            "style_intensity": 0.5,  # optional, ã‚¹ã‚¿ã‚¤ãƒ«å¼·åº¦
            "noise_reduction": true,  # optional, ãƒã‚¤ã‚ºé™¤å»
            "stream_playback": false,  # optional, ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å†ç”Ÿ
            "speaker_noised": false,  # optional, è©±è€…ãƒã‚¤ã‚ºä»˜ä¸
        }
    
    Returns:
        JSON response with audio file information or binary audio data
    """
    if not tts_service or not voice_manager:
        return jsonify({
            'error': 'service_unavailable',
            'message': 'TTS service is not available'
        }), 503
    
    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
        data = request.get_json()
        text = data.get('text', '').strip()
        language = data.get('language', 'ja')
        emotion = data.get('emotion', 'neutral')
        speed = float(data.get('speed', 1.0))
        pitch = float(data.get('pitch', 1.0))
        speaker_sample_id = data.get('speaker_sample_id')
        return_url = data.get('return_url', False)
        save_to_cache = data.get('save_to_cache', True)
        stream_to_clients = data.get('stream_to_clients', False)
        target_clients = data.get('target_clients', [])
        
        # éŸ³è³ªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
        max_frequency = int(data.get('max_frequency', 24000))  # fmax: æœ€å¤§å‘¨æ³¢æ•°
        audio_quality = float(data.get('audio_quality', 4.0))  # dnsmos_ovrl: éŸ³è³ªã‚¹ã‚³ã‚¢
        vq_score = float(data.get('vq_score', 0.78))          # vqscore_8: VQã‚¹ã‚³ã‚¢
        
        # æ–°è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
        cfg_scale = float(data.get('cfg_scale', 0.8))
        min_p = float(data.get('min_p', 0.0))
        seed = int(data.get('seed', 0)) if data.get('seed') is not None else None
        audio_prefix = data.get('audio_prefix')
        breath_style = data.get('breath_style', False)
        whisper_style = data.get('whisper_style', False)
        style_intensity = float(data.get('style_intensity', 0.5))
        noise_reduction = data.get('noise_reduction', True)
        stream_playback = data.get('stream_playback', False)
        speaker_noised = data.get('speaker_noised', False)
        
        # éŸ³å£°ãƒ¢ãƒ¼ãƒ‰ã®æ˜ç¤ºçš„ãªæŒ‡å®šã‚’ãƒã‚§ãƒƒã‚¯
        tts_mode = data.get('tts_mode', False)
        voice_clone_mode = data.get('voice_clone_mode', False)

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        if not text:
            raise ValidationError("Text is required")
        if len(text) > 1000:
            raise ValidationError("Text is too long (max 1000 characters)")

        # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã®å‡¦ç†
        if audio_prefix and audio_prefix.strip():
            # ç©ºç™½ã‚’é™¤å»ã—ã¦å…ˆé ­ã«è¿½åŠ 
            text = f"{audio_prefix.strip()} {text}"
            logger.info(f"Added audio prefix: '{audio_prefix.strip()}'")

        # éŸ³å£°IDç”Ÿæˆ
        audio_id = str(uuid.uuid4())
        
        # TTSé–‹å§‹é€šçŸ¥
        if stream_to_clients and get_connected_clients_count() > 0:
            broadcast_audio_notification(
                'tts_started',
                f'éŸ³å£°åˆæˆã‚’é–‹å§‹: {text[:50]}...',
                audio_id
            )

        # éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ç”¨ã®ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ãƒ‘ã‚¹å–å¾—
        speaker_sample_path = None
        
        # TTSæ¨™æº–ãƒ¢ãƒ¼ãƒ‰ãŒæ˜ç¤ºçš„ã«æŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³ã‚’ç„¡åŠ¹åŒ–
        if tts_mode:
            logger.info(f"ğŸµ TTSæ¨™æº–ãƒ¢ãƒ¼ãƒ‰æ˜ç¤ºæŒ‡å®š - ãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³ã‚’ç„¡åŠ¹åŒ–")
            speaker_sample_path = None
        elif voice_clone_mode and speaker_sample_id:
            logger.info(f"ğŸ­ ãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ¢ãƒ¼ãƒ‰æ˜ç¤ºæŒ‡å®š")
            if speaker_sample_id == 'default_sample':
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆéŸ³å£°ã‚µãƒ³ãƒ—ãƒ«ï¼ˆsample.wavï¼‰ã‚’ä½¿ç”¨
                default_sample_path = get_backend_path() / 'voice_data/voice_samples/sample.wav'
                if default_sample_path.exists():
                    speaker_sample_path = str(default_sample_path)
                    logger.info("Using default voice sample: sample.wav")
                else:
                    logger.warning("Default sample.wav not found, proceeding without voice cloning")
            else:
                try:
                    speaker_sample_path, _ = voice_manager.get_audio_file(speaker_sample_id)
                    logger.info(f"Using voice sample: {speaker_sample_id}")
                except FileNotFoundError as e:
                    logger.warning(f"Voice sample not found: {speaker_sample_id}, proceeding without voice cloning")
                    speaker_sample_path = None
                except Exception as e:
                    logger.error(f"Error loading voice sample {speaker_sample_id}: {e}, proceeding without voice cloning")
                    speaker_sample_path = None
        elif speaker_sample_id:
            # å¾“æ¥ã®äº’æ›æ€§ã®ãŸã‚ã®å‡¦ç†ï¼ˆãƒ¢ãƒ¼ãƒ‰æŒ‡å®šãªã—ã§ speaker_sample_id ãŒã‚ã‚‹å ´åˆï¼‰
            logger.info(f"ğŸ”„ ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ¢ãƒ¼ãƒ‰ - speaker_sample_id ã«ã‚ˆã‚‹è‡ªå‹•åˆ¤å®š")
            if speaker_sample_id == 'default_sample':
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆéŸ³å£°ã‚µãƒ³ãƒ—ãƒ«ï¼ˆsample.wavï¼‰ã‚’ä½¿ç”¨
                default_sample_path = get_backend_path() / 'voice_data/voice_samples/sample.wav'
                if default_sample_path.exists():
                    speaker_sample_path = str(default_sample_path)
                    logger.info("Using default voice sample: sample.wav")
                else:
                    logger.warning("Default sample.wav not found, proceeding without voice cloning")
            else:
                try:
                    speaker_sample_path, _ = voice_manager.get_audio_file(speaker_sample_id)
                    logger.info(f"Using voice sample: {speaker_sample_id}")
                except FileNotFoundError as e:
                    logger.warning(f"Voice sample not found: {speaker_sample_id}, proceeding without voice cloning")
                    speaker_sample_path = None
                except Exception as e:
                    logger.error(f"Error loading voice sample {speaker_sample_id}: {e}, proceeding without voice cloning")
                    speaker_sample_path = None

        # éŸ³å£°åˆæˆå®Ÿè¡Œ
        processing_mode = "TTSæ¨™æº–" if speaker_sample_path is None else "ãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³"
        logger.info(f"Synthesizing speech: '{text[:50]}...' (emotion: {emotion}, language: {language}, mode: {processing_mode})")
        
        # APIå®Ÿè¡Œæ™‚ã®é€²æ—ãƒãƒ¼ç„¡åŠ¹åŒ–ã‚’ç¢ºå®Ÿã«ã™ã‚‹
        ensure_tqdm_disabled()
        
        # æ¨™æº–å‡ºåŠ›/ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã‚‚æŠ‘åˆ¶ã—ã¦tqdmã®è¡¨ç¤ºã‚’å®Œå…¨ã«é˜²ã
        with contextlib.redirect_stdout(io.StringIO()), \
             contextlib.redirect_stderr(io.StringIO()):
            
            # è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
            advanced_params = {}
            
            # CFGã‚¹ã‚±ãƒ¼ãƒ«ã¨Min-Pï¼ˆæ–°è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
            advanced_params['cfg_scale'] = cfg_scale
            advanced_params['min_p'] = min_p
            
            # ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
            if breath_style:
                advanced_params['breath_style'] = breath_style
                advanced_params['style_intensity'] = style_intensity
                
            if whisper_style:
                advanced_params['whisper_style'] = whisper_style
                advanced_params['style_intensity'] = style_intensity
            
            # è©±è€…ãƒã‚¤ã‚ºè¨­å®š
            if speaker_sample_path:
                if speaker_noised:
                    style_params = {'speaker_noised': True}
                else:
                    style_params = {}
            else:
                style_params = {}
            
            # éŸ³å£°å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            advanced_params['noise_reduction'] = noise_reduction
            
            # ã‚·ãƒ¼ãƒ‰è¨­å®š
            if seed:
                advanced_params['seed'] = int(seed)
            
            output_path = tts_service.generate_speech(
                text=text,
                speaker_sample_path=speaker_sample_path,
                language=language,
                emotion=emotion,
                speed=speed,
                pitch=pitch,
                max_frequency=max_frequency,
                audio_quality=audio_quality,
                vq_score=vq_score,
                **style_params,
                **advanced_params
            )

        # TTSå®Œäº†é€šçŸ¥
        if stream_to_clients and get_connected_clients_count() > 0:
            broadcast_audio_notification(
                'tts_completed',
                f'éŸ³å£°åˆæˆãŒå®Œäº†: {text[:50]}...',
                audio_id
            )

        file_id = None
        if save_to_cache:
            file_id = voice_manager.save_audio_file(
                audio_path=output_path,
                file_type='cache',
                metadata={
                    'audio_id': audio_id,
                    'text_content': text,
                    'emotion': emotion,
                    'language': language,
                    'synthesis_timestamp': datetime.now().isoformat()
                }
            )

        # WebSocketé…ä¿¡ã®å®Ÿè¡Œ
        if stream_to_clients and get_connected_clients_count() > 0:
            stream_metadata = {
                'audio_id': audio_id,
                'file_id': file_id,
                'text_content': text,
                'emotion': emotion,
                'language': language,
                'speed': speed,
                'pitch': pitch,
                'voice_cloned': speaker_sample_path is not None,
                'synthesis_timestamp': datetime.now().isoformat()
            }
            
            # éŸ³å£°é…ä¿¡ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
            queue_audio_for_streaming(output_path, stream_metadata)
            
            logger.info(f"Audio queued for WebSocket streaming: {audio_id}")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼é¸æŠ
        if return_url:
            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¿”ã™
            file_size = os.path.getsize(output_path)
            response = {
                'success': True,
                'audio_id': audio_id,
                'file_id': file_id,
                'file_size': file_size,
                'duration': None,  # å®Ÿè£…æ™‚ã«éŸ³å£°é•·ã‚’è¨ˆç®—å¯èƒ½
                'streamed': stream_to_clients,
                'connected_clients': get_connected_clients_count(),
                'parameters': {
                    'text': text,
                    'language': language,
                    'emotion': emotion,
                    'speed': speed,
                    'pitch': pitch,
                    'voice_cloned': speaker_sample_path is not None
                }
            }
            return jsonify(response)
        else:
            # send_fileå‰ã«ãƒ‘ã‚¹æ¤œè¨¼
            absolute_output_path = os.path.abspath(output_path)
            logger.debug(f"Sending file: {output_path} -> absolute: {absolute_output_path}")
            logger.debug(f"File exists: {os.path.exists(output_path)}")
            
            return send_file(
                output_path,
                as_attachment=True,
                download_name=f'speech_{emotion}_{language}.wav',
                mimetype='audio/wav'
            )
    
    except ValidationError as e:
        logger.warning(f"Validation error in speech synthesis: {e}")
        
        # ã‚¨ãƒ©ãƒ¼é€šçŸ¥
        if stream_to_clients:
            broadcast_audio_notification(
                'tts_error',
                f'éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {str(e)}',
                audio_id if 'audio_id' in locals() else None
            )
        
        return jsonify({
            'error': 'validation_error',
            'message': str(e)
        }), 400
        
    except (AudioError, ServiceUnavailableError) as e:
        logger.error(f"TTS error in speech synthesis: {e}")
        
        # ã‚¨ãƒ©ãƒ¼é€šçŸ¥
        if stream_to_clients:
            broadcast_audio_notification(
                'tts_error',
                f'éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {str(e)}',
                audio_id if 'audio_id' in locals() else None
            )
        
        return jsonify({
            'error': 'synthesis_error',
            'message': str(e)
        }), 500
        
    except Exception as e:
        logger.error(f"Unexpected error in speech synthesis: {e}")
        
        # ã‚¨ãƒ©ãƒ¼é€šçŸ¥
        if stream_to_clients:
            broadcast_audio_notification(
                'tts_error',
                f'äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}',
                audio_id if 'audio_id' in locals() else None
            )
        
        return jsonify({
            'error': 'internal_error',
            'message': 'An unexpected error occurred'
        }), 500


@tts_synthesis_bp.route('/synthesize-fast', methods=['POST'])
def synthesize_speech_fast():
    """é«˜é€Ÿç‰ˆãƒ†ã‚­ã‚¹ãƒˆéŸ³å£°åˆæˆ
    
    Request Body:
        {
            "text": "åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ",
            "language": "ja",  # optional, default: "ja"
            "emotion": "neutral",  # optional, default: "neutral"
            "speed": 1.0,  # optional, default: 1.0
            "pitch": 1.0,  # optional, default: 1.0
            "speaker_sample_id": "file_id",  # optional, for voice cloning
            "return_url": true,  # optional, default: false
            
            # ä»¥ä¸‹ã€æ–°è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            "cfg_scale": 0.8,  # optional, æ¡ä»¶ä»˜ãç¢ºç‡ã‚¹ã‚±ãƒ¼ãƒ«
            "min_p": 0.0,  # optional, æœ€å°ç¢ºç‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            "seed": 1234,  # optional, ä¹±æ•°ã‚·ãƒ¼ãƒ‰å€¤
            "audio_prefix": "ãˆã£ã¨ã€",  # optional, éŸ³å£°ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹
            "breath_style": true,  # optional, æ¯ç¶™ãã‚¹ã‚¿ã‚¤ãƒ«
            "whisper_style": false,  # optional, ã•ã•ã‚„ãã‚¹ã‚¿ã‚¤ãƒ«
            "style_intensity": 0.5,  # optional, ã‚¹ã‚¿ã‚¤ãƒ«å¼·åº¦
            "noise_reduction": true,  # optional, ãƒã‚¤ã‚ºé™¤å»
            "stream_playback": false,  # optional, ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å†ç”Ÿ
            "speaker_noised": false,  # optional, è©±è€…ãƒã‚¤ã‚ºä»˜ä¸
        }
    
    Returns:
        Binary audio data
    """
    if not tts_service or not voice_manager:
        return jsonify({
            'error': 'service_unavailable',
            'message': 'TTS service is not available'
        }), 503
    
    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
        data = request.get_json()
        text = data.get('text', '').strip()
        language = data.get('language', 'ja')
        emotion = data.get('emotion', 'neutral')
        speed = float(data.get('speed', 1.0))
        pitch = float(data.get('pitch', 1.0))
        speaker_sample_id = data.get('speaker_sample_id')
        return_url = data.get('return_url', False)
        
        # éŸ³è³ªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
        max_frequency = int(data.get('max_frequency', 24000))  # fmax: æœ€å¤§å‘¨æ³¢æ•°
        audio_quality = float(data.get('audio_quality', 4.0))  # dnsmos_ovrl: éŸ³è³ªã‚¹ã‚³ã‚¢
        vq_score = float(data.get('vq_score', 0.78))          # vqscore_8: VQã‚¹ã‚³ã‚¢
        
        # æ–°è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
        cfg_scale = float(data.get('cfg_scale', 0.8))
        min_p = float(data.get('min_p', 0.0))
        seed = int(data.get('seed', 0)) if data.get('seed') is not None else None
        audio_prefix = data.get('audio_prefix')
        breath_style = data.get('breath_style', False)
        whisper_style = data.get('whisper_style', False)
        style_intensity = float(data.get('style_intensity', 0.5))
        noise_reduction = data.get('noise_reduction', True)
        stream_playback = data.get('stream_playback', False)
        speaker_noised = data.get('speaker_noised', False)

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæœ€å°é™ï¼‰
        if not text:
            raise ValidationError("Text is required")
        if len(text) > 1000:
            raise ValidationError("Text is too long (max 1000 characters)")

        # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã®å‡¦ç†
        if audio_prefix and audio_prefix.strip():
            # ç©ºç™½ã‚’é™¤å»ã—ã¦å…ˆé ­ã«è¿½åŠ 
            text = f"{audio_prefix.strip()} {text}"
            logger.info(f"Added audio prefix: '{audio_prefix.strip()}'")

        # éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ç”¨ã®ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ãƒ‘ã‚¹å–å¾—
        speaker_sample_path = None
        if speaker_sample_id:
            if speaker_sample_id == 'default_sample':
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆéŸ³å£°ã‚µãƒ³ãƒ—ãƒ«ï¼ˆsample.wavï¼‰ã‚’ä½¿ç”¨
                default_sample_path = get_backend_path() / 'voice_data/voice_samples/sample.wav'
                if default_sample_path.exists():
                    speaker_sample_path = str(default_sample_path)
                    logger.info("Using default voice sample: sample.wav")
                else:
                    logger.warning("Default sample.wav not found, proceeding without voice cloning")
            else:
                try:
                    speaker_sample_path, _ = voice_manager.get_audio_file(speaker_sample_id)
                    logger.info(f"Using voice sample: {speaker_sample_id}")
                except Exception as e:
                    logger.warning(f"Voice sample error: {e}, proceeding without voice cloning")
                    speaker_sample_path = None

        # éŸ³å£°åˆæˆå®Ÿè¡Œï¼ˆé«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼‰
        logger.info(f"Fast synthesizing speech: '{text[:30]}...' (emotion: {emotion})")
        
        # APIå®Ÿè¡Œæ™‚ã®é€²æ—ãƒãƒ¼ç„¡åŠ¹åŒ–ã‚’ç¢ºå®Ÿã«ã™ã‚‹
        ensure_tqdm_disabled()
        
        # æ¨™æº–å‡ºåŠ›/ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã‚‚æŠ‘åˆ¶ã—ã¦tqdmã®è¡¨ç¤ºã‚’å®Œå…¨ã«é˜²ã
        with contextlib.redirect_stdout(io.StringIO()), \
             contextlib.redirect_stderr(io.StringIO()):
            
            # è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
            advanced_params = {}
            
            # CFGã‚¹ã‚±ãƒ¼ãƒ«ã¨Min-Pï¼ˆæ–°è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
            advanced_params['cfg_scale'] = cfg_scale
            advanced_params['min_p'] = min_p
            
            # ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
            if breath_style:
                advanced_params['breath_style'] = breath_style
                advanced_params['style_intensity'] = style_intensity
                
            if whisper_style:
                advanced_params['whisper_style'] = whisper_style
                advanced_params['style_intensity'] = style_intensity
            
            # è©±è€…ãƒã‚¤ã‚ºè¨­å®š
            if speaker_sample_path:
                if speaker_noised:
                    style_params = {'speaker_noised': True}
                else:
                    style_params = {}
            else:
                style_params = {}
            
            # éŸ³å£°å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            advanced_params['noise_reduction'] = noise_reduction
            
            # ã‚·ãƒ¼ãƒ‰è¨­å®š
            if seed:
                advanced_params['seed'] = int(seed)
                
            output_path = tts_service.generate_speech_fast(
                text=text,
                speaker_sample_path=speaker_sample_path,
                language=language,
                emotion=emotion,
                speed=speed,
                pitch=pitch,
                max_frequency=max_frequency,
                audio_quality=audio_quality,
                vq_score=vq_score,
                **style_params,
                **advanced_params
            )

        # ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ï¼ˆæœ€å°é™ï¼‰
        file_id = voice_manager.save_audio_file(
            audio_path=output_path,
            file_type='fast_cache',
            metadata={
                'audio_id': audio_id,
                'text_content': text,
                'language': language,
                'emotion': emotion,
                'speed': speed,
                'pitch': pitch,
                'fast_mode': True,
                'synthesis_timestamp': datetime.now().isoformat()
            }
        )

        # WebSocketé…ä¿¡ï¼ˆç°¡ç´ åŒ–ï¼‰
        if stream_to_clients and get_connected_clients_count() > 0:
            stream_metadata = {
                'audio_id': audio_id,
                'file_id': file_id,
                'text_content': text,
                'language': language,
                'emotion': emotion,
                'speed': speed,
                'pitch': pitch,
                'fast_mode': True,
                'voice_cloned': speaker_sample_path is not None,
                'synthesis_timestamp': datetime.now().isoformat()
            }
            queue_audio_for_streaming(output_path, stream_metadata)
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ
        if return_url:
            file_size = os.path.getsize(output_path)
            response = {
                'success': True,
                'audio_id': audio_id,
                'file_id': file_id,
                'file_size': file_size,
                'fast_mode': True,
                'streamed': stream_to_clients,
                'text_content': text,
                'language': language,
                'emotion': emotion,
                'speed': speed,
                'pitch': pitch,
                'voice_cloned': speaker_sample_path is not None,
                'quality_params': {
                    'max_frequency': max_frequency,
                    'audio_quality': audio_quality,
                    'vq_score': vq_score
                }
            }
            logger.info(f"âœ… Fast synthesis completed: {audio_id}")
            return jsonify(response)
        else:
            # ãƒã‚¤ãƒŠãƒªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥è¿”ã™
            logger.info(f"âœ… Fast synthesis completed, returning binary data: {audio_id}")
            return send_file(
                output_path,
                as_attachment=False,
                download_name=f'tts_fast_{audio_id}.wav',
                mimetype='audio/wav'
            )

    except ValidationError as e:
        logger.warning(f"Fast synthesis validation error: {e}")
        return jsonify({
            'error': 'validation_error',
            'message': str(e)
        }), 400
    except AudioError as e:
        logger.error(f"Fast synthesis audio error: {e}")
        return jsonify({
            'error': 'audio_error',
            'message': str(e)
        }), 500
    except Exception as e:
        logger.error(f"Fast synthesis unexpected error: {e}")
        return jsonify({
            'error': 'internal_error',
            'message': 'Fast synthesis failed due to internal error'
        }), 500


@tts_synthesis_bp.route('/synthesize-advanced', methods=['POST'])
def synthesize_advanced_speech():
    """é«˜åº¦ãªãƒ†ã‚­ã‚¹ãƒˆéŸ³å£°åˆæˆ
    
    Request Body:
        {
            "text": "åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ",
            "language": "ja",
            "emotion": "happy",  # æ„Ÿæƒ…å or ã‚«ã‚¹ã‚¿ãƒ ãƒ™ã‚¯ãƒˆãƒ«
            "emotion_vector": [0.7, 0.1, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0],  # optional
            "emotion_mixing": {  # optional
                "primary_emotion": "happy",
                "secondary_emotion": "excited",
                "primary_weight": 0.7
            },
            "speed": 1.0,
            "pitch": 1.0,
            "speaker_sample_id": "file_id",
            "return_url": true,
            "save_to_cache": true
        }
    
    Returns:
        JSON response with audio file information or binary audio data
    """
    if not tts_service or not voice_manager:
        return jsonify({
            'error': 'service_unavailable',
            'message': 'TTS service is not available'
        }), 503
    
    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
        data = request.get_json()
        if not data or 'text' not in data:
            raise ValidationError("Missing required field: text")
        
        text = data['text'].strip()
        if not text or len(text) > 1000:
            raise ValidationError("Text length must be between 1 and 1000 characters")
        
        # åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
        language = data.get('language', 'ja')
        speed = float(data.get('speed', 1.0))
        pitch = float(data.get('pitch', 1.0))
        speaker_sample_id = data.get('speaker_sample_id')
        return_url = data.get('return_url', False)
        save_to_cache = data.get('save_to_cache', True)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼
        if speed < 0.5 or speed > 2.0:
            raise ValidationError("Speed must be between 0.5 and 2.0")
        if pitch < 0.5 or pitch > 2.0:
            raise ValidationError("Pitch must be between 0.5 and 2.0")
        
        # æ„Ÿæƒ…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é«˜åº¦ãªå‡¦ç†
        emotion = 'neutral'
        emotion_info = {}
        
        if 'emotion_vector' in data:
            # ã‚«ã‚¹ã‚¿ãƒ æ„Ÿæƒ…ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç›´æ¥ä½¿ç”¨
            emotion_vector = data['emotion_vector']
            if len(emotion_vector) != 8:
                raise ValidationError("emotion_vector must have exactly 8 elements")
            emotion = emotion_vector
            emotion_info['type'] = 'custom_vector'
            emotion_info['vector'] = emotion_vector
            
        elif 'emotion_mixing' in data:
            # æ„Ÿæƒ…ãƒŸã‚­ã‚·ãƒ³ã‚°
            mix_data = data['emotion_mixing']
            primary_emotion = mix_data.get('primary_emotion')
            secondary_emotion = mix_data.get('secondary_emotion')
            primary_weight = float(mix_data.get('primary_weight', 0.7))
            
            if not primary_emotion or not secondary_emotion:
                raise ValidationError("emotion_mixing requires primary_emotion and secondary_emotion")
            
            mixed_vector = tts_service.mix_emotions(primary_emotion, secondary_emotion, primary_weight)
            emotion = mixed_vector
            emotion_info['type'] = 'mixed'
            emotion_info['primary_emotion'] = primary_emotion
            emotion_info['secondary_emotion'] = secondary_emotion
            emotion_info['primary_weight'] = primary_weight
            emotion_info['vector'] = mixed_vector
            
        else:
            # é€šå¸¸ã®æ„Ÿæƒ…å
            emotion = data.get('emotion', 'neutral')
            emotion_info['type'] = 'preset'
            emotion_info['emotion_name'] = emotion
        
        # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‚µãƒ³ãƒ—ãƒ«å–å¾—
        speaker_sample_path = None
        if speaker_sample_id:
            if speaker_sample_id == 'default_sample':
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆéŸ³å£°ã‚µãƒ³ãƒ—ãƒ«ï¼ˆsample.wavï¼‰ã‚’ä½¿ç”¨
                default_sample_path = get_backend_path() / 'voice_data/voice_samples/sample.wav'
                if default_sample_path.exists():
                    speaker_sample_path = str(default_sample_path)
                    logger.info("Using default voice sample: sample.wav")
                else:
                    logger.warning("Default sample.wav not found, proceeding without voice cloning")
            else:
                try:
                    speaker_sample_path, _ = voice_manager.get_audio_file(speaker_sample_id)
                    logger.info(f"Using voice sample: {speaker_sample_id}")
                except FileNotFoundError as e:
                    logger.warning(f"Voice sample not found: {speaker_sample_id}, proceeding without voice cloning")
                    speaker_sample_path = None
                except Exception as e:
                    logger.error(f"Error loading voice sample {speaker_sample_id}: {e}, proceeding without voice cloning")
                    speaker_sample_path = None

        # éŸ³å£°åˆæˆå®Ÿè¡Œ
        logger.info(f"Advanced speech synthesis: '{text[:50]}...' (lang: {language}, emotion: {emotion_info})")
        
        # APIå®Ÿè¡Œæ™‚ã®é€²æ—ãƒãƒ¼ç„¡åŠ¹åŒ–ã‚’ç¢ºå®Ÿã«ã™ã‚‹
        ensure_tqdm_disabled()
        
        # æ¨™æº–å‡ºåŠ›/ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã‚‚æŠ‘åˆ¶ã—ã¦tqdmã®è¡¨ç¤ºã‚’å®Œå…¨ã«é˜²ã
        with contextlib.redirect_stdout(io.StringIO()), \
             contextlib.redirect_stderr(io.StringIO()):
            
            # è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
            advanced_params = {}
            
            # CFGã‚¹ã‚±ãƒ¼ãƒ«ã¨Min-Pï¼ˆæ–°è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
            advanced_params['cfg_scale'] = cfg_scale
            advanced_params['min_p'] = min_p
            
            # ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
            if breath_style:
                advanced_params['breath_style'] = breath_style
                advanced_params['style_intensity'] = style_intensity
                
            if whisper_style:
                advanced_params['whisper_style'] = whisper_style
                advanced_params['style_intensity'] = style_intensity
            
            # è©±è€…ãƒã‚¤ã‚ºè¨­å®š
            if speaker_sample_path:
                speaker_noised = data.get('speaker_noised', False)
                if speaker_noised:
                    style_params = {'speaker_noised': True}
                else:
                    style_params = {}
            else:
                style_params = {}
            
            # éŸ³å£°å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            advanced_params['noise_reduction'] = noise_reduction
            
            # ã‚·ãƒ¼ãƒ‰è¨­å®š
            seed = data.get('seed')
            if seed:
                advanced_params['seed'] = int(seed)
            
            output_path = tts_service.generate_speech(
                text=text,
                speaker_sample_path=speaker_sample_path,
                language=language,
                emotion=emotion,
                speed=speed,
                pitch=pitch,
                max_frequency=max_frequency,
                audio_quality=audio_quality,
                vq_score=vq_score,
                **style_params,
                **advanced_params
            )
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        file_id = None
        if save_to_cache:
            file_id = voice_manager.save_audio_file(
                audio_path=output_path,
                file_type='cache',
                metadata={
                    'text_content': text,
                    'emotion_info': emotion_info,
                    'language': language,
                    'advanced_synthesis': True
                }
            )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼é¸æŠ
        if return_url:
            file_size = os.path.getsize(output_path)
            response = {
                'success': True,
                'file_id': file_id,
                'file_size': file_size,
                'parameters': {
                    'text': text,
                    'language': language,
                    'emotion_info': emotion_info,
                    'speed': speed,
                    'pitch': pitch,
                    'voice_cloned': speaker_sample_path is not None,
                    'advanced_synthesis': True
                }
            }
            return jsonify(response)
        else:
            emotion_str = emotion_info.get('emotion_name', 'custom')
            return send_file(
                output_path,
                as_attachment=True,
                download_name=f'advanced_speech_{emotion_str}_{language}.wav',
                mimetype='audio/wav'
            )
    
    except ValidationError as e:
        logger.warning(f"Validation error in advanced speech synthesis: {e}")
        return jsonify({
            'error': 'validation_error',
            'message': str(e)
        }), 400
        
    except (AudioError, ServiceUnavailableError) as e:
        logger.error(f"TTS error in advanced speech synthesis: {e}")
        return jsonify({
            'error': 'synthesis_error',
            'message': str(e)
        }), 500
        
    except Exception as e:
        logger.error(f"Unexpected error in advanced speech synthesis: {e}")
        return jsonify({
            'error': 'internal_error',
            'message': 'An unexpected error occurred'
        }), 500 