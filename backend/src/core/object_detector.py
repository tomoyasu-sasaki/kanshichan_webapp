import cv2
import torch
from ultralytics import YOLO
import mediapipe as mp
import os
import numpy as np
import asyncio
import threading
import time
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from utils.logger import setup_logger
from utils.config_manager import ConfigManager
from utils.exceptions import (
    ModelError, ModelInitializationError, ModelInferenceError,
    YOLOError, MediaPipeError, DetectionError, ConfigError,
    HardwareError, OptimizationError, SmoothingError, wrap_exception
)
from core.ai_optimizer import AIOptimizer
from core.detection_smoother import DetectionSmoother
import shutil
from pathlib import Path
from ultralytics.utils import SETTINGS

logger = setup_logger(__name__)


class ObjectDetector:
    """
    ç‰©ä½“æ¤œå‡ºå°‚é–€ã‚¯ãƒ©ã‚¹
    - YOLOåˆæœŸåŒ–ã¨æ¨è«–
    - MediaPipeåˆæœŸåŒ–ã¨æ¨è«–
    - æ¤œå‡ºçµæœã®çµ±åˆå‡¦ç†
    - æ¤œå‡ºçµæœã®å¹³æ»‘åŒ–ï¼ˆç‚¹æ»…æŠ‘åˆ¶ï¼‰
    - æ¤œå‡ºçµæœã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
    """
    
    def __init__(self, config_manager: Optional[ConfigManager] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            config_manager: è¨­å®šç®¡ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        try:
            self.config_manager = config_manager
            
            # è¨­å®šã‹ã‚‰ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã¨æ¤œå‡ºã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®è¨­å®šã‚’å–å¾—
            self.landmark_settings = {}
            self.detection_objects = {}
            if config_manager:
                self.landmark_settings = config_manager.get_landmark_settings()
                self.detection_objects = config_manager.get_detection_objects()
            
            # æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
            self.use_mediapipe = False
            self.use_yolo = True
            
            # MediaPipeåˆæœŸåŒ–
            self._setup_mediapipe()
            
            # YOLOåˆæœŸåŒ–
            self._setup_yolo()
            
            # AIæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
            try:
                self.ai_optimizer = AIOptimizer(config_manager)
                logger.info("AIOptimizer integrated successfully")
            except Exception as e:
                optimization_error = wrap_exception(
                    e, OptimizationError,
                    "AIOptimizer initialization failed, using standard processing",
                    details={'optimization_disabled': True}
                )
                logger.warning(f"AIOptimizer error: {optimization_error.to_dict()}")
                self.ai_optimizer = None
            
            # æ¤œå‡ºçµæœå¹³æ»‘åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
            try:
                # è¨­å®šã§ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                smoother_enabled = config_manager.get('detection_smoother.enabled', True) if config_manager else True
                if smoother_enabled:
                    self.detection_smoother = DetectionSmoother(config_manager)
                    logger.info("DetectionSmoother integrated successfully")
                else:
                    self.detection_smoother = None
                    logger.info("DetectionSmoother disabled by configuration")
            except Exception as e:
                smoothing_error = wrap_exception(
                    e, SmoothingError,
                    "DetectionSmoother initialization failed, disabling smoothing",
                    details={'smoothing_disabled': True}
                )
                logger.warning(f"DetectionSmoother error: {smoothing_error.to_dict()}")
                self.detection_smoother = None
            
            # æ¤œå‡ºãƒ­ã‚°ä¿å­˜è¨­å®š
            self.log_detections = config_manager.get('detector.log_detections', False) if config_manager else False
            self.camera_id = config_manager.get('camera.id', 'main') if config_manager else 'main'
            self.log_queue = []
            self.log_thread = None
            self.log_thread_running = False
            self.log_interval = config_manager.get('detector.log_interval', 300) if config_manager else 300  # 5åˆ†ã”ã¨
            self.last_summary_time = datetime.utcnow()
            
            # æ¤œå‡ºãƒ­ã‚°ä¿å­˜ã‚¹ãƒ¬ãƒƒãƒ‰ã®èµ·å‹•ï¼ˆè¨­å®šãŒæœ‰åŠ¹ãªå ´åˆï¼‰
            if self.log_detections:
                self._start_log_thread()
            
            logger.info("ObjectDetector initialized successfully.")
            
        except Exception as e:
            init_error = wrap_exception(
                e, ModelInitializationError,
                "ObjectDetector initialization failed, disabling all detection systems",
                details={
                    'mediapipe_disabled': True,
                    'yolo_disabled': True,
                    'fallback_mode': True
                }
            )
            logger.error(f"Critical initialization error: {init_error.to_dict()}")
            # åˆæœŸåŒ–ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¸¡æ–¹ç„¡åŠ¹ã«ã™ã‚‹
            self.use_mediapipe = False
            self.use_yolo = False
            logger.critical("Disabling both MediaPipe and YOLO due to critical error during initialization.")

    def _setup_mediapipe(self) -> None:
        """MediaPipeã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–"""
        if self.config_manager:
            self.use_mediapipe = self.config_manager.get('detector.use_mediapipe', False)
            logger.info(f"MediaPipe status from config: {'enabled' if self.use_mediapipe else 'disabled'}")
        
        if not self.use_mediapipe:
            logger.info("MediaPipe usage is disabled in config.")
            return
            
        try:
            # MediaPipeå†…éƒ¨ã®è­¦å‘Šã‚’æŠ‘åˆ¶
            os.environ["MEDIAPIPE_DISABLE_GPU"] = "1"  # GPUã‚’ç„¡åŠ¹åŒ–ã—ã¦å®‰å®šæ€§å‘ä¸Š
            
            # MediaPipeè­¦å‘ŠæŠ‘åˆ¶ã®ãŸã‚ã®è¿½åŠ è¨­å®š
            os.environ["GLOG_minloglevel"] = "2"  # ERRORä»¥ä¸Šã®ãƒ­ã‚°ã®ã¿è¡¨ç¤º
            os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"  # TensorFlowè­¦å‘ŠæŠ‘åˆ¶
            
            self.mp_pose = mp.solutions.pose
            self.mp_hands = mp.solutions.hands
            self.mp_face_mesh = mp.solutions.face_mesh
            self.mp_drawing = mp.solutions.drawing_utils
            self.mp_drawing_styles = mp.solutions.drawing_styles
            
            # Poseãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆè­¦å‘Šè»½æ¸›è¨­å®šï¼‰
            self.pose = self.mp_pose.Pose(
                static_image_mode=False,
                model_complexity=0,  # è»½é‡ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
                smooth_landmarks=True,
                min_detection_confidence=0.7,  # ä¿¡é ¼åº¦é–¾å€¤ã‚’ä¸Šã’ã‚‹
                min_tracking_confidence=0.7,   # ä¿¡é ¼åº¦é–¾å€¤ã‚’ä¸Šã’ã‚‹
                enable_segmentation=False
            )
            logger.info("MediaPipe Pose model initialized with warning suppression")
            
            # Handsãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆè¨­å®šãŒæœ‰åŠ¹ãªå ´åˆï¼‰
            if self.landmark_settings.get('hands', {}).get('enabled', False):
                self.hands = self.mp_hands.Hands(
                    static_image_mode=False,
                    max_num_hands=2,
                    min_detection_confidence=0.5,
                    min_tracking_confidence=0.5
                )
                logger.info("MediaPipe Hands model initialized successfully")
            
            # Face Meshãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆè¨­å®šãŒæœ‰åŠ¹ãªå ´åˆï¼‰
            if self.landmark_settings.get('face', {}).get('enabled', False):
                self.face_mesh = self.mp_face_mesh.FaceMesh(
                    static_image_mode=False,
                    max_num_faces=1,
                    refine_landmarks=True,
                    min_detection_confidence=0.5,
                    min_tracking_confidence=0.5
                )
                logger.info("MediaPipe Face Mesh model initialized successfully")
                
        except Exception as e:
            mediapipe_error = wrap_exception(
                e, MediaPipeError,
                "MediaPipe components initialization failed",
                details={
                    'component_disabled': True,
                    'gpu_disabled': True,
                    'config_settings': self.landmark_settings
                }
            )
            logger.error(f"MediaPipe initialization error: {mediapipe_error.to_dict()}")
            self.use_mediapipe = False

    def _setup_yolo(self) -> None:
        """YOLOç‰©ä½“æ¤œå‡ºå™¨ã®åˆæœŸåŒ–"""
        if self.config_manager:
            self.use_yolo = self.config_manager.get('detector.use_yolo', True)
        
        if not self.use_yolo:
            logger.info("YOLO object detector is disabled.")
            return
            
        try:
            # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¨­å®š
            model_name = self.config_manager.get('models.yolo.model_name', 'yolov8n.pt') if self.config_manager else 'yolov8n.pt'
            
            # ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
            if self.config_manager:
                models_dir_rel = self.config_manager.get('models.yolo.models_dir', 'models')
                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
                project_root = Path(__file__).resolve().parent.parent.parent
                models_dir = project_root / models_dir_rel
            else:
                # è¨­å®šãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’ä½¿ç”¨
                project_root = Path(__file__).resolve().parent.parent.parent
                models_dir = project_root / "models"
            
            # ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
            os.makedirs(models_dir, exist_ok=True)
            
            # ãƒ¢ãƒ‡ãƒ«ã®çµ¶å¯¾ãƒ‘ã‚¹ã‚’è¨­å®š
            model_path = models_dir / model_name
            
            # ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä¿å­˜
            if not model_path.exists():
                logger.warning(f"YOLOãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}ã€‚'{model_name}' ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™...")
                self.model = YOLO(model_name)  # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ

                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‰€å®šã®å ´æ‰€ã«ã‚³ãƒ”ãƒ¼
                weights_dir = Path(SETTINGS['weights_dir'])
                source_model_path = weights_dir / model_name
                
                if source_model_path.exists():
                    logger.info(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã—ã¾ã™: {source_model_path} -> {model_path}")
                    shutil.copy(source_model_path, model_path)
                    logger.info(f"ãƒ¢ãƒ‡ãƒ«ã‚’æ­£å¸¸ã«ä¿å­˜ã—ã¾ã—ãŸ: {model_path}")
                else:
                    logger.error(f"ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source_model_path}")

            else:
                logger.info(f"æ—¢å­˜ã®YOLOãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™: {model_path}")

            # ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ï¼‰
            self.model = YOLO(str(model_path))
            
            # YOLOãƒ¢ãƒ‡ãƒ«ã®æœ€é©åŒ–è¨­å®š
            self.model.verbose = False
            
            # NMSå‡¦ç†æœ€é©åŒ– - è­¦å‘Šè»½æ¸›ã®ãŸã‚ã®è¨­å®š
            self.yolo_predict_args = {
                'verbose': False,           # è©³ç´°ãƒ­ã‚°ç„¡åŠ¹åŒ–
                'conf': 0.5,               # ä¿¡é ¼åº¦é–¾å€¤
                'iou': 0.7,                # IoUé–¾å€¤ï¼ˆNMSå‡¦ç†ï¼‰
                'max_det': 10,             # æœ€å¤§æ¤œå‡ºæ•°åˆ¶é™ï¼ˆNMSè»½é‡åŒ–ï¼‰
                'agnostic_nms': False,     # ã‚¯ãƒ©ã‚¹åˆ¥NMS
                'save': False,             # çµæœä¿å­˜ç„¡åŠ¹
                'save_txt': False,         # ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜ç„¡åŠ¹
                'save_conf': False,        # ä¿¡é ¼åº¦ä¿å­˜ç„¡åŠ¹
                'save_crop': False,        # ã‚¯ãƒ­ãƒƒãƒ—ä¿å­˜ç„¡åŠ¹
                'show': False,             # è¡¨ç¤ºç„¡åŠ¹
                'half': False,             # åŠç²¾åº¦è¨ˆç®—ï¼ˆCPUã§ã¯ç„¡åŠ¹ï¼‰
            }
            
            # ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š
            if torch.backends.mps.is_built():
                self.device = torch.device("mps")
            elif torch.cuda.is_available():
                self.device = torch.device("cuda")
            else:
                self.device = torch.device("cpu")
            
            logger.info(f"Using device: {self.device}")
            self.model.to(self.device)
            logger.info("YOLO initialized with NMS optimization settings")
            
        except Exception as e:
            # KeyError / TypeError ãªã©å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç³»ã¯ recoverable
            data_error_classes = (KeyError, AttributeError, TypeError, ValueError)
            critical = not isinstance(e, data_error_classes)

            yolo_runtime_error = wrap_exception(
                e, YOLOError,
                "YOLO object detection runtime error",
                details={
                    'frame_shape': frame.shape if frame is not None else None,
                    'model_available': hasattr(self, 'model'),
                    'device': str(self.device) if hasattr(self, 'device') else 'unknown',
                    'yolo_disabled': critical
                }
            )
            logger.error(f"YOLO runtime error: {yolo_runtime_error.to_dict()}")

            if critical:
                # ãƒ¢ãƒ‡ãƒ«ç ´æãªã©è‡´å‘½çš„ãªå ´åˆã®ã¿ç„¡åŠ¹åŒ–
                self.use_yolo = False
                logger.warning("Disabling YOLO due to critical runtime error.")
            else:
                # recoverable ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯æ¬¡ãƒ•ãƒ¬ãƒ¼ãƒ ã§å†è©¦è¡Œ
                logger.warning("Recoverable YOLO data error; keeping YOLO enabled.")

    def detect_objects(self, frame: np.ndarray) -> Dict[str, Any]:
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã®ç‰©ä½“ã‚’æ¤œå‡º
        
        Args:
            frame: æ¤œå‡ºå¯¾è±¡ã®ç”»åƒãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            æ¤œå‡ºçµæœã‚’å«ã‚€è¾æ›¸
        """
        if frame is None or frame.size == 0:
            logger.warning("Empty frame received for object detection")
            return self._create_empty_results()
            
        try:
            # AIã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ãŒã‚ã‚‹å ´åˆã€æœ€é©åŒ–å‡¦ç†ã‚’é©ç”¨
            if self.ai_optimizer:
                # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—åˆ¤å®š
                if self.ai_optimizer.should_skip_frame():
                    return self._create_empty_results()
                    
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°é–‹å§‹
                self.ai_optimizer.start_inference_timer()
                
            # çµæœæ ¼ç´ç”¨è¾æ›¸
            results = {
                'detections': {},             # ã‚¯ãƒ©ã‚¹å â†’ List[detection]
                'timestamp': datetime.now().isoformat(),
                'frame_id': id(frame),
                'mediapipe_results': {},
                'yolo_results': {},
                'person_detected': False     # äººç‰©æ¤œå‡ºãƒ•ãƒ©ã‚°ã‚’æ˜ç¤ºçš„ã«åˆæœŸåŒ–
            }
            
            # MediaPipeæ¤œå‡ºï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰
            if self.use_mediapipe:
                # RGBå¤‰æ›ï¼ˆMediaPipeã¯RGBã‚’ä½¿ç”¨ï¼‰
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                self._detect_with_mediapipe(rgb_frame, results)
            
            # YOLOæ¤œå‡ºï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰
            if self.use_yolo:
                self._detect_with_yolo_bgr(frame, results)
            
            # æ¤œå‡ºçµæœã®å¹³æ»‘åŒ–å‡¦ç†ï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰
            if self.detection_smoother:
                results = self.detection_smoother.smooth_detections(results)
            
            # AIã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ãŒã‚ã‚‹å ´åˆã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šçµ‚äº†
            if self.ai_optimizer:
                self.ai_optimizer.end_inference_timer()
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’çµæœã«è¿½åŠ 
                performance_metrics = self.ai_optimizer.get_performance_metrics()
                results['performance'] = performance_metrics
                
            # æ¤œå‡ºãƒ­ã‚°ä¿å­˜ï¼ˆè¨­å®šãŒæœ‰åŠ¹ãªå ´åˆï¼‰
            if self.log_detections and results.get('detections'):
                self._queue_detection_logs(results)
                
            return results
            
        except Exception as e:
            detection_error = wrap_exception(
                e, DetectionError,
                "Error during object detection",
                details={'frame_shape': frame.shape if frame is not None else None}
            )
            logger.error(f"Detection error: {detection_error.to_dict()}")
            return self._create_empty_results()

    def _detect_with_mediapipe(self, rgb_frame: np.ndarray, results: Dict[str, Any]) -> None:
        """
        MediaPipeã‚’ä½¿ç”¨ã—ãŸæ¤œå‡ºå‡¦ç†
        
        Args:
            rgb_frame: RGBå½¢å¼ã®ãƒ•ãƒ¬ãƒ¼ãƒ 
            results: æ¤œå‡ºçµæœã‚’æ ¼ç´ã™ã‚‹è¾æ›¸
        """
        # Poseæ¤œå‡º
        if hasattr(self, 'pose'):
            try:
                # AIæœ€é©åŒ–ã‚’ä½¿ç”¨ã—ãŸæ¨è«–
                if self.ai_optimizer:
                    pose_results = self.ai_optimizer.optimize_mediapipe_pipeline(self.pose, rgb_frame)
                else:
                    # æ¨™æº–æ¨è«–
                    pose_results = self.pose.process(rgb_frame)
                if pose_results and pose_results.pose_landmarks:
                    results['person_detected'] = True
                    if self.landmark_settings.get('pose', {}).get('enabled', False):
                        results['pose_landmarks'] = pose_results.pose_landmarks
                        logger.debug(f"Pose landmarks detected and added to results")
            except Exception as e:
                pose_error = wrap_exception(
                    e, MediaPipeError,
                    "MediaPipe pose detection failed",
                    details={'detection_type': 'pose'}
                )
                logger.error(f"Pose detection error: {pose_error.to_dict()}")
        
        # Handsæ¤œå‡º
        if (hasattr(self, 'hands') and 
            self.landmark_settings.get('hands', {}).get('enabled', False)):
            try:
                hands_results = self.hands.process(rgb_frame)
                if hands_results and hands_results.multi_hand_landmarks:
                    results['hands_landmarks'] = hands_results.multi_hand_landmarks
                    logger.debug(f"Hands landmarks detected and added to results")
            except Exception as e:
                hands_error = wrap_exception(
                    e, MediaPipeError,
                    "MediaPipe hands detection failed",
                    details={'detection_type': 'hands'}
                )
                logger.error(f"Hands detection error: {hands_error.to_dict()}")
        
        # Faceæ¤œå‡º
        if (hasattr(self, 'face_mesh') and 
            self.landmark_settings.get('face', {}).get('enabled', False)):
            try:
                face_results = self.face_mesh.process(rgb_frame)
                if face_results and face_results.multi_face_landmarks:
                    results['face_landmarks'] = face_results.multi_face_landmarks
                    logger.debug(f"Face landmarks detected and added to results")
            except Exception as e:
                face_error = wrap_exception(
                    e, MediaPipeError,
                    "MediaPipe face detection failed",
                    details={'detection_type': 'face'}
                )
                logger.error(f"Face detection error: {face_error.to_dict()}")

    def _detect_with_yolo_bgr(self, frame: np.ndarray, results: Dict[str, Any]) -> None:
        """
        YOLOã‚’ä½¿ç”¨ã—ãŸç‰©ä½“æ¤œå‡ºå‡¦ç†ï¼ˆåº§æ¨™çµ±ä¸€ç‰ˆï¼‰
        
        Args:
            frame: BGRå½¢å¼ã®ãƒ•ãƒ¬ãƒ¼ãƒ 
            results: æ¤œå‡ºçµæœã‚’æ ¼ç´ã™ã‚‹è¾æ›¸
        """
        try:
            # ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚ºã‚’ä¿æŒ
            original_height, original_width = frame.shape[:2]
            
            # AIæœ€é©åŒ–ã§ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚ºãŒå¤‰æ›´ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€
            # YOLOã§ã‚‚åŒã˜æœ€é©åŒ–ã‚’é©ç”¨ã—ã¦åº§æ¨™ç³»ã‚’çµ±ä¸€
            yolo_frame = frame
            scale_x, scale_y = 1.0, 1.0
            
            if self.ai_optimizer:
                # MediaPipeã¨åŒã˜ãƒ•ãƒ¬ãƒ¼ãƒ æœ€é©åŒ–ã‚’é©ç”¨
                yolo_frame = self.ai_optimizer._optimize_frame_preprocessing(frame)
                # ã‚¹ã‚±ãƒ¼ãƒ«æ¯”ã‚’è¨ˆç®—
                yolo_height, yolo_width = yolo_frame.shape[:2]
                scale_x = original_width / yolo_width
                scale_y = original_height / yolo_height
                
                # YOLOæ¨è«–ï¼ˆæœ€é©åŒ–è¨­å®šé©ç”¨ï¼‰
                yolo_results = self.ai_optimizer.optimize_yolo_inference(self.model, yolo_frame)
                # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸå ´åˆã¯NoneãŒè¿”ã•ã‚Œã‚‹
                if yolo_results is None:
                    return
                yolo_results = yolo_results[0]
            else:
                # æ¨™æº–æ¨è«–ï¼ˆNMSæœ€é©åŒ–è¨­å®šé©ç”¨ï¼‰
                yolo_results = self.model(yolo_frame, **self.yolo_predict_args)[0]
            
            # YOLOã§ã®äººç‰©æ¤œå‡ºï¼ˆMediaPipeã§æœªæ¤œå‡ºã®å ´åˆã®ã¿ãƒã‚§ãƒƒã‚¯ï¼‰
            if not results['person_detected']:
                for det in yolo_results.boxes.data.tolist():
                    x1, y1, x2, y2, conf, cls = det
                    class_name = yolo_results.names[int(cls)]
                    if class_name == 'person' and conf > 0.5:
                        results['person_detected'] = True
                        break
            
            # ãã®ä»–ã®ç‰©ä½“æ¤œå‡º
            for obj_key, obj_settings in self.detection_objects.items():
                if not obj_settings.get('enabled', False):
                    continue
                    
                detections = []
                for det in yolo_results.boxes.data.tolist():
                    x1, y1, x2, y2, conf, cls = det
                    detected_class = yolo_results.names[int(cls)]
                    
                    if (detected_class == obj_settings.get('class_name') and 
                        conf > obj_settings.get('confidence_threshold', 0.5)):
                        
                        # åº§æ¨™ã‚’ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚ºã«ã‚¹ã‚±ãƒ¼ãƒ«ãƒãƒƒã‚¯
                        scaled_x1 = int(x1 * scale_x)
                        scaled_y1 = int(y1 * scale_y)
                        scaled_x2 = int(x2 * scale_x)
                        scaled_y2 = int(y2 * scale_y)
                        
                        # ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³æ¤œå‡ºæ™‚ã¯ç‰¹åˆ¥ã«INFOãƒ¬ãƒ™ãƒ«ã§ãƒ­ã‚°å‡ºåŠ›
                        if obj_key == 'smartphone':
                            logger.debug(f"ğŸ“± ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³æ¤œå‡º: {obj_settings.get('name')} (ä¿¡é ¼åº¦: {conf:.3f}, åº§æ¨™: ({scaled_x1}, {scaled_y1}, {scaled_x2}, {scaled_y2}))")
                        else:
                            logger.debug(f"ç‰©ä½“ã‚’æ¤œå‡º: {obj_settings.get('name')} (confidence: {conf:.3f}, bbox: ({scaled_x1}, {scaled_y1}, {scaled_x2}, {scaled_y2}))")
                        
                        detections.append({
                            'bbox': (scaled_x1, scaled_y1, scaled_x2, scaled_y2),
                            'confidence': conf
                        })
                        
                if detections:
                    results['detections'][obj_key] = detections
                    
        except Exception as e:
            yolo_runtime_error = wrap_exception(
                e, YOLOError,
                "YOLO object detection runtime error",
                details={
                    'frame_shape': frame.shape if frame is not None else None,
                    'model_available': hasattr(self, 'model'),
                    'device': str(self.device) if hasattr(self, 'device') else 'unknown',
                    'yolo_disabled': True
                }
            )
            logger.error(f"YOLO runtime error: {yolo_runtime_error.to_dict()}")
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã‚‰YOLOã‚’ç„¡åŠ¹åŒ–
            self.use_yolo = False
            logger.warning("Disabling YOLO due to runtime error.")

    def get_detection_status(self) -> Dict[str, Any]:
        """
        æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹æƒ…å ±ã‚’å–å¾—
        
        Returns:
            Dict[str, Any]: çŠ¶æ…‹æƒ…å ±
        """
        status = {
            'use_mediapipe': self.use_mediapipe,
            'use_yolo': self.use_yolo,
            'has_pose_model': hasattr(self, 'pose') if self.use_mediapipe else False,
            'has_hands_model': hasattr(self, 'hands') if self.use_mediapipe else False,
            'has_face_model': hasattr(self, 'face_mesh') if self.use_mediapipe else False,
            'has_yolo_model': hasattr(self, 'model') if self.use_yolo else False,
            'device': str(self.device) if hasattr(self, 'device') else 'unknown',
            'landmark_settings': self.landmark_settings,
            'detection_objects': self.detection_objects
        }
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’è¿½åŠ 
        if self.ai_optimizer:
            status['performance'] = self.ai_optimizer.get_performance_stats()
        
        return status

    def reload_settings(self) -> None:
        """
        è¨­å®šã‚’å†èª­ã¿è¾¼ã¿ã—ã¦æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã‚’å†åˆæœŸåŒ–
        """
        logger.info("Reloading ObjectDetector settings...")
        if self.config_manager:
            self.landmark_settings = self.config_manager.get_landmark_settings()
            self.detection_objects = self.config_manager.get_detection_objects()
            self.use_mediapipe = self.config_manager.get('detector.use_mediapipe', False)
            self.use_yolo = self.config_manager.get('detector.use_yolo', True)
            logger.info(f"Settings reloaded: MediaPipe={'enabled' if self.use_mediapipe else 'disabled'}, YOLO={'enabled' if self.use_yolo else 'disabled'}")
        else:
            logger.warning("ConfigManager not available, cannot reload settings.") 

    def _queue_detection_logs(self, results: Dict[str, Any]) -> None:
        """
        æ¤œå‡ºçµæœã‚’ãƒ­ã‚°ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
        
        Args:
            results: æ¤œå‡ºçµæœ
        """
        try:
            frame_id = results.get('frame_id', 0)
            timestamp = datetime.utcnow()
            
            # å„æ¤œå‡ºã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
            for detection in results.get('detections', []):
                log_entry = {
                    'timestamp': timestamp,
                    'camera_id': self.camera_id,
                    'frame_id': frame_id,
                    'object_class': detection.get('class_name', 'unknown'),
                    'confidence': detection.get('confidence', 0.0),
                    'bbox': detection.get('bbox', (0, 0, 0, 0)),
                    'is_smoothed': detection.get('is_smoothed', False),
                    'is_interpolated': detection.get('is_interpolated', False),
                    'additional_data': {
                        'performance': results.get('performance', {})
                    }
                }
                self.log_queue.append(log_entry)
                
            # ã‚­ãƒ¥ãƒ¼ãŒä¸€å®šã‚µã‚¤ã‚ºã‚’è¶…ãˆãŸã‚‰å³æ™‚ä¿å­˜
            if len(self.log_queue) >= 100:
                self._save_detection_logs_async()
                
            # ã‚µãƒãƒªãƒ¼ä½œæˆæ™‚é–“ãƒã‚§ãƒƒã‚¯
            current_time = datetime.utcnow()
            if (current_time - self.last_summary_time).total_seconds() >= self.log_interval:
                self._create_detection_summary_async()
                self.last_summary_time = current_time
                
        except Exception as e:
            logger.error(f"Error queueing detection logs: {str(e)}")
    
    def _start_log_thread(self) -> None:
        """æ¤œå‡ºãƒ­ã‚°ä¿å­˜ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹"""
        if self.log_thread_running:
            return
            
        self.log_thread_running = True
        self.log_thread = threading.Thread(target=self._log_thread_worker, daemon=True)
        self.log_thread.start()
        logger.info("Detection log thread started")
    
    def _log_thread_worker(self) -> None:
        """æ¤œå‡ºãƒ­ã‚°ä¿å­˜ã‚¹ãƒ¬ãƒƒãƒ‰ã®ãƒ¯ãƒ¼ã‚«ãƒ¼é–¢æ•°"""
        try:
            while self.log_thread_running:
                # å®šæœŸçš„ã«ãƒ­ã‚°ã‚’ä¿å­˜
                if self.log_queue:
                    self._save_detection_logs_sync()
                
                # ã‚¹ãƒ¬ãƒƒãƒ‰ä¼‘æ­¢
                time.sleep(10)  # 10ç§’ã”ã¨ã«ãƒã‚§ãƒƒã‚¯
                
        except Exception as e:
            logger.error(f"Error in log thread worker: {str(e)}")
        finally:
            logger.info("Detection log thread stopped")
    
    def _save_detection_logs_async(self) -> None:
        """æ¤œå‡ºãƒ­ã‚°ã‚’éåŒæœŸã§ä¿å­˜ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ï¼‰"""
        if not self.log_queue:
            return
            
        # ã‚­ãƒ¥ãƒ¼ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦ç©ºã«ã™ã‚‹
        queue_copy = self.log_queue.copy()
        self.log_queue = []
        
        # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§ä¿å­˜å‡¦ç†ã‚’å®Ÿè¡Œ
        thread = threading.Thread(
            target=self._save_logs_to_db,
            args=(queue_copy,),
            daemon=True
        )
        thread.start()
    
    def _save_detection_logs_sync(self) -> None:
        """æ¤œå‡ºãƒ­ã‚°ã‚’åŒæœŸçš„ã«ä¿å­˜ï¼ˆãƒ­ã‚°ã‚¹ãƒ¬ãƒƒãƒ‰å†…ã§ä½¿ç”¨ï¼‰"""
        if not self.log_queue:
            return
            
        # ã‚­ãƒ¥ãƒ¼ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦ç©ºã«ã™ã‚‹
        queue_copy = self.log_queue.copy()
        self.log_queue = []
        
        # DBã«ä¿å­˜
        self._save_logs_to_db(queue_copy)
    
    def _save_logs_to_db(self, log_entries: List[Dict[str, Any]]) -> None:
        """
        æ¤œå‡ºãƒ­ã‚°ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        
        Args:
            log_entries: ä¿å­˜ã™ã‚‹æ¤œå‡ºãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®ãƒªã‚¹ãƒˆ
        """
        try:
            # ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆå¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆå›é¿ã®ãŸã‚ï¼‰
            from models.detection_log import DetectionLog
            
            # å„ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’DBã«ä¿å­˜
            for entry in log_entries:
                log = DetectionLog.create_from_detection(
                    camera_id=entry['camera_id'],
                    frame_id=entry['frame_id'],
                    object_class=entry['object_class'],
                    confidence=entry['confidence'],
                    bbox=entry['bbox'],
                    is_smoothed=entry['is_smoothed'],
                    is_interpolated=entry['is_interpolated'],
                    additional_data=entry['additional_data']
                )
                log.save()
                
            logger.debug(f"Saved {len(log_entries)} detection logs to database")
            
        except Exception as e:
            logger.error(f"Error saving detection logs to database: {str(e)}")
    
    def _create_detection_summary_async(self) -> None:
        """æ¤œå‡ºã‚µãƒãƒªãƒ¼ã‚’éåŒæœŸã§ä½œæˆ"""
        # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã‚µãƒãƒªãƒ¼ä½œæˆå‡¦ç†ã‚’å®Ÿè¡Œ
        thread = threading.Thread(
            target=self._create_detection_summary,
            daemon=True
        )
        thread.start()
    
    def _create_detection_summary(self) -> None:
        """æ¤œå‡ºã‚µãƒãƒªãƒ¼ã‚’ä½œæˆã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        try:
            # ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆå¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆå›é¿ã®ãŸã‚ï¼‰
            from models.detection_log import DetectionLog
            from models.detection_summary import DetectionSummary
            
            # é›†è¨ˆæœŸé–“
            end_time = datetime.utcnow()
            start_time = self.last_summary_time
            
            # æœŸé–“å†…ã®ãƒ­ã‚°ã‚’å–å¾—
            logs = DetectionLog.query.filter(
                DetectionLog.timestamp >= start_time,
                DetectionLog.timestamp <= end_time,
                DetectionLog.camera_id == self.camera_id
            ).all()
            
            if not logs:
                logger.debug("No detection logs found for summary creation")
                return
                
            # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¯ãƒ©ã‚¹åˆ¥ã®é›†è¨ˆ
            object_stats = {}
            total_frames = len(set(log.frame_id for log in logs))
            
            for log in logs:
                obj_class = log.object_class
                if obj_class not in object_stats:
                    object_stats[obj_class] = {'count': 0, 'confidence_sum': 0.0}
                    
                object_stats[obj_class]['count'] += 1
                object_stats[obj_class]['confidence_sum'] += log.confidence
            
            # å¹³å‡ä¿¡é ¼åº¦ã®è¨ˆç®—
            for obj_class, stats in object_stats.items():
                if stats['count'] > 0:
                    stats['avg_confidence'] = stats['confidence_sum'] / stats['count']
                    del stats['confidence_sum']
                else:
                    stats['avg_confidence'] = 0.0
                    del stats['confidence_sum']
            
            # ã‚µãƒãƒªãƒ¼ã®ä½œæˆã¨ä¿å­˜
            summary = DetectionSummary.create_summary(
                camera_id=self.camera_id,
                start_time=start_time,
                end_time=end_time,
                total_frames=total_frames,
                object_stats=object_stats,
                metadata={
                    'ai_optimizer_enabled': self.ai_optimizer is not None,
                    'detection_smoother_enabled': self.detection_smoother is not None
                }
            )
            summary.save()
            
            # ã‚µãƒãƒªãƒ¼ã«é–¢é€£ã™ã‚‹ãƒ­ã‚°ã‚’é–¢é€£ä»˜ã‘
            for log in logs:
                log.summary_id = summary.id
                log.save()
                
            logger.info(f"Created detection summary for period {start_time} to {end_time}")
            
        except Exception as e:
            logger.error(f"Error creating detection summary: {str(e)}")

    def _create_empty_results(self) -> Dict[str, Any]:
        """
        ç©ºã®æ¤œå‡ºçµæœã‚’ä½œæˆ
        
        Returns:
            Dict[str, Any]: ç©ºã®æ¤œå‡ºçµæœ
        """
        return {
            'detections': {},
            'pose_landmarks': None,
            'hands_landmarks': None,
            'face_landmarks': None,
            'person_detected': False,
            'frame_info': {
                'width': 0,
                'height': 0,
                'channels': 0
            }
        } 