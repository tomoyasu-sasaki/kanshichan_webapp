"""
AIå‡¦ç†æœ€é©åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
- YOLOæ¨è«–ã®æœ€é©åŒ–
- MediaPipeãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æœ€é©åŒ–
- ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æ©Ÿèƒ½
- ãƒãƒƒãƒå‡¦ç†ã®å°å…¥
"""

import cv2
import numpy as np
import time
import threading
from typing import Dict, Any, List, Optional, Tuple
from collections import deque
import psutil
import torch
from utils.logger import setup_logger
from utils.config_manager import ConfigManager
from utils.exceptions import (
    ModelError, PerformanceError, OptimizationError, 
    ConfigError, wrap_exception
)

logger = setup_logger(__name__)


class PerformanceMonitor:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, window_size: int = 30):
        """
        Args:
            window_size: FPSè¨ˆç®—ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰
        """
        self.frame_times = deque(maxlen=window_size)
        self.inference_times = deque(maxlen=window_size)
        self.memory_usage = deque(maxlen=window_size)
        self.last_frame_time = time.time()
        
    def record_frame(self) -> None:
        """ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†æ™‚é–“ã‚’è¨˜éŒ²"""
        current_time = time.time()
        frame_time = current_time - self.last_frame_time
        self.frame_times.append(frame_time)
        self.last_frame_time = current_time
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚‚è¨˜éŒ²
        memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
        self.memory_usage.append(memory_mb)
        
    def record_inference_time(self, inference_time: float) -> None:
        """æ¨è«–æ™‚é–“ã‚’è¨˜éŒ²"""
        self.inference_times.append(inference_time)
        
    def get_current_fps(self) -> float:
        """ç¾åœ¨ã®FPSã‚’å–å¾—"""
        if len(self.frame_times) < 2:
            return 0.0
        avg_frame_time = sum(self.frame_times) / len(self.frame_times)
        return 1.0 / avg_frame_time if avg_frame_time > 0 else 0.0
        
    def get_avg_inference_time(self) -> float:
        """å¹³å‡æ¨è«–æ™‚é–“ã‚’å–å¾—ï¼ˆãƒŸãƒªç§’ï¼‰"""
        if not self.inference_times:
            return 0.0
        return (sum(self.inference_times) / len(self.inference_times)) * 1000
        
    def get_memory_usage(self) -> float:
        """ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—ï¼ˆMBï¼‰"""
        if not self.memory_usage:
            return 0.0
        return self.memory_usage[-1]
        
    def get_stats(self) -> Dict[str, float]:
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        return {
            'fps': self.get_current_fps(),
            'avg_inference_ms': self.get_avg_inference_time(),
            'memory_mb': self.get_memory_usage(),
            'frame_count': len(self.frame_times)
        }


class FrameSkipper:
    """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—æ©Ÿèƒ½"""
    
    def __init__(self, config_manager: Optional[ConfigManager] = None):
        self.config_manager = config_manager
        self.skip_rate = 1  # 1 = ã‚¹ã‚­ãƒƒãƒ—ãªã—
        self.frame_counter = 0
        self.target_fps = 15.0
        self.min_fps = 5.0
        self.max_skip_rate = 5
        self.last_adjustment = time.time()
        self.adjustment_interval = 2.0  # 2ç§’ã”ã¨ã«èª¿æ•´
        
    def should_process_frame(self, current_fps: float) -> bool:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ã™ã¹ãã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        self.frame_counter += 1
        
        # å‹•çš„ã‚¹ã‚­ãƒƒãƒ—ãƒ¬ãƒ¼ãƒˆèª¿æ•´
        self._adjust_skip_rate(current_fps)
        
        # ã‚¹ã‚­ãƒƒãƒ—ãƒ¬ãƒ¼ãƒˆã«åŸºã¥ã„ã¦å‡¦ç†åˆ¤å®š
        return (self.frame_counter % self.skip_rate) == 0
        
    def _adjust_skip_rate(self, current_fps: float) -> None:
        """ç¾åœ¨ã®FPSã«åŸºã¥ã„ã¦ã‚¹ã‚­ãƒƒãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å‹•çš„èª¿æ•´"""
        current_time = time.time()
        
        if current_time - self.last_adjustment < self.adjustment_interval:
            return
            
        self.last_adjustment = current_time
        
        if current_fps < self.min_fps:
            # FPSãŒä½ã™ãã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä¸Šã’ã‚‹
            self.skip_rate = min(self.skip_rate + 1, self.max_skip_rate)
            logger.debug(f"Low FPS detected ({current_fps:.1f}), increasing skip rate to {self.skip_rate}")
        elif current_fps > self.target_fps * 1.2:
            # FPSãŒååˆ†é«˜ã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä¸‹ã’ã‚‹
            self.skip_rate = max(self.skip_rate - 1, 1)
            logger.debug(f"High FPS detected ({current_fps:.1f}), decreasing skip rate to {self.skip_rate}")


class BatchProcessor:
    """ãƒãƒƒãƒå‡¦ç†æ©Ÿèƒ½"""
    
    def __init__(self, batch_size: int = 4, timeout_ms: int = 50):
        """
        Args:
            batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º
            timeout_ms: ãƒãƒƒãƒè“„ç©ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆãƒŸãƒªç§’ï¼‰
        """
        self.batch_size = batch_size
        self.timeout_ms = timeout_ms
        self.frame_buffer = []
        self.last_batch_time = time.time()
        self.enabled = False  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç„¡åŠ¹ï¼ˆå®Ÿé¨“çš„æ©Ÿèƒ½ï¼‰
        
    def add_frame(self, frame: np.ndarray) -> Optional[List[np.ndarray]]:
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ ã—ã€ãƒãƒƒãƒãŒæº–å‚™ã§ããŸã‚‰è¿”ã™
        
        Returns:
            ãƒãƒƒãƒãŒæº–å‚™ã§ããŸå ´åˆã¯ãƒ•ãƒ¬ãƒ¼ãƒ ãƒªã‚¹ãƒˆã€ãã†ã§ãªã‘ã‚Œã°None
        """
        if not self.enabled:
            return [frame]  # ãƒãƒƒãƒå‡¦ç†ãŒç„¡åŠ¹ã®å ´åˆã¯å³åº§ã«è¿”ã™
            
        self.frame_buffer.append(frame)
        current_time = time.time()
        
        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã«é”ã—ãŸã€ã¾ãŸã¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ãŸå ´åˆ
        if (len(self.frame_buffer) >= self.batch_size or 
            (current_time - self.last_batch_time) * 1000 > self.timeout_ms):
            
            batch = self.frame_buffer.copy()
            self.frame_buffer.clear()
            self.last_batch_time = current_time
            return batch
            
        return None


class AIOptimizer:
    """AIå‡¦ç†æœ€é©åŒ–ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config_manager: Optional[ConfigManager] = None):
        """
        Args:
            config_manager: è¨­å®šç®¡ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        try:
            self.config_manager = config_manager
            self.performance_monitor = PerformanceMonitor()
            self.frame_skipper = FrameSkipper(config_manager)
            self.batch_processor = BatchProcessor()
            
            # ğŸ†• æ¤œå‡ºçµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆæç”»ç¶™ç¶šæ€§ã®ãŸã‚ï¼‰
            self.last_yolo_results = None
            self.last_yolo_results_age = 0  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®çµŒéãƒ•ãƒ¬ãƒ¼ãƒ æ•°
            self.max_cache_age = 10  # æœ€å¤§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿æŒãƒ•ãƒ¬ãƒ¼ãƒ æ•°
            
            # æœ€é©åŒ–è¨­å®šã®èª­ã¿è¾¼ã¿
            self._load_optimization_settings()
            
            logger.info("AIOptimizer initialized successfully with detection caching")
            
        except Exception as e:
            optimization_error = wrap_exception(
                e, OptimizationError,
                "AIOptimizer initialization failed",
                details={'optimization_disabled': True}
            )
            logger.error(f"AIOptimizer initialization error: {optimization_error.to_dict()}")
            raise optimization_error
            
    def _load_optimization_settings(self) -> None:
        """æœ€é©åŒ–è¨­å®šã®èª­ã¿è¾¼ã¿"""
        if not self.config_manager:
            return
            
        try:
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—è¨­å®š
            self.frame_skipper.target_fps = self.config_manager.get('optimization.target_fps', 15.0)
            self.frame_skipper.min_fps = self.config_manager.get('optimization.min_fps', 5.0)
            self.frame_skipper.max_skip_rate = self.config_manager.get('optimization.max_skip_rate', 5)
            
            # ãƒãƒƒãƒå‡¦ç†è¨­å®š
            batch_enabled = self.config_manager.get('optimization.batch_processing.enabled', False)
            self.batch_processor.enabled = batch_enabled
            self.batch_processor.batch_size = self.config_manager.get('optimization.batch_processing.batch_size', 4)
            self.batch_processor.timeout_ms = self.config_manager.get('optimization.batch_processing.timeout_ms', 50)
            
            logger.info(f"Optimization settings loaded: target_fps={self.frame_skipper.target_fps}, "
                       f"batch_enabled={batch_enabled}")
                       
        except Exception as e:
            config_error = wrap_exception(
                e, ConfigError,
                "Failed to load optimization settings",
                details={'using_defaults': True}
            )
            logger.warning(f"Using default optimization settings: {config_error.to_dict()}")
            
    def optimize_yolo_inference(self, model, frame: np.ndarray) -> Optional[Any]:
        """
        YOLOæ¨è«–ã®æœ€é©åŒ–ï¼ˆæç”»ç¶™ç¶šæ€§ã‚’è€ƒæ…®ã—ãŸæ”¹è‰¯ç‰ˆï¼‰
        
        Args:
            model: YOLOãƒ¢ãƒ‡ãƒ«
            frame: å…¥åŠ›ãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            æ¨è«–çµæœï¼ˆæœ€é©åŒ–é©ç”¨æ¸ˆã¿ï¼‰
        """
        try:
            inference_start = time.time()
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å¹´é½¢ã‚’æ›´æ–°
            self.last_yolo_results_age += 1
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ—åˆ¤å®š
            current_fps = self.performance_monitor.get_current_fps()
            should_skip = not self.frame_skipper.should_process_frame(current_fps)
            
            if should_skip:
                # ğŸ†• ã‚¹ã‚­ãƒƒãƒ—æ™‚ã‚‚å‰å›ã®æ¤œå‡ºçµæœã‚’è¿”ã™ãƒ¢ãƒ¼ãƒ‰ã‚’è¿½åŠ 
                if (self.last_yolo_results is not None and 
                    self.last_yolo_results_age <= self.max_cache_age):
                    # å‰å›çµæœã‚’è¿”ã—ã¦æç”»ç¶™ç¶šæ€§ã‚’ç¶­æŒ
                    logger.debug(f"Using cached YOLO results (age: {self.last_yolo_results_age} frames)")
                    return self.last_yolo_results
                else:
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå¤ã™ãã‚‹å ´åˆã¯Noneã‚’è¿”ã™
                    logger.debug(f"Cache too old or empty, returning None (age: {self.last_yolo_results_age})")
                return None
                
            # ãƒ•ãƒ¬ãƒ¼ãƒ å‰å‡¦ç†ã®æœ€é©åŒ–
            optimized_frame = self._optimize_frame_preprocessing(frame)
            
            # YOLOæ¨è«–å®Ÿè¡Œ
            with torch.no_grad():  # å‹¾é…è¨ˆç®—ã‚’ç„¡åŠ¹åŒ–
                results = model(optimized_frame, verbose=False)
                
            # ğŸ†• æˆåŠŸã—ãŸæ¨è«–çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
            self.last_yolo_results = results
            self.last_yolo_results_age = 0  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥
                
            inference_time = time.time() - inference_start
            self.performance_monitor.record_inference_time(inference_time)
            
            logger.debug(f"YOLO inference completed, results cached")
            return results
            
        except Exception as e:
            model_error = wrap_exception(
                e, ModelError,
                "YOLO inference optimization failed",
                details={'fallback_to_standard': True}
            )
            logger.warning(f"YOLO optimization error: {model_error.to_dict()}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚å‰å›çµæœã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if (self.last_yolo_results is not None and 
                self.last_yolo_results_age <= self.max_cache_age):
                logger.debug("Fallback to cached YOLO results due to error")
                return self.last_yolo_results
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ¨™æº–æ¨è«–
            try:
                return model(frame, verbose=False)
            except Exception:
                return None
            
    def optimize_mediapipe_pipeline(self, pose_model, frame: np.ndarray) -> Optional[Any]:
        """
        MediaPipeãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æœ€é©åŒ–
        
        Args:
            pose_model: MediaPipe Poseãƒ¢ãƒ‡ãƒ«
            frame: å…¥åŠ›ãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            æ¨è«–çµæœï¼ˆæœ€é©åŒ–é©ç”¨æ¸ˆã¿ï¼‰
        """
        try:
            inference_start = time.time()
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚ºæœ€é©åŒ–
            optimized_frame = self._optimize_frame_for_mediapipe(frame)
            
            # MediaPipeæ¨è«–å®Ÿè¡Œ
            results = pose_model.process(optimized_frame)
            
            inference_time = time.time() - inference_start
            self.performance_monitor.record_inference_time(inference_time)
            
            return results
            
        except Exception as e:
            model_error = wrap_exception(
                e, ModelError,
                "MediaPipe pipeline optimization failed",
                details={'fallback_to_standard': True}
            )
            logger.warning(f"MediaPipe optimization error: {model_error.to_dict()}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ¨™æº–æ¨è«–
            return pose_model.process(frame)
            
    def _optimize_frame_preprocessing(self, frame: np.ndarray) -> np.ndarray:
        """ãƒ•ãƒ¬ãƒ¼ãƒ å‰å‡¦ç†ã®æœ€é©åŒ–"""
        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚ºã®æœ€é©åŒ–ï¼ˆè§£åƒåº¦ã‚’ä¸‹ã’ã¦å‡¦ç†é€Ÿåº¦å‘ä¸Šï¼‰
        height, width = frame.shape[:2]
        
        # è§£åƒåº¦ãŒé«˜ã™ãã‚‹å ´åˆã¯ãƒªã‚µã‚¤ã‚º
        max_width = 640
        if width > max_width:
            scale = max_width / width
            new_width = max_width
            new_height = int(height * scale)
            frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_LINEAR)
            
        return frame
        
    def _optimize_frame_for_mediapipe(self, frame: np.ndarray) -> np.ndarray:
        """MediaPipeç”¨ãƒ•ãƒ¬ãƒ¼ãƒ æœ€é©åŒ–"""
        # MediaPipeã¯RGBã‚’æœŸå¾…ã™ã‚‹ãŒã€å¤‰æ›ã‚³ã‚¹ãƒˆã‚’æœ€å°åŒ–
        if len(frame.shape) == 3 and frame.shape[2] == 3:
            # BGR to RGBå¤‰æ›
            return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        return frame
        
    def update_performance_stats(self) -> None:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’æ›´æ–°"""
        self.performance_monitor.record_frame()
        
    def get_performance_stats(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’å–å¾—"""
        stats = self.performance_monitor.get_stats()
        stats.update({
            'skip_rate': self.frame_skipper.skip_rate,
            'batch_enabled': self.batch_processor.enabled,
            'optimization_active': True,
            # ğŸ†• ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã‚’è¿½åŠ 
            'cache_active': self.last_yolo_results is not None,
            'cache_age': self.last_yolo_results_age,
            'max_cache_age': self.max_cache_age
        })
        return stats
        
    def log_performance_summary(self) -> None:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’ãƒ­ã‚°å‡ºåŠ›"""
        stats = self.get_performance_stats()
        logger.info(
            f"Performance Stats - FPS: {stats['fps']:.1f}, "
            f"Inference: {stats['avg_inference_ms']:.1f}ms, "
            f"Memory: {stats['memory_mb']:.1f}MB, "
            f"Skip Rate: {stats['skip_rate']}"
        ) 