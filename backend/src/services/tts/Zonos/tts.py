import torch
import torchaudio
import os
import argparse
from pathlib import Path
from typing import Optional, Union

from zonos.model import Zonos
from zonos.conditioning import make_cond_dict, supported_language_codes

# å¯¾å¿œè¨€èªã‚’æ—¥æœ¬èªã¨è‹±èªã®ã¿ã«åˆ¶é™
SUPPORTED_LANGUAGES = ["ja", "en-us"]

class MacOSTTSApp:
    """macOSå¯¾å¿œã®TTSã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆCLIç‰ˆï¼‰"""
    
    def __init__(self):
        # macOSç”¨ã®ãƒ‡ãƒã‚¤ã‚¹è¨­å®šï¼ˆMPSã‚’å„ªå…ˆï¼‰
        # MPSã¯ç¾åœ¨ä¸å®‰å®šãªãŸã‚ã€ä¸€æ™‚çš„ã«CPUã‚’ä½¿ç”¨
        if torch.backends.mps.is_available():
            self.device = torch.device("mps")
            print("âœ… MPSãƒ‡ãƒã‚¤ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™")
        elif torch.cuda.is_available():
            self.device = torch.device("cuda")
            print("âœ… CUDAãƒ‡ãƒã‚¤ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™")
        else:
            self.device = torch.device("cpu")
            print("âš ï¸  CPUãƒ‡ãƒã‚¤ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆZonosã®ã‚³ãƒ¼ãƒ‰ã§ã¯ç¾åœ¨MPSãŒä¸å®‰å®šãªãŸã‚ï¼‰")
        
        self.model = None
        self.current_model_type = None
        self.speaker_embedding = None
        self.speaker_audio_path = None
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        self.output_dir = Path("generated_audio")
        self.output_dir.mkdir(exist_ok=True)
    
    def load_model(self, model_choice: str = "Zyphra/Zonos-v0.1-hybrid"):
        """ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        if self.current_model_type != model_choice:
            if self.model is not None:
                del self.model
                if torch.backends.mps.is_available():
                    torch.mps.empty_cache()
                elif torch.cuda.is_available():
                    torch.cuda.empty_cache()
            
            print(f"ğŸ”„ {model_choice} ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            try:
                self.model = Zonos.from_pretrained(model_choice, device=self.device)
                self.model.requires_grad_(False).eval()
                self.current_model_type = model_choice
                print(f"âœ… {model_choice} ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            except Exception as e:
                print(f"âŒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦transformerãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™
                if "hybrid" in model_choice:
                    print("ğŸ”„ Hybridãƒ¢ãƒ‡ãƒ«ã«ã¯'mamba-ssm'ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒå¿…è¦ã§ã™ã€‚transformerãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™...")
                    fallback_model = "Zyphra/Zonos-v0.1-transformer"
                    self.model = Zonos.from_pretrained(fallback_model, device=self.device)
                    self.model.requires_grad_(False).eval()
                    self.current_model_type = fallback_model
                    print(f"âœ… {fallback_model} ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                else:
                    raise e
        
        return self.model
    
    def generate_basic_tts(
        self,
        text: str,
        language: str = "en-us",
        model_choice: str = "Zyphra/Zonos-v0.1-transformer",
        seed: int = 42,
        # éŸ³å£°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        fmax: float = 22050.0,
        pitch_std: float = 20.0,
        speaking_rate: float = 15.0,
        # æ„Ÿæƒ…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        happiness: float = 0.3077,
        sadness: float = 0.0256,
        anger: float = 0.0256,
        # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        cfg_scale: float = 2.0,
        max_new_tokens: int = 2580,
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        top_p: float = 0.9,
        min_p: float = 0.1,
        output_filename: str = None,
    ):
        """åŸºæœ¬çš„ãªTTSç”Ÿæˆï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ‹¡å¼µç‰ˆï¼‰"""
        if not text.strip():
            print("âŒ ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return None
        
        try:
            model = self.load_model(model_choice)
            
            torch.manual_seed(seed)
            
            print("ğŸ”Š éŸ³å£°ç”Ÿæˆä¸­...")
            
            # æ„Ÿæƒ…ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ§‹ç¯‰ï¼ˆæ­£è¦åŒ–ã•ã‚Œã‚‹ï¼‰
            # Happiness, Sadness, Disgust, Fear, Surprise, Anger, Other, Neutral
            emotion = [happiness, sadness, 0.0256, 0.0256, 0.0256, anger, 0.2564, 1.0 - happiness - sadness - anger]
            
            cond_dict = make_cond_dict(
                text=text,
                language=language,
                emotion=emotion,
                fmax=fmax,
                pitch_std=pitch_std,
                speaking_rate=speaking_rate,
                device=self.device
            )
            conditioning = model.prepare_conditioning(cond_dict)
            
            print("ğŸ”„ éŸ³å£°ã‚³ãƒ¼ãƒ‰ç”Ÿæˆä¸­...")
            codes = model.generate(
                conditioning,
                max_new_tokens=max_new_tokens,
                cfg_scale=cfg_scale,
                sampling_params={"top_p": top_p, "min_p": min_p}
            )
            
            print("ğŸ”„ éŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ‰ä¸­...")
            wavs = model.autoencoder.decode(codes).cpu()
            
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            if output_filename:
                output_path = Path(output_filename)
            else:
                output_path = self.output_dir / f"basic_tts_{seed}.wav"
            
            torchaudio.save(str(output_path), wavs[0], model.autoencoder.sampling_rate)
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±ã‚’è¡¨ç¤º
            print(f"""âœ… éŸ³å£°ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼
ğŸ“‚ ä¿å­˜å…ˆ: {output_path}
ğŸ“Š ä½¿ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
â€¢ è¨€èª: {language}
â€¢ æœ€å¤§å‘¨æ³¢æ•°: {fmax}Hz
â€¢ ãƒ”ãƒƒãƒå¤‰å‹•: {pitch_std}
â€¢ è©±é€Ÿ: {speaking_rate}
â€¢ æ„Ÿæƒ… - å¹¸ç¦: {happiness:.2f}, æ‚²ã—ã¿: {sadness:.2f}, æ€’ã‚Š: {anger:.2f}
â€¢ CFGã‚¹ã‚±ãƒ¼ãƒ«: {cfg_scale}
â€¢ ã‚·ãƒ¼ãƒ‰: {seed}""")
            
            return str(output_path)
            
        except Exception as e:
            print(f"âŒ éŸ³å£°ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return None
    
    def generate_voice_clone(
        self,
        text: str,
        reference_audio,
        language: str = "en-us",
        model_choice: str = "Zyphra/Zonos-v0.1-transformer",
        seed: int = 42,
        # éŸ³å£°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        fmax: float = 22050.0,
        pitch_std: float = 20.0,
        speaking_rate: float = 15.0,
        # æ„Ÿæƒ…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        happiness: float = 0.3077,
        sadness: float = 0.0256,
        anger: float = 0.0256,
        # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        cfg_scale: float = 2.0,
        max_new_tokens: int = 2580,
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        top_p: float = 0.9,
        min_p: float = 0.1,
        output_filename: str = None,
    ):
        """ãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³æ©Ÿèƒ½ä»˜ãTTSç”Ÿæˆï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ‹¡å¼µç‰ˆï¼‰"""
        if not text.strip():
            print("âŒ ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return None
        
        if not os.path.exists(reference_audio):
            print(f"âŒ å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« '{reference_audio}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None
        
        try:
            model = self.load_model(model_choice)
            
            torch.manual_seed(seed)
            
            print("ğŸ”Š å‚ç…§éŸ³å£°ã‚’å‡¦ç†ä¸­...")
            
            # å‚ç…§éŸ³å£°ã‹ã‚‰è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆ
            if reference_audio != self.speaker_audio_path:
                wav, sr = torchaudio.load(reference_audio)
                self.speaker_embedding = model.make_speaker_embedding(wav, sr)
                self.speaker_embedding = self.speaker_embedding.to(self.device)
                self.speaker_audio_path = reference_audio
                print("âœ… æ–°ã—ã„è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            
            print("ğŸ”„ æ¡ä»¶ä»˜ã‘ã‚’æº–å‚™ä¸­...")
            
            # æ„Ÿæƒ…ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ§‹ç¯‰
            emotion = [happiness, sadness, 0.0256, 0.0256, 0.0256, anger, 0.2564, 1.0 - happiness - sadness - anger]
            
            cond_dict = make_cond_dict(
                text=text,
                language=language,
                speaker=self.speaker_embedding,
                emotion=emotion,
                fmax=fmax,
                pitch_std=pitch_std,
                speaking_rate=speaking_rate,
                device=self.device
            )
            conditioning = model.prepare_conditioning(cond_dict)
            
            print("ğŸ”„ éŸ³å£°ã‚³ãƒ¼ãƒ‰ç”Ÿæˆä¸­...")
            codes = model.generate(
                conditioning,
                max_new_tokens=max_new_tokens,
                cfg_scale=cfg_scale,
                sampling_params={"top_p": top_p, "min_p": min_p}
            )
            
            print("ğŸ”„ éŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ‰ä¸­...")
            wavs = model.autoencoder.decode(codes).cpu()
            
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            if output_filename:
                output_path = Path(output_filename)
            else:
                output_path = self.output_dir / f"voice_clone_{seed}.wav"
            
            torchaudio.save(str(output_path), wavs[0], model.autoencoder.sampling_rate)
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±ã‚’è¡¨ç¤º
            print(f"""âœ… ãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼
ğŸ“‚ ä¿å­˜å…ˆ: {output_path}
ğŸ“Š ä½¿ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
â€¢ è¨€èª: {language}
â€¢ æœ€å¤§å‘¨æ³¢æ•°: {fmax}Hz
â€¢ ãƒ”ãƒƒãƒå¤‰å‹•: {pitch_std}
â€¢ è©±é€Ÿ: {speaking_rate}
â€¢ æ„Ÿæƒ… - å¹¸ç¦: {happiness:.2f}, æ‚²ã—ã¿: {sadness:.2f}, æ€’ã‚Š: {anger:.2f}
â€¢ CFGã‚¹ã‚±ãƒ¼ãƒ«: {cfg_scale}
â€¢ ã‚·ãƒ¼ãƒ‰: {seed}""")
            
            return str(output_path)
            
        except Exception as e:
            print(f"âŒ ãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return None

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•° - ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    parser = argparse.ArgumentParser(description="Zonos TTS - CLIç‰ˆ")
    
    # ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã®è¨­å®š
    subparsers = parser.add_subparsers(dest="command", help="ä½¿ç”¨ã™ã‚‹ã‚³ãƒãƒ³ãƒ‰")
    
    # åŸºæœ¬TTSã‚³ãƒãƒ³ãƒ‰
    basic_parser = subparsers.add_parser("basic", help="åŸºæœ¬çš„ãªTTSç”Ÿæˆ")
    basic_parser.add_argument("--text", "-t", required=True, help="ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ")
    basic_parser.add_argument("--lang", "-l", choices=SUPPORTED_LANGUAGES, default="en-us", help="è¨€èª (ja/en-us)")
    basic_parser.add_argument("--model", "-m", choices=["Zyphra/Zonos-v0.1-transformer", "Zyphra/Zonos-v0.1-hybrid"], 
                              default="Zyphra/Zonos-v0.1-transformer", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«")
    basic_parser.add_argument("--seed", "-s", type=int, default=42, help="ä¹±æ•°ã‚·ãƒ¼ãƒ‰")
    basic_parser.add_argument("--output", "-o", help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    
    # éŸ³å£°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    basic_parser.add_argument("--fmax", type=float, default=22050.0, help="æœ€å¤§å‘¨æ³¢æ•° (Hz)")
    basic_parser.add_argument("--pitch-std", type=float, default=20.0, help="ãƒ”ãƒƒãƒå¤‰å‹•")
    basic_parser.add_argument("--speaking-rate", type=float, default=15.0, help="è©±é€Ÿ")
    
    # æ„Ÿæƒ…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    basic_parser.add_argument("--happiness", type=float, default=0.3077, help="å¹¸ç¦æ„Ÿ (0.0-1.0)")
    basic_parser.add_argument("--sadness", type=float, default=0.0256, help="æ‚²ã—ã¿ (0.0-1.0)")
    basic_parser.add_argument("--anger", type=float, default=0.0256, help="æ€’ã‚Š (0.0-1.0)")
    
    # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    basic_parser.add_argument("--cfg-scale", type=float, default=2.0, help="CFGã‚¹ã‚±ãƒ¼ãƒ«")
    basic_parser.add_argument("--max-tokens", type=int, default=2580, help="æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°")
    
    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    basic_parser.add_argument("--top-p", type=float, default=0.9, help="Top-p")
    basic_parser.add_argument("--min-p", type=float, default=0.1, help="Min-p")
    
    # ãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³ã‚³ãƒãƒ³ãƒ‰
    clone_parser = subparsers.add_parser("clone", help="ãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³ç”Ÿæˆ")
    clone_parser.add_argument("--text", "-t", required=True, help="ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ")
    clone_parser.add_argument("--reference", "-r", required=True, help="å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    clone_parser.add_argument("--lang", "-l", choices=SUPPORTED_LANGUAGES, default="en-us", help="è¨€èª (ja/en-us)")
    clone_parser.add_argument("--model", "-m", choices=["Zyphra/Zonos-v0.1-transformer", "Zyphra/Zonos-v0.1-hybrid"], 
                              default="Zyphra/Zonos-v0.1-transformer", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«")
    clone_parser.add_argument("--seed", "-s", type=int, default=42, help="ä¹±æ•°ã‚·ãƒ¼ãƒ‰")
    clone_parser.add_argument("--output", "-o", help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    
    # éŸ³å£°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    clone_parser.add_argument("--fmax", type=float, default=22050.0, help="æœ€å¤§å‘¨æ³¢æ•° (Hz)")
    clone_parser.add_argument("--pitch-std", type=float, default=20.0, help="ãƒ”ãƒƒãƒå¤‰å‹•")
    clone_parser.add_argument("--speaking-rate", type=float, default=15.0, help="è©±é€Ÿ")
    
    # æ„Ÿæƒ…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    clone_parser.add_argument("--happiness", type=float, default=0.3077, help="å¹¸ç¦æ„Ÿ (0.0-1.0)")
    clone_parser.add_argument("--sadness", type=float, default=0.0256, help="æ‚²ã—ã¿ (0.0-1.0)")
    clone_parser.add_argument("--anger", type=float, default=0.0256, help="æ€’ã‚Š (0.0-1.0)")
    
    # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    clone_parser.add_argument("--cfg-scale", type=float, default=2.0, help="CFGã‚¹ã‚±ãƒ¼ãƒ«")
    clone_parser.add_argument("--max-tokens", type=int, default=2580, help="æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°")
    
    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    clone_parser.add_argument("--top-p", type=float, default=0.9, help="Top-p")
    clone_parser.add_argument("--min-p", type=float, default=0.1, help="Min-p")
    
    # ãƒ˜ãƒ«ãƒ—ã‚³ãƒãƒ³ãƒ‰
    help_parser = subparsers.add_parser("help", help="ä½¿ç”¨æ–¹æ³•ã‚’è¡¨ç¤º")
    
    args = parser.parse_args()
    
    # ãƒ˜ãƒ«ãƒ—ã¾ãŸã¯ã‚³ãƒãƒ³ãƒ‰ãªã—ã®å ´åˆ
    if args.command is None or args.command == "help":
        print("""
ğŸ™ï¸ Zonos TTS - CLIç‰ˆ
=====================

åŸºæœ¬çš„ãªä½¿ã„æ–¹:
--------------
1. åŸºæœ¬çš„ãªTTSç”Ÿæˆ:
   python tts_app_macos.py basic --text "ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œ" --lang ja

2. ãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³ç”Ÿæˆ:
   python tts_app_macos.py clone --text "ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œ" --reference voice.wav --lang ja

è©³ç´°ãªãƒ˜ãƒ«ãƒ—:
-----------
- åŸºæœ¬TTS: python tts_app_macos.py basic --help
- ãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³: python tts_app_macos.py clone --help

å¯¾å¿œè¨€èª:
--------
- æ—¥æœ¬èª: ja
- è‹±èª: en-us
        """)
        return
    
    # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–
    app = MacOSTTSApp()
    
    # ã‚³ãƒãƒ³ãƒ‰ã«å¿œã˜ãŸå‡¦ç†
    if args.command == "basic":
        app.generate_basic_tts(
            text=args.text,
            language=args.lang,
            model_choice=args.model,
            seed=args.seed,
            # éŸ³å£°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            fmax=args.fmax,
            pitch_std=args.pitch_std,
            speaking_rate=args.speaking_rate,
            # æ„Ÿæƒ…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            happiness=args.happiness,
            sadness=args.sadness,
            anger=args.anger,
            # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            cfg_scale=args.cfg_scale,
            max_new_tokens=args.max_tokens,
            # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            top_p=args.top_p,
            min_p=args.min_p,
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
            output_filename=args.output
        )
    
    elif args.command == "clone":
        app.generate_voice_clone(
            text=args.text,
            reference_audio=args.reference,
            language=args.lang,
            model_choice=args.model,
            seed=args.seed,
            # éŸ³å£°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            fmax=args.fmax,
            pitch_std=args.pitch_std,
            speaking_rate=args.speaking_rate,
            # æ„Ÿæƒ…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            happiness=args.happiness,
            sadness=args.sadness,
            anger=args.anger,
            # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            cfg_scale=args.cfg_scale,
            max_new_tokens=args.max_tokens,
            # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            top_p=args.top_p,
            min_p=args.min_p,
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
            output_filename=args.output
        )


if __name__ == "__main__":
    main() 