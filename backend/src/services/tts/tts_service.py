"""
TTS Service - Refactored Zonos TTSã‚µãƒ¼ãƒ“ã‚¹

ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã€å¯èª­æ€§å‘ä¸Šã€ä¿å®ˆæ€§å‘ä¸Š
Zonos TTSã‚’ä½¿ç”¨ã—ãŸéŸ³å£°åˆæˆãƒ»éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³æ©Ÿèƒ½
"""

import os
import sys
import tempfile
import warnings
import time
import contextlib
import io
from typing import Dict, Any, List, Optional
from datetime import datetime
import torch
import torchaudio

# tqdmã®é€²æ—ãƒãƒ¼è¡¨ç¤ºã‚’ç„¡åŠ¹åŒ–
os.environ['TQDM_DISABLE'] = '1'
import tqdm
tqdm.tqdm.disable = True

from utils.logger import setup_logger
from utils.exceptions import AudioError, ServiceUnavailableError, wrap_exception
from .tts_config import TTSConfig
from .device_manager import DeviceManager
from .emotion_manager import EmotionManager
from .audio_processor import AudioProcessor
from .quality_evaluator import QualityEvaluator

logger = setup_logger(__name__)


class TTSService:
    """TTSéŸ³å£°åˆæˆã‚µãƒ¼ãƒ“ã‚¹ (ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆ)
    
    Zonos TTSã‚’ä½¿ç”¨ã—ãŸãƒ†ã‚­ã‚¹ãƒˆéŸ³å£°å¤‰æ›ãƒ»éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³æ©Ÿèƒ½
    - ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆéŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ï¼ˆ5-30ç§’ã‚µãƒ³ãƒ—ãƒ«ï¼‰
    - æ„Ÿæƒ…ãƒ»ãƒˆãƒ¼ãƒ³åˆ¶å¾¡
    - å¤šè¨€èªå¯¾å¿œï¼ˆæ—¥æœ¬èªãƒ¡ã‚¤ãƒ³ï¼‰
    - 44kHzé«˜å“è³ªéŸ³å£°å‡ºåŠ›
    - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã«ã‚ˆã‚‹ä¿å®ˆæ€§å‘ä¸Š
    """
    
    def __init__(self, config: Dict[str, Any]):
        """TTSã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        
        Args:
            config: TTSè¨­å®šè¾æ›¸
        """
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–
        self.tts_config = TTSConfig(config)
        self.device_manager = DeviceManager(self.tts_config)
        self.emotion_manager = EmotionManager()
        self.audio_processor = AudioProcessor(self.tts_config)
        self.quality_evaluator = QualityEvaluator()
        
        # Zonosãƒ¢ãƒ‡ãƒ«é–¢é€£
        self.model = None
        self.make_cond_dict = None
        self.is_initialized = False
        
        # é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰è¨­å®š
        self.fast_mode = config.get('tts', {}).get('fast_mode', False)
        
        logger.info(f"TTSService initialized - Model: {self.tts_config.model_name}, Device: {self.device_manager.device}, Fast Mode: {self.fast_mode}")
    
    def initialize(self) -> bool:
        """TTSãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        
        Returns:
            bool: åˆæœŸåŒ–æˆåŠŸãƒ•ãƒ©ã‚°
        """
        if self.is_initialized:
            logger.info("âœ… TTS model already initialized")
            return True
        
        try:
            print("\n" + "="*60)
            print("ğŸš€ TTS MODEL LOADING STARTED")
            print("="*60)
            logger.info("ğŸ”„ Initializing Zonos TTS model...")
            
            # ãƒ‡ãƒã‚¤ã‚¹æœ€é©åŒ–è¨­å®š
            logger.info(f"ğŸ“± Configuring device optimizations for: {self.device_manager.device}")
            self.device_manager.configure_device_optimizations()
            
            # Torch Compileæœ€é©åŒ–ç„¡åŠ¹åŒ–
            logger.info("ğŸ”§ Disabling torch compile optimizations...")
            self._disable_torch_compile_optimizations()
            
            # Zonosãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            logger.info("ğŸ“¦ Importing Zonos library...")
            try:
                from zonos.model import Zonos
                from zonos.conditioning import make_cond_dict
                logger.info("âœ… Zonos library imported successfully")
            except ImportError as import_error:
                print("âŒ ZONOS LIBRARY IMPORT FAILED")
                error = wrap_exception(
                    import_error, ServiceUnavailableError,
                    "Zonos TTS library not available. Please install zonos package.",
                    details={
                        'install_command': 'pip install git+https://github.com/Zyphra/Zonos.git',
                        'model_id': self.tts_config.get_model_id(),
                        'device': self.device_manager.device
                    }
                )
                logger.error(f"Zonos import error: {error.to_dict()}")
                print("="*60)
                return False
            
            # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã¨ãƒ‡ãƒã‚¤ã‚¹æœ€é©åŒ–
            try:
                model_id = self.tts_config.get_model_id()
                logger.info(f"ğŸ“¥ Loading TTS model: {model_id}")
                print(f"ğŸ“¥ Loading model: {model_id}")
                print(f"ğŸ¯ Target device: {self.device_manager.device.upper()}")
                
                # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿é–‹å§‹æ™‚åˆ»è¨˜éŒ²
                start_time = time.time()
                
                logger.info("ğŸ”„ Downloading/Loading model from Hugging Face...")
                print("ğŸ”„ Downloading/Loading model (this may take a while on first run)...")
                
                self.model = Zonos.from_pretrained(model_id, device=self.device_manager.device)
                
                load_time = time.time() - start_time
                logger.info(f"âœ… Model loaded in {load_time:.2f} seconds")
                print(f"âœ… Model loaded in {load_time:.2f} seconds")
                
                # ãƒ‡ãƒã‚¤ã‚¹æœ€é©åŒ–é©ç”¨
                logger.info(f"âš™ï¸ Applying device optimizations for {self.device_manager.device}...")
                print(f"âš™ï¸ Optimizing model for {self.device_manager.device.upper()}...")
                
                optimization_start = time.time()
                self.model = self.device_manager.optimize_model_for_device(self.model)
                optimization_time = time.time() - optimization_start
                
                logger.info(f"âœ… Device optimization completed in {optimization_time:.2f} seconds")
                print(f"âœ… Device optimization completed in {optimization_time:.2f} seconds")
                
                self.make_cond_dict = make_cond_dict
                self.is_initialized = True
                
                total_time = time.time() - start_time
                
                print("\n" + "="*60)
                print("ğŸ‰ TTS MODEL LOADING COMPLETED SUCCESSFULLY!")
                print(f"ğŸ“Š Model: {model_id}")
                print(f"ğŸ¯ Device: {self.device_manager.device.upper()}")
                print(f"â° Total initialization time: {total_time:.2f} seconds")
                print("="*60 + "\n")
                
                logger.info(f"ğŸ‰ Zonos TTS model initialized successfully on {self.device_manager.device.upper()} (total: {total_time:.2f}s)")
                return True
                
            except Exception as e:
                print(f"âš ï¸ PRIMARY DEVICE FAILED, ATTEMPTING FALLBACK...")
                logger.warning(f"Primary device initialization failed: {e}")
                
                # ãƒ‡ãƒã‚¤ã‚¹ã‚¨ãƒ©ãƒ¼ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
                try:
                    fallback_start = time.time()
                    new_device, fallback_model = self.device_manager.handle_device_error(e, self.model)
                    
                    print(f"ğŸ”„ Falling back to: {new_device.upper()}")
                    logger.info(f"Attempting fallback to device: {new_device}")
                    
                    if fallback_model is not None:
                        self.model = fallback_model
                    
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¾Œã®å†åˆæœŸåŒ–
                    if self.model is None:
                        model_id = self.tts_config.get_model_id()
                        logger.info(f"ğŸ“¥ Re-loading model on fallback device: {new_device}")
                        print(f"ğŸ“¥ Re-loading model on {new_device.upper()}...")
                        
                        self.model = Zonos.from_pretrained(model_id, device=new_device)
                        self.model = self.device_manager.optimize_model_for_device(self.model)
                    
                    self.make_cond_dict = make_cond_dict
                    self.is_initialized = True
                    
                    fallback_time = time.time() - fallback_start
                    
                    print("\n" + "="*60)
                    print("ğŸ‰ TTS MODEL LOADING COMPLETED (FALLBACK)!")
                    print(f"ğŸ“Š Model: {model_id}")
                    print(f"ğŸ¯ Device: {new_device.upper()} (fallback)")
                    print(f"â° Fallback initialization time: {fallback_time:.2f} seconds")
                    print("="*60 + "\n")
                    
                    logger.info(f"âœ… Zonos TTS model initialized successfully on {new_device.upper()} (fallback, {fallback_time:.2f}s)")
                    return True
                    
                except Exception as fallback_error:
                    print("âŒ TTS MODEL LOADING COMPLETELY FAILED!")
                    print(f"âŒ Original error: {str(e)}")
                    print(f"âŒ Fallback error: {str(fallback_error)}")
                    print("="*60)
                    
                    error = wrap_exception(
                        fallback_error, ServiceUnavailableError,
                        f"Failed to initialize Zonos TTS model even with fallback: {model_id}",
                        details={
                            'model_id': model_id,
                            'original_device': self.device_manager.original_device,
                            'fallback_device': self.device_manager.device,
                            'original_error': str(e),
                            'fallback_error': str(fallback_error)
                        }
                    )
                    logger.error(f"TTS initialization error with fallback: {error.to_dict()}")
                    return False
            
        except Exception as e:
            print("âŒ TTS MODEL LOADING FAILED!")
            print(f"âŒ Error: {str(e)}")
            print("="*60)
            
            error = wrap_exception(
                e, ServiceUnavailableError,
                f"Failed to initialize Zonos TTS model: {self.tts_config.get_model_id()}",
                details={
                    'model_id': self.tts_config.get_model_id(),
                    'device': self.device_manager.device,
                    'use_hybrid': self.tts_config.use_hybrid
                }
            )
            logger.error(f"TTS initialization error: {error.to_dict()}")
            return False
    
    def generate_speech(self, 
                       text: str,
                       speaker_sample_path: Optional[str] = None,
                       language: Optional[str] = None,
                       emotion: str = 'neutral',
                       speed: float = 1.0,
                       pitch: float = 1.0,
                       output_path: Optional[str] = None) -> str:
        """éŸ³å£°åˆæˆ
        
        Args:
            text: åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            speaker_sample_path: éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ç”¨ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            language: è¨€èªã‚³ãƒ¼ãƒ‰ (ja, en-us, etc.)
            emotion: æ„Ÿæƒ…è¨­å®š (neutral, happy, sad, angry, etc.)
            speed: è©±é€Ÿèª¿æ•´ (0.5-2.0)
            pitch: éŸ³ç¨‹èª¿æ•´ (0.5-2.0)
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        if not self.is_initialized:
            if not self.initialize():
                raise ServiceUnavailableError("TTS service is not available")
        
        try:
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
            language = language or self.tts_config.default_language
            language = self.tts_config.normalize_language_code(language)
            output_path = output_path or self.audio_processor.generate_output_path()
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            cache_key = self.audio_processor.generate_cache_key(text, emotion, language, speaker_sample_path)
            cached_result = self.audio_processor.get_from_cache(cache_key)
            if cached_result:
                logger.info(f"ğŸ¯ Cache hit for audio generation: {cache_key[:8]}...")
                return cached_result
            
            # éŸ³å£°åˆæˆå®Ÿè¡Œ
            start_time = time.time()
            result_path = self._perform_speech_generation(text, speaker_sample_path, language, emotion, speed, pitch, output_path)
            generation_time = time.time() - start_time
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™æ›´æ–°
            self.audio_processor.update_metrics(generation_time)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self.audio_processor.save_to_cache(cache_key, result_path)
            
            logger.info(f"ğŸ‰ éŸ³å£°åˆæˆå®Œäº†! ç·æ‰€è¦æ™‚é–“: {generation_time:.2f}ç§’")
            return result_path
            
        except Exception as e:
            # ãƒ‡ãƒã‚¤ã‚¹ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†
            error_str = str(e).lower()
            if 'scatter_reduce' in error_str or 'aten::' in error_str or 'mps' in error_str:
                try:
                    logger.warning(f"ğŸ”§ Device error detected, attempting fallback: {e}")
                    new_device, _ = self.device_manager.handle_device_error(e, self.model)
                    
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¾Œã®ãƒ¢ãƒ‡ãƒ«å†åˆæœŸåŒ–ãŒå¿…è¦
                    if new_device == 'cpu' and self.device_manager.device == 'cpu':
                        logger.info("ğŸ”„ Reinitializing model on CPU after fallback...")
                        
                        # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç ´æ£„
                        self.model = None
                        self.is_initialized = False
                        
                        # CPUç’°å¢ƒã§ãƒ¢ãƒ‡ãƒ«ã‚’å†åˆæœŸåŒ–
                        if self.initialize():
                            logger.info("âœ… Model successfully reinitialized on CPU")
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¾Œã«å†è©¦è¡Œ
                            return self.generate_speech(text, speaker_sample_path, language, emotion, speed, pitch, output_path)
                        else:
                            raise ServiceUnavailableError("Failed to reinitialize TTS model on CPU")
                    
                except Exception as fallback_error:
                    logger.error(f"âŒ Fallback also failed: {fallback_error}")
                    raise AudioError(f"Speech generation failed even with device fallback: {str(e)}")
            
            # é€šå¸¸ã®ã‚¨ãƒ©ãƒ¼å‡¦ç†
            error = wrap_exception(
                e, AudioError,
                f"Failed to generate speech for text: {text[:50]}...",
                details={
                    'text_length': len(text),
                    'language': language,
                    'emotion': emotion,
                    'speed': speed,
                    'pitch': pitch,
                    'speaker_sample': speaker_sample_path is not None,
                    'output_path': output_path
                }
            )
            logger.error(f"Speech generation error: {error.to_dict()}")
            raise AudioError(f"Speech generation failed: {str(e)}")
    
    def _perform_speech_generation(self, text: str, speaker_sample_path: Optional[str], 
                                 language: str, emotion: str, speed: float, pitch: float, 
                                 output_path: str) -> str:
        """éŸ³å£°åˆæˆã®å®Ÿéš›ã®å‡¦ç†
        
        Args:
            text: åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            speaker_sample_path: éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«ãƒ‘ã‚¹
            language: è¨€èªã‚³ãƒ¼ãƒ‰
            emotion: æ„Ÿæƒ…è¨­å®š
            speed: è©±é€Ÿ
            pitch: éŸ³ç¨‹
            output_path: å‡ºåŠ›ãƒ‘ã‚¹
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        with torch.no_grad():
            logger.info(f"ğŸµ éŸ³å£°åˆæˆé–‹å§‹: '{text[:50]}...' (è¨€èª: {language}, æ„Ÿæƒ…: {emotion})")
            
            # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
            speaker_embedding = None
            if speaker_sample_path and self.tts_config.enable_voice_cloning:
                logger.info("ğŸ“ ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿ç”Ÿæˆä¸­...")
                speaker_embedding = self._create_speaker_embedding(speaker_sample_path)
                logger.info("âœ… ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿ç”Ÿæˆå®Œäº†")
            
            # æ„Ÿæƒ…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æº–å‚™
            logger.info("âš™ï¸ éŸ³å£°ç”Ÿæˆæ¡ä»¶ã‚’æº–å‚™ä¸­...")
            emotion_params = self.emotion_manager.prepare_emotion_parameters(emotion, speed, pitch)
            
            # æ¡ä»¶è¾æ›¸æ§‹ç¯‰
            cond_dict_params = {
                'text': text,
                'language': language,
                **emotion_params
            }
            
            if speaker_embedding is not None:
                cond_dict_params['speaker'] = speaker_embedding
            
            # ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°æº–å‚™
            cond_dict = self.make_cond_dict(**cond_dict_params)
            cond_dict = self._ensure_conditioning_device_consistency(cond_dict)
            conditioning = self.model.prepare_conditioning(cond_dict)
            logger.info("âœ… éŸ³å£°ç”Ÿæˆæ¡ä»¶ã®æº–å‚™å®Œäº†")
            
            # éŸ³å£°ç”Ÿæˆï¼ˆé€²æ—ãƒãƒ¼æŠ‘åˆ¶ï¼‰
            logger.info("ğŸš€ Zonos TTSãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹éŸ³å£°ç”Ÿæˆä¸­...")
            generation_start = time.time()
            
            with contextlib.redirect_stdout(io.StringIO()), \
                 contextlib.redirect_stderr(io.StringIO()), \
                 warnings.catch_warnings():
                warnings.simplefilter("ignore")
                codes = self.model.generate(conditioning)
            
            generation_time = time.time() - generation_start
            logger.info(f"âœ… éŸ³å£°ã‚³ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº† (æ‰€è¦æ™‚é–“: {generation_time:.2f}ç§’)")
            
            # ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦éŸ³å£°æ³¢å½¢ã‚’å–å¾—
            logger.info("ğŸ¶ éŸ³å£°æ³¢å½¢ãƒ‡ã‚³ãƒ¼ãƒ‰ä¸­...")
            wavs = self.model.autoencoder.decode(codes).cpu()
            logger.info("âœ… éŸ³å£°æ³¢å½¢ãƒ‡ã‚³ãƒ¼ãƒ‰å®Œäº†")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        logger.info(f"ğŸ’¾ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­: {output_path}")
        torchaudio.save(output_path, wavs[0], self.model.autoencoder.sampling_rate)
        
        # ä¿å­˜æ¤œè¨¼
        if not os.path.exists(output_path):
            raise AudioError(f"Generated audio file not found: {output_path}")
        
        file_size = os.path.getsize(output_path)
        logger.info(f"ğŸ“ ä¿å­˜å®Œäº†: {output_path} (ã‚µã‚¤ã‚º: {file_size} bytes)")
        
        return output_path
    
    def _create_speaker_embedding(self, audio_path: str) -> torch.Tensor:
        """ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿ã‚’ä½œæˆ
        
        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            torch.Tensor: ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿
        """
        try:
            with torch.no_grad():
                wav, sampling_rate = torchaudio.load(audio_path)
                
                # ãƒ‡ãƒã‚¤ã‚¹ä¸€è²«æ€§ã®ç¢ºä¿
                wav = self.device_manager.ensure_tensor_device_consistency(wav, self.model)
                
                speaker_embedding = self.model.make_speaker_embedding(wav, sampling_rate)
                logger.info(f"Speaker embedding created from: {audio_path}")
                return speaker_embedding
            
        except Exception as e:
            error = wrap_exception(
                e, AudioError,
                f"Failed to create speaker embedding from: {audio_path}",
                details={
                    'audio_path': audio_path,
                    'exists': os.path.exists(audio_path) if audio_path else False
                }
            )
            logger.error(f"Speaker embedding error: {error.to_dict()}")
            raise AudioError(f"Failed to create speaker embedding: {str(e)}")
    
    def _ensure_conditioning_device_consistency(self, cond_dict: Dict[str, Any]) -> Dict[str, Any]:
        """æ¡ä»¶è¾æ›¸å†…ã®ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒ‡ãƒã‚¤ã‚¹ä¸€è²«æ€§ã‚’ç¢ºä¿
        
        Args:
            cond_dict: æ¡ä»¶è¾æ›¸
            
        Returns:
            Dict[str, Any]: ãƒ‡ãƒã‚¤ã‚¹ä¸€è²«æ€§ãŒä¿è¨¼ã•ã‚ŒãŸæ¡ä»¶è¾æ›¸
        """
        if not self.is_initialized or self.model is None:
            return cond_dict
            
        try:
            for key, value in cond_dict.items():
                if isinstance(value, torch.Tensor):
                    cond_dict[key] = self.device_manager.ensure_tensor_device_consistency(value, self.model)
                        
            return cond_dict
        except Exception as e:
            logger.warning(f"Failed to ensure conditioning device consistency: {str(e)}")
            return cond_dict
    
    def _disable_torch_compile_optimizations(self) -> None:
        """Torch Compileã®æœ€é©åŒ–ã‚’ç„¡åŠ¹åŒ–"""
        try:
            import torch._dynamo
            torch._dynamo.config.disable = True
            torch._dynamo.config.suppress_errors = True
            torch.backends.cudnn.deterministic = True
            torch.backends.cudnn.benchmark = False
            logger.debug("Torch compile optimizations disabled for stable inference")
        except Exception as e:
            logger.warning(f"Failed to disable torch compile optimizations: {e}")
    
    # å…¬é–‹APIï¼ˆæ—¢å­˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç¶­æŒï¼‰
    def clone_voice(self, text: str, reference_audio_path: str, emotion: str = 'neutral',
                   output_path: Optional[str] = None, enhance_quality: bool = True) -> str:
        """éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ï¼ˆç‰¹åŒ–ç‰ˆï¼‰
        
        Args:
            text: åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            reference_audio_path: å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆ5-30ç§’æ¨å¥¨ï¼‰
            emotion: æ„Ÿæƒ…è¨­å®š
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            enhance_quality: éŸ³å£°å“è³ªå‘ä¸Šå‡¦ç†ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        if not self.tts_config.enable_voice_cloning:
            raise ServiceUnavailableError("Voice cloning is disabled")
        
        # å‚ç…§éŸ³å£°ã®æ¤œè¨¼
        self.audio_processor.validate_reference_audio(reference_audio_path)
        
        # éŸ³å£°å“è³ªå‘ä¸Šã®å‰å‡¦ç†
        processed_audio_path = reference_audio_path
        if enhance_quality:
            try:
                processed_audio_path = self.audio_processor.preprocess_reference_audio(reference_audio_path)
                logger.info(f"Using enhanced audio for voice cloning: {processed_audio_path}")
            except Exception as e:
                logger.warning(f"Audio enhancement failed, using original: {e}")
                processed_audio_path = reference_audio_path
        
        try:
            result = self.generate_speech(
                text=text,
                speaker_sample_path=processed_audio_path,
                emotion=emotion,
                output_path=output_path
            )
            
            # å‰å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
            if processed_audio_path != reference_audio_path and os.path.exists(processed_audio_path):
                try:
                    os.unlink(processed_audio_path)
                    logger.debug(f"Cleaned up preprocessed audio: {processed_audio_path}")
                except Exception as e:
                    logger.warning(f"Failed to cleanup preprocessed audio: {e}")
            
            return result
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚å‰å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if processed_audio_path != reference_audio_path and os.path.exists(processed_audio_path):
                try:
                    os.unlink(processed_audio_path)
                except Exception:
                    pass
            raise
    
    # æ„Ÿæƒ…åˆ¶å¾¡API
    def create_custom_emotion(self, **kwargs) -> List[float]:
        """ã‚«ã‚¹ã‚¿ãƒ æ„Ÿæƒ…ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œæˆ"""
        return self.emotion_manager.create_custom_emotion(**kwargs)
    
    def mix_emotions(self, primary_emotion: str, secondary_emotion: str, primary_weight: float = 0.7) -> List[float]:
        """æ„Ÿæƒ…ã‚’ãƒŸã‚­ã‚·ãƒ³ã‚°"""
        return self.emotion_manager.mix_emotions(primary_emotion, secondary_emotion, primary_weight)
    
    def get_available_emotions(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªæ„Ÿæƒ…åã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        return self.emotion_manager.get_available_emotions()
    
    # å“è³ªè©•ä¾¡API
    def evaluate_voice_sample_quality(self, audio_path: str) -> Dict[str, Any]:
        """éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«å“è³ªè©•ä¾¡"""
        return self.quality_evaluator.evaluate_voice_sample_quality(audio_path)
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹API
    def cleanup_old_files(self, max_age_hours: int = 24) -> int:
        """å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
        return self.audio_processor.cleanup_old_files(max_age_hours)
    
    def clear_audio_cache(self) -> int:
        """éŸ³å£°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        return self.audio_processor.clear_cache()
    
    # éåŒæœŸAPI
    async def generate_speech_async(self, text: str, **kwargs) -> str:
        """éåŒæœŸéŸ³å£°ç”Ÿæˆ"""
        return await self.audio_processor.generate_audio_async(self.generate_speech, text, **kwargs)
    
    # æƒ…å ±å–å¾—API
    def get_supported_languages(self) -> List[str]:
        """ã‚µãƒãƒ¼ãƒˆè¨€èªã‚’å–å¾—"""
        return self.tts_config.get_supported_languages()
    
    def get_service_status(self) -> Dict[str, Any]:
        """ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ã‚’å–å¾—"""
        status = {
            'initialized': self.is_initialized,
            'model_name': self.tts_config.model_name,
            'device_info': self.device_manager.get_device_info(),
            'voice_cloning_enabled': self.tts_config.enable_voice_cloning,
            'default_language': self.tts_config.default_language,
            'config': self.tts_config.to_dict(),
            'supported_languages': self.get_supported_languages(),
            'available_emotions': self.get_available_emotions()
        }
        
        return status
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚’å–å¾—"""
        metrics = self.audio_processor.get_performance_metrics()
        metrics['device_info'] = self.device_manager.get_device_info()
        metrics['emotion_info'] = self.emotion_manager.get_emotion_info()
        return metrics
    
    def generate_speech_fast(self, 
                           text: str,
                           speaker_sample_path: Optional[str] = None,
                           language: Optional[str] = None,
                           emotion: str = 'neutral',
                           output_path: Optional[str] = None) -> str:
        """é«˜é€ŸéŸ³å£°åˆæˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆç›¸å½“ï¼‰
        
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€è©³ç´°ãƒ­ã‚°ã€è¤‡é›‘ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’çœç•¥ã—ã¦é«˜é€ŸåŒ–
        
        Args:
            text: åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            speaker_sample_path: éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ç”¨ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            language: è¨€èªã‚³ãƒ¼ãƒ‰ (ja, en-us, etc.)
            emotion: æ„Ÿæƒ…è¨­å®š (ç¾åœ¨æœªä½¿ç”¨)
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        if not self.is_initialized:
            if not self.initialize():
                raise ServiceUnavailableError("TTS service is not available")
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆæœ€å°é™ï¼‰
        language = language or self.tts_config.default_language
        language = self.tts_config.normalize_language_code(language)
        output_path = output_path or self.audio_processor.generate_output_path()
        
        try:
            # ç›´æ¥çš„ãªéŸ³å£°åˆæˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆæ–¹å¼ï¼‰
            start_time = time.time()
            
            with torch.no_grad():
                # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿ç”Ÿæˆï¼ˆæœ€å°é™ï¼‰
                speaker_embedding = None
                if speaker_sample_path and self.tts_config.enable_voice_cloning:
                    wav, sampling_rate = torchaudio.load(speaker_sample_path)
                    wav = wav.to(self.device_manager.device)
                    speaker_embedding = self.model.make_speaker_embedding(wav, sampling_rate)
                
                # æ¡ä»¶è¾æ›¸æ§‹ç¯‰ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆæ–¹å¼ï¼‰
                cond_dict_params = {
                    'text': text,
                    'language': language,
                    'device': self.device_manager.device
                }
                
                if speaker_embedding is not None:
                    cond_dict_params['speaker'] = speaker_embedding
                
                # ç›´æ¥çš„ãªã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°
                cond_dict = self.make_cond_dict(**cond_dict_params)
                conditioning = self.model.prepare_conditioning(cond_dict)
                
                # éŸ³å£°ç”Ÿæˆï¼ˆé€²æ—ãªã—ã€ãƒ­ã‚°ãªã—ï¼‰
                codes = self.model.generate(conditioning)
                
                # éŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ‰
                wavs = self.model.autoencoder.decode(codes).cpu()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            torchaudio.save(output_path, wavs[0], self.model.autoencoder.sampling_rate)
            
            generation_time = time.time() - start_time
            
            # æœ€å°é™ã®ãƒ­ã‚°
            if not os.path.exists(output_path):
                raise AudioError(f"Generated audio file not found: {output_path}")
            
            logger.info(f"ğŸš€ Fast speech generation completed in {generation_time:.2f}s: {output_path}")
            return output_path
            
        except Exception as e:
            # ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãªã—ï¼‰
            logger.error(f"Fast speech generation failed: {str(e)}")
            raise AudioError(f"Fast speech generation failed: {str(e)}")
    
    def clone_voice_fast(self, text: str, reference_audio_path: str, 
                        language: Optional[str] = None, output_path: Optional[str] = None) -> str:
        """é«˜é€ŸéŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆç›¸å½“ï¼‰
        
        Args:
            text: åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            reference_audio_path: å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            language: è¨€èªã‚³ãƒ¼ãƒ‰
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        return self.generate_speech_fast(
            text=text,
            speaker_sample_path=reference_audio_path,
            language=language,
            output_path=output_path
        ) 