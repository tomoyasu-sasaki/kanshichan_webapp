"""
TTS Service - Refactored Zonos TTSã‚µãƒ¼ãƒ“ã‚¹

ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã€å¯èª­æ€§å‘ä¸Šã€ä¿å®ˆæ€§å‘ä¸Š
Zonos TTSã‚’ä½¿ç”¨ã—ãŸéŸ³å£°åˆæˆãƒ»éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³æ©Ÿèƒ½
"""

import os
import sys
import tempfile
import warnings
import time
import contextlib
import io
from typing import Dict, Any, List, Optional
from datetime import datetime
import torch
import torchaudio
import numpy as np
import random
import inspect

# tqdmã®é€²æ—ãƒãƒ¼è¡¨ç¤ºã‚’ç„¡åŠ¹åŒ–
os.environ['TQDM_DISABLE'] = '1'
import tqdm
tqdm.tqdm.disable = True

from utils.logger import setup_logger
from utils.exceptions import AudioError, ServiceUnavailableError, wrap_exception
from .tts_config import TTSConfig
from .device_manager import DeviceManager
from .emotion_manager import EmotionManager
from .audio_processor import AudioProcessor
from .quality_evaluator import QualityEvaluator

# åŸ‹ã‚è¾¼ã¿Zonosã¸ã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
EMBEDDED_ZONOS_PATH = os.path.join(os.path.dirname(__file__), 'vendor', 'zonos')
if EMBEDDED_ZONOS_PATH not in sys.path:
    sys.path.insert(0, EMBEDDED_ZONOS_PATH)

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹è¨­å®š
LOCAL_MODEL_DIR = os.path.join(EMBEDDED_ZONOS_PATH, "model")
LOCAL_CONFIG_PATH = os.path.join(LOCAL_MODEL_DIR, "config.json")
LOCAL_MODEL_PATH = os.path.join(LOCAL_MODEL_DIR, "model.safetensors")

logger = setup_logger(__name__)


class TTSService:
    """TTSéŸ³å£°åˆæˆã‚µãƒ¼ãƒ“ã‚¹ (ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆ)
    
    Zonos TTSã‚’ä½¿ç”¨ã—ãŸãƒ†ã‚­ã‚¹ãƒˆéŸ³å£°å¤‰æ›ãƒ»éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³æ©Ÿèƒ½
    - ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆéŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ï¼ˆ5-30ç§’ã‚µãƒ³ãƒ—ãƒ«ï¼‰
    - æ„Ÿæƒ…ãƒ»ãƒˆãƒ¼ãƒ³åˆ¶å¾¡
    - å¤šè¨€èªå¯¾å¿œï¼ˆæ—¥æœ¬èªãƒ¡ã‚¤ãƒ³ï¼‰
    - 44kHzé«˜å“è³ªéŸ³å£°å‡ºåŠ›
    - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã«ã‚ˆã‚‹ä¿å®ˆæ€§å‘ä¸Š
    """
    
    def __init__(self, config: Dict[str, Any]):
        """TTSã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        
        Args:
            config: TTSè¨­å®šè¾æ›¸
        """
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–
        self.tts_config = TTSConfig(config)
        self.device_manager = DeviceManager(self.tts_config)
        self.emotion_manager = EmotionManager()
        self.audio_processor = AudioProcessor(self.tts_config)
        self.quality_evaluator = QualityEvaluator()
        
        # Zonosãƒ¢ãƒ‡ãƒ«é–¢é€£
        self.model = None
        self.make_cond_dict = None
        self.is_initialized = False
        
        # é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰è¨­å®š
        self.fast_mode = config.get('tts', {}).get('fast_mode', False)
        
        logger.info(f"TTSService initialized - Model: {self.tts_config.model_name}, Device: {self.device_manager.device}, Fast Mode: {self.fast_mode}")
    
    def initialize(self) -> bool:
        """TTSãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        
        Returns:
            bool: åˆæœŸåŒ–æˆåŠŸãƒ•ãƒ©ã‚°
        """
        if self.is_initialized:
            logger.info("âœ… TTS model already initialized")
            return True
        
        try:
            logger.info("ğŸš€ TTS MODEL LOADING STARTED")
            logger.info("ğŸ”„ Initializing Zonos TTS model...")
            
            # Torch Compileæœ€é©åŒ–ç„¡åŠ¹åŒ–
            logger.info("ğŸ”§ Disabling torch compile optimizations...")
            self._disable_torch_compile_optimizations()
            
            # Zonosãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            logger.info("ğŸ“¦ Importing Zonos library...")
            try:
                # ã¾ãšåŸ‹ã‚è¾¼ã¿ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦ã¿ã‚‹
                logger.info("ğŸ” Trying embedded Zonos import...")
                from zonos.model import Zonos
                from zonos.conditioning import make_cond_dict
                logger.info("âœ… Zonos library imported from embedded code")
            except ImportError:
                # åŸ‹ã‚è¾¼ã¿ã‚³ãƒ¼ãƒ‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ãŸå ´åˆã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
                logger.warning("âš ï¸ Embedded import failed, trying installed package...")
                from zonos.model import Zonos
                from zonos.conditioning import make_cond_dict
                logger.info("âœ… Zonos library imported from installed package")
            except ImportError as import_error:
                logger.error("âŒ ZONOS LIBRARY IMPORT FAILED")
                error = wrap_exception(
                    import_error, ServiceUnavailableError,
                    "Zonos TTS library not available. Check embedded code or install zonos package.",
                    details={
                        'install_command': 'pip install git+https://github.com/Zyphra/Zonos.git',
                        'model_id': self.tts_config.get_model_id(),
                        'device': self.device_manager.device,
                        'embedded_path': EMBEDDED_ZONOS_PATH
                    }
                )
                logger.error(f"Zonos import error: {error.to_dict()}")
                return False
            
            # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã¨ãƒ‡ãƒã‚¤ã‚¹æœ€é©åŒ–
            try:
                model_id = self.tts_config.get_model_id()
                logger.info(f"ğŸ“¥ Loading TTS model: {model_id} on {self.device_manager.device}")
                
                # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿é–‹å§‹æ™‚åˆ»è¨˜éŒ²
                start_time = time.time()
                
                # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯
                if os.path.exists(LOCAL_CONFIG_PATH) and os.path.exists(LOCAL_MODEL_PATH):
                    logger.info(f"ğŸ“‚ Using local model files from: {LOCAL_MODEL_DIR}")
                    self.model = Zonos.from_local(LOCAL_CONFIG_PATH, LOCAL_MODEL_PATH, device=self.device_manager.device)
                else:
                    logger.warning(f"âš ï¸ Local model files not found. Downloading from HuggingFace: {model_id}")
                    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
                    self.model = Zonos.from_pretrained(model_id, device=self.device_manager.device)
                
                load_time = time.time() - start_time
                logger.info(f"âœ… Model loaded in {load_time:.2f} seconds")
                
                # ãƒ‡ãƒã‚¤ã‚¹æœ€é©åŒ–é©ç”¨
                logger.info(f"âš™ï¸ Optimizing model for {self.device_manager.device}...")
                
                optimization_start = time.time()
                self.model = self.device_manager.optimize_model_for_device(self.model)
                optimization_time = time.time() - optimization_start
                
                logger.info(f"âœ… Device optimization completed in {optimization_time:.2f} seconds")
                
                self.make_cond_dict = make_cond_dict
                self.is_initialized = True
                
                total_time = time.time() - start_time
                
                logger.info(f"ğŸ‰ Zonos TTS model initialized successfully on {self.device_manager.device.upper()} (total: {total_time:.2f}s)")
                return True
                
            except Exception as e:
                # ãƒ‡ãƒã‚¤ã‚¹ã‚¨ãƒ©ãƒ¼æ™‚ã¯CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                logger.warning(f"Device error detected, attempting fallback to CPU: {e}")
                
                # ã‚·ãƒ³ãƒ—ãƒ«ãªCPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                new_device, _ = self.device_manager.handle_device_error(e, self.model)
                
                try:
                    # CPUã§ãƒ¢ãƒ‡ãƒ«ã‚’å†ãƒ­ãƒ¼ãƒ‰
                    model_id = self.tts_config.get_model_id()
                    logger.info("ğŸ“¥ Re-loading model on CPU...")
                    
                    fallback_start = time.time()
                    
                    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯
                    if os.path.exists(LOCAL_CONFIG_PATH) and os.path.exists(LOCAL_MODEL_PATH):
                        logger.info(f"ğŸ“‚ Using local model files for CPU fallback: {LOCAL_MODEL_DIR}")
                        self.model = Zonos.from_local(LOCAL_CONFIG_PATH, LOCAL_MODEL_PATH, device='cpu')
                    else:
                        logger.warning(f"âš ï¸ Local model files not found. Downloading from HuggingFace for CPU fallback: {model_id}")
                        self.model = Zonos.from_pretrained(model_id, device='cpu')
                        
                    self.model = self.device_manager.optimize_model_for_device(self.model)
                    
                    self.make_cond_dict = make_cond_dict
                    self.is_initialized = True
                    
                    fallback_time = time.time() - fallback_start
                    
                    logger.info(f"ğŸ‰ TTS MODEL LOADING COMPLETED (CPU FALLBACK)")
                    logger.info(f"ğŸ“Š Model: {model_id}")
                    logger.info(f"ğŸ¯ Device: CPU (fallback)")
                    logger.info(f"â° Fallback initialization time: {fallback_time:.2f} seconds")

                    logger.info(f"âœ… Zonos TTS model initialized successfully on CPU (fallback, {fallback_time:.2f}s)")
                    return True
                    
                except Exception as fallback_error:
                    logger.error("âŒ TTS MODEL LOADING COMPLETELY FAILED!")
                    logger.error(f"âŒ Original error: {str(e)}")
                    logger.error(f"âŒ Fallback error: {str(fallback_error)}")
                    
                    error = wrap_exception(
                        fallback_error, ServiceUnavailableError,
                        f"Failed to initialize Zonos TTS model even with CPU fallback: {model_id}",
                        details={
                            'model_id': model_id,
                            'device': self.device_manager.device,
                            'original_error': str(e),
                            'fallback_error': str(fallback_error)
                        }
                    )
                    logger.error(f"TTS initialization error with fallback: {error.to_dict()}")
                    return False
            
        except Exception as e:
            logger.error("âŒ TTS MODEL LOADING FAILED!")
            logger.error(f"âŒ Error: {str(e)}")
            
            error = wrap_exception(
                e, ServiceUnavailableError,
                f"Failed to initialize Zonos TTS model: {self.tts_config.get_model_id()}",
                details={
                    'model_id': self.tts_config.get_model_id(),
                    'device': self.device_manager.device
                }
            )
            logger.error(f"TTS initialization error: {error.to_dict()}")
            return False
    
    def generate_speech(self, 
                       text: str,
                       speaker_sample_path: Optional[str] = None,
                       language: Optional[str] = None,
                       emotion: str = 'neutral',
                       speed: float = 1.0,
                       pitch: float = 1.0,
                       max_frequency: int = 24000,
                       audio_quality: float = 4.0,
                       vq_score: float = 0.78,
                       output_path: Optional[str] = None,
                       # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                       cfg_scale: float = 0.8,
                       min_p: float = 0.0,
                       seed: Optional[int] = None,
                       # ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
                       breath_style: bool = False,
                       whisper_style: bool = False,
                       style_intensity: float = 0.5,
                       speaker_noised: bool = False,
                       # å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                       noise_reduction: bool = True) -> str:
        """éŸ³å£°åˆæˆ
        
        Args:
            text: åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            speaker_sample_path: éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ç”¨ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            language: è¨€èªã‚³ãƒ¼ãƒ‰ (ja, en-us, etc.)
            emotion: æ„Ÿæƒ…è¨­å®š (neutral, happy, sad, angry, etc.)
            speed: è©±é€Ÿèª¿æ•´ (0.5-2.0)
            pitch: éŸ³ç¨‹èª¿æ•´ (0.5-2.0)
            max_frequency: æœ€å¤§å‘¨æ³¢æ•° (8000-24000 Hz)
            audio_quality: éŸ³è³ªã‚¹ã‚³ã‚¢ç›®æ¨™ (1.0-5.0)
            vq_score: VQã‚¹ã‚³ã‚¢ (0.5-0.8)
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
            
            # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            cfg_scale: æ¡ä»¶ä»˜ãç¢ºç‡ã‚¹ã‚±ãƒ¼ãƒ« (0.0-1.5)
            min_p: æœ€å°ç¢ºç‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (0.0-1.0)
            seed: ä¹±æ•°ã‚·ãƒ¼ãƒ‰å€¤ï¼ˆå†ç¾æ€§ã®ãŸã‚ï¼‰
            
            # ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
            breath_style: æ¯ç¶™ãã‚¹ã‚¿ã‚¤ãƒ«ã®é©ç”¨
            whisper_style: ã•ã•ã‚„ãã‚¹ã‚¿ã‚¤ãƒ«ã®é©ç”¨
            style_intensity: ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨å¼·åº¦ (0.1-1.0)
            speaker_noised: è©±è€…ãƒã‚¤ã‚ºä»˜ä¸
            
            # å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            noise_reduction: ãƒã‚¤ã‚ºé™¤å»é©ç”¨
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        if not self.is_initialized:
            if not self.initialize():
                raise ServiceUnavailableError("TTS service is not available")
        
        try:
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
            language = language or self.tts_config.default_language
            language = self.tts_config.normalize_language_code(language)
            output_path = output_path or self.audio_processor.generate_output_path()
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            cache_key = self.audio_processor.generate_cache_key(text, emotion, language, speaker_sample_path)
            cached_result = self.audio_processor.get_from_cache(cache_key)
            if cached_result:
                logger.info(f"ğŸ¯ Cache hit for audio generation: {cache_key[:8]}...")
                return cached_result
            
            # ä¹±æ•°ã‚·ãƒ¼ãƒ‰è¨­å®šï¼ˆå†ç¾æ€§ã®ãŸã‚ï¼‰
            if seed is not None and seed > 0:
                logger.info(f"ğŸ² ã‚·ãƒ¼ãƒ‰å€¤ã‚’è¨­å®š: {seed}")
                torch.manual_seed(seed)
                np.random.seed(seed)
                random.seed(seed)
            
            # éŸ³å£°åˆæˆå®Ÿè¡Œ
            start_time = time.time()
            result_path = self._perform_speech_generation(
                text=text, 
                speaker_sample_path=speaker_sample_path, 
                language=language, 
                emotion=emotion, 
                speed=speed, 
                pitch=pitch, 
                max_frequency=max_frequency, 
                audio_quality=audio_quality, 
                vq_score=vq_score, 
                output_path=output_path,
                cfg_scale=cfg_scale,
                min_p=min_p,
                breath_style=breath_style,
                whisper_style=whisper_style,
                style_intensity=style_intensity,
                speaker_noised=speaker_noised,
                noise_reduction=noise_reduction
            )
            generation_time = time.time() - start_time
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™æ›´æ–°
            self.audio_processor.update_metrics(generation_time)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self.audio_processor.save_to_cache(cache_key, result_path)
            
            logger.info(f"ğŸ‰ éŸ³å£°åˆæˆå®Œäº†! ç·æ‰€è¦æ™‚é–“: {generation_time:.2f}ç§’")
            return result_path
            
        except Exception as e:
            # ãƒ‡ãƒã‚¤ã‚¹ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†
            error_str = str(e).lower()
            if 'scatter_reduce' in error_str or 'aten::' in error_str or 'mps' in error_str:
                try:
                    logger.warning(f"ğŸ”§ Device error detected, attempting fallback: {e}")
                    new_device, _ = self.device_manager.handle_device_error(e, self.model)
                    
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¾Œã®ãƒ¢ãƒ‡ãƒ«å†åˆæœŸåŒ–ãŒå¿…è¦
                    if new_device == 'cpu' and self.device_manager.device == 'cpu':
                        logger.info("ğŸ”„ Reinitializing model on CPU after fallback...")
                        
                        # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç ´æ£„
                        self.model = None
                        self.is_initialized = False
                        
                        # CPUç’°å¢ƒã§ãƒ¢ãƒ‡ãƒ«ã‚’å†åˆæœŸåŒ–
                        if self.initialize():
                            logger.info("âœ… Model successfully reinitialized on CPU")
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¾Œã«å†è©¦è¡Œ
                            return self.generate_speech(text, speaker_sample_path, language, emotion, speed, pitch, max_frequency, audio_quality, vq_score, output_path, cfg_scale, min_p, seed, breath_style, whisper_style, style_intensity, speaker_noised, noise_reduction)
                        else:
                            raise ServiceUnavailableError("Failed to reinitialize TTS model on CPU")
                    
                except Exception as fallback_error:
                    logger.error(f"âŒ Fallback also failed: {fallback_error}")
                    raise AudioError(f"Speech generation failed even with device fallback: {str(e)}")
            
            # é€šå¸¸ã®ã‚¨ãƒ©ãƒ¼å‡¦ç†
            error = wrap_exception(
                e, AudioError,
                f"Failed to generate speech for text: {text[:50]}...",
                details={
                    'text_length': len(text),
                    'language': language,
                    'emotion': emotion,
                    'speed': speed,
                    'pitch': pitch,
                    'speaker_sample': speaker_sample_path is not None,
                    'output_path': output_path
                }
            )
            logger.error(f"Speech generation error: {error.to_dict()}")
            raise AudioError(f"Speech generation failed: {str(e)}")
    
    def _perform_speech_generation(self, text: str, speaker_sample_path: Optional[str], 
                                 language: str, emotion: str, speed: float, pitch: float, 
                                 max_frequency: int, audio_quality: float, vq_score: float,
                                 output_path: str,
                                 cfg_scale: float,
                                 min_p: float,
                                 breath_style: bool,
                                 whisper_style: bool,
                                 style_intensity: float,
                                 speaker_noised: bool,
                                 noise_reduction: bool) -> str:
        """éŸ³å£°åˆæˆã®å®Ÿéš›ã®å‡¦ç†
        
        Args:
            text: åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            speaker_sample_path: éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«ãƒ‘ã‚¹
            language: è¨€èªã‚³ãƒ¼ãƒ‰
            emotion: æ„Ÿæƒ…è¨­å®š
            speed: è©±é€Ÿ
            pitch: éŸ³ç¨‹
            max_frequency: æœ€å¤§å‘¨æ³¢æ•° (Hz)
            audio_quality: éŸ³è³ªã‚¹ã‚³ã‚¢ç›®æ¨™
            vq_score: VQã‚¹ã‚³ã‚¢
            output_path: å‡ºåŠ›ãƒ‘ã‚¹
            
            # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            cfg_scale: æ¡ä»¶ä»˜ãç¢ºç‡ã‚¹ã‚±ãƒ¼ãƒ« (0.0-1.5)
            min_p: æœ€å°ç¢ºç‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (0.0-1.0)
            breath_style: æ¯ç¶™ãã‚¹ã‚¿ã‚¤ãƒ«ã®é©ç”¨
            whisper_style: ã•ã•ã‚„ãã‚¹ã‚¿ã‚¤ãƒ«ã®é©ç”¨
            style_intensity: ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨å¼·åº¦ (0.1-1.0)
            speaker_noised: è©±è€…ãƒã‚¤ã‚ºä»˜ä¸
            noise_reduction: ãƒã‚¤ã‚ºé™¤å»é©ç”¨
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        with torch.no_grad():
            logger.info(f"ğŸµ éŸ³å£°åˆæˆé–‹å§‹: '{text[:50]}...' (è¨€èª: {language}, æ„Ÿæƒ…: {emotion})")
            
            # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
            speaker_embedding = None
            if speaker_sample_path and self.tts_config.enable_voice_cloning:
                logger.info("ğŸ“ ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿ç”Ÿæˆä¸­...")
                speaker_embedding = self._create_speaker_embedding(speaker_sample_path)
                logger.info("âœ… ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿ç”Ÿæˆå®Œäº†")
            
            # æ„Ÿæƒ…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æº–å‚™
            logger.info("âš™ï¸ éŸ³å£°ç”Ÿæˆæ¡ä»¶ã‚’æº–å‚™ä¸­...")
            emotion_params = self.emotion_manager.prepare_emotion_parameters(emotion, speed, pitch)
            
            # æ¡ä»¶è¾æ›¸æ§‹ç¯‰
            cond_dict_params = {
                'text': text,
                'language': language,
                'fmax': max_frequency,       # æœ€å¤§å‘¨æ³¢æ•°
                'dnsmos_ovrl': audio_quality, # éŸ³è³ªã‚¹ã‚³ã‚¢ç›®æ¨™
                'vqscore_8': vq_score,       # VQã‚¹ã‚³ã‚¢
                **emotion_params
            }
            
            # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿è¨­å®š
            if speaker_embedding is not None:
                cond_dict_params['speaker'] = speaker_embedding
                
                # è©±è€…ãƒã‚¤ã‚ºè¨­å®šï¼ˆãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³æ™‚ã®ã¿æœ‰åŠ¹ï¼‰
                if speaker_noised:
                    # Zonosã®make_cond_dictã§å‡¦ç†å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                    cond_dict_params['speaker_noised'] = True
                    logger.info("ğŸ‘¤ è©±è€…ãƒã‚¤ã‚ºã‚’é©ç”¨ã—ã¾ã™")
            
            # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®šã‚’ãƒ­ã‚°ã«è¨˜éŒ²
            generation_params = {}
            
            # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
            generation_params['cfg_scale'] = cfg_scale
            generation_params['min_p'] = min_p
            logger.info(f"âš™ï¸ ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š: CFG={cfg_scale}, Min-P={min_p}")
            
            # ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
            if breath_style:
                generation_params['breath_style'] = True
                generation_params['style_intensity'] = style_intensity
                logger.info(f"ğŸ’¨ æ¯ç¶™ãã‚¹ã‚¿ã‚¤ãƒ«ã‚’é©ç”¨ã—ã¾ã™ (å¼·åº¦: {style_intensity})")
                
            if whisper_style:
                generation_params['whisper_style'] = True
                generation_params['style_intensity'] = style_intensity
                logger.info(f"ğŸ¤« ã•ã•ã‚„ãã‚¹ã‚¿ã‚¤ãƒ«ã‚’é©ç”¨ã—ã¾ã™ (å¼·åº¦: {style_intensity})")
                
            # ãƒã‚¤ã‚ºé™¤å»è¨­å®š
            generation_params['noise_reduction'] = noise_reduction
            if noise_reduction:
                logger.info("ğŸ”‡ ãƒã‚¤ã‚ºé™¤å»ã‚’é©ç”¨ã—ã¾ã™")
            
            # ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°æº–å‚™ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ç›´æ¥make_cond_dictã«æ¸¡ã›ã‚‹ã‚‚ã®ã ã‘ã‚’æ¸¡ã™ï¼‰
            cond_dict = self.make_cond_dict(**cond_dict_params)
            cond_dict = self._ensure_conditioning_device_consistency(cond_dict)
            conditioning = self.model.prepare_conditioning(cond_dict)
            logger.info("âœ… éŸ³å£°ç”Ÿæˆæ¡ä»¶ã®æº–å‚™å®Œäº†")
            
            # éŸ³å£°ç”Ÿæˆï¼ˆé€²æ—ãƒãƒ¼æŠ‘åˆ¶ï¼‰
            logger.info("ğŸš€ Zonos TTSãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹éŸ³å£°ç”Ÿæˆä¸­...")
            generation_start = time.time()
            
            with contextlib.redirect_stdout(io.StringIO()), \
                 contextlib.redirect_stderr(io.StringIO()), \
                 warnings.catch_warnings():
                warnings.simplefilter("ignore")
                
                # ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆæ™‚ã«è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¸¡ã™
                generate_params = {}
                
                # CFGã‚¹ã‚±ãƒ¼ãƒ«ã‚’ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦æ¸¡ã™ï¼ˆã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
                if hasattr(self.model, 'generate') and 'cfg_scale' in inspect.signature(self.model.generate).parameters:
                    generate_params['cfg_scale'] = cfg_scale
                    
                # Min-Pã‚’ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦æ¸¡ã™ï¼ˆã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
                if hasattr(self.model, 'generate') and 'min_p' in inspect.signature(self.model.generate).parameters:
                    generate_params['min_p'] = min_p
                
                # ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆå®Ÿè¡Œ
                if generate_params:
                    logger.info(f"ğŸ”§ ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é©ç”¨: {generate_params}")
                    codes = self.model.generate(conditioning, **generate_params)
                else:
                    # è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„å ´åˆã¯é€šå¸¸é€šã‚Šç”Ÿæˆ
                    logger.info("â„¹ï¸ æ¨™æº–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç”Ÿæˆã—ã¾ã™")
                    codes = self.model.generate(conditioning)
            
            generation_time = time.time() - generation_start
            logger.info(f"âœ… éŸ³å£°ã‚³ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº† (æ‰€è¦æ™‚é–“: {generation_time:.2f}ç§’)")
            
            # ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦éŸ³å£°æ³¢å½¢ã‚’å–å¾—
            logger.info("ğŸ¶ éŸ³å£°æ³¢å½¢ãƒ‡ã‚³ãƒ¼ãƒ‰ä¸­...")
            wavs = self.model.autoencoder.decode(codes).cpu()
            logger.info("âœ… éŸ³å£°æ³¢å½¢ãƒ‡ã‚³ãƒ¼ãƒ‰å®Œäº†")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        logger.info(f"ğŸ’¾ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­: {output_path}")
        torchaudio.save(output_path, wavs[0], self.model.autoencoder.sampling_rate)
        
        # ä¿å­˜æ¤œè¨¼
        if not os.path.exists(output_path):
            raise AudioError(f"Generated audio file not found: {output_path}")
        
        file_size = os.path.getsize(output_path)
        logger.info(f"ğŸ“ ä¿å­˜å®Œäº†: {output_path} (ã‚µã‚¤ã‚º: {file_size} bytes)")
        
        return output_path
    
    def _create_speaker_embedding(self, audio_path: str) -> torch.Tensor:
        """ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿ã‚’ä½œæˆ
        
        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            torch.Tensor: ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åŸ‹ã‚è¾¼ã¿
        """
        try:
            with torch.no_grad():
                wav, sampling_rate = torchaudio.load(audio_path)
                
                # ãƒ‡ãƒã‚¤ã‚¹ä¸€è²«æ€§ã®ç¢ºä¿
                wav = self.device_manager.ensure_tensor_device_consistency(wav, self.model)
                
                speaker_embedding = self.model.make_speaker_embedding(wav, sampling_rate)
                logger.info(f"Speaker embedding created from: {audio_path}")
                return speaker_embedding
            
        except Exception as e:
            error = wrap_exception(
                e, AudioError,
                f"Failed to create speaker embedding from: {audio_path}",
                details={
                    'audio_path': audio_path,
                    'exists': os.path.exists(audio_path) if audio_path else False
                }
            )
            logger.error(f"Speaker embedding error: {error.to_dict()}")
            raise AudioError(f"Failed to create speaker embedding: {str(e)}")
    
    def _ensure_conditioning_device_consistency(self, cond_dict: Dict[str, Any]) -> Dict[str, Any]:
        """æ¡ä»¶è¾æ›¸å†…ã®ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒ‡ãƒã‚¤ã‚¹ä¸€è²«æ€§ã‚’ç¢ºä¿
        
        Args:
            cond_dict: æ¡ä»¶è¾æ›¸
            
        Returns:
            Dict[str, Any]: ãƒ‡ãƒã‚¤ã‚¹ä¸€è²«æ€§ãŒç¢ºä¿ã•ã‚ŒãŸæ¡ä»¶è¾æ›¸
        """
        if not self.is_initialized or self.model is None:
            return cond_dict
            
        try:
            for key, value in cond_dict.items():
                if isinstance(value, torch.Tensor):
                    # MPSãƒ‡ãƒã‚¤ã‚¹ã®å ´åˆã¯float16ã«çµ±ä¸€ï¼ˆBF16/F16æ··åœ¨å•é¡Œã®å›é¿ï¼‰
                    if self.device_manager.device == 'mps':
                        # bfloat16ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ç‰¹åˆ¥ãªå‡¦ç†
                        if hasattr(value, 'dtype') and value.dtype == torch.bfloat16:
                            # ä¸€åº¦float32ã«å¤‰æ›ã—ã¦ã‹ã‚‰float16ã«å¤‰æ›ï¼ˆç›´æ¥ã®å¤‰æ›ã¯ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ï¼‰
                            cond_dict[key] = value.to(dtype=torch.float32).to(self.device_manager.device, dtype=torch.float16)
                        else:
                            cond_dict[key] = self.device_manager.ensure_tensor_device_consistency(value, self.model)
                        
                        # å‹ã®ç¢ºèªã¨è¨˜éŒ²
                        if hasattr(cond_dict[key], 'dtype'):
                            logger.debug(f"Tensor '{key}' dtype: {cond_dict[key].dtype}")
                    else:
                        cond_dict[key] = self.device_manager.ensure_tensor_device_consistency(value, self.model)
                        
            return cond_dict
        except Exception as e:
            logger.warning(f"Failed to ensure conditioning device consistency: {str(e)}")
            return cond_dict
    
    def _disable_torch_compile_optimizations(self) -> None:
        """Torch Compileã®æœ€é©åŒ–ã‚’ç„¡åŠ¹åŒ–"""
        try:
            import torch._dynamo
            torch._dynamo.config.disable = True
            torch._dynamo.config.suppress_errors = True
            torch.backends.cudnn.deterministic = True
            torch.backends.cudnn.benchmark = False
            logger.debug("Torch compile optimizations disabled for stable inference")
        except Exception as e:
            logger.warning(f"Failed to disable torch compile optimizations: {e}")
    
    # å…¬é–‹APIï¼ˆæ—¢å­˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç¶­æŒï¼‰
    def clone_voice(self, text: str, reference_audio_path: str, emotion: str = 'neutral',
                   output_path: Optional[str] = None, enhance_quality: bool = True) -> str:
        """éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ï¼ˆç‰¹åŒ–ç‰ˆï¼‰
        
        Args:
            text: åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            reference_audio_path: å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆ5-30ç§’æ¨å¥¨ï¼‰
            emotion: æ„Ÿæƒ…è¨­å®š
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            enhance_quality: éŸ³å£°å“è³ªå‘ä¸Šå‡¦ç†ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        if not self.tts_config.enable_voice_cloning:
            raise ServiceUnavailableError("Voice cloning is disabled")
        
        # å‚ç…§éŸ³å£°ã®æ¤œè¨¼
        self.audio_processor.validate_reference_audio(reference_audio_path)
        
        # éŸ³å£°å“è³ªå‘ä¸Šã®å‰å‡¦ç†
        processed_audio_path = reference_audio_path
        if enhance_quality:
            try:
                processed_audio_path = self.audio_processor.preprocess_reference_audio(reference_audio_path)
                logger.info(f"Using enhanced audio for voice cloning: {processed_audio_path}")
            except Exception as e:
                logger.warning(f"Audio enhancement failed, using original: {e}")
                processed_audio_path = reference_audio_path
        
        try:
            result = self.generate_speech(
                text=text,
                speaker_sample_path=processed_audio_path,
                emotion=emotion,
                output_path=output_path
            )
            
            # å‰å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
            if processed_audio_path != reference_audio_path and os.path.exists(processed_audio_path):
                try:
                    os.unlink(processed_audio_path)
                    logger.debug(f"Cleaned up preprocessed audio: {processed_audio_path}")
                except Exception as e:
                    logger.warning(f"Failed to cleanup preprocessed audio: {e}")
            
            return result
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚å‰å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if processed_audio_path != reference_audio_path and os.path.exists(processed_audio_path):
                try:
                    os.unlink(processed_audio_path)
                except Exception:
                    pass
            raise
    
    # æ„Ÿæƒ…åˆ¶å¾¡API
    def create_custom_emotion(self, **kwargs) -> List[float]:
        """ã‚«ã‚¹ã‚¿ãƒ æ„Ÿæƒ…ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œæˆ"""
        return self.emotion_manager.create_custom_emotion(**kwargs)
    
    def mix_emotions(self, primary_emotion: str, secondary_emotion: str, primary_weight: float = 0.7) -> List[float]:
        """æ„Ÿæƒ…ã‚’ãƒŸã‚­ã‚·ãƒ³ã‚°"""
        return self.emotion_manager.mix_emotions(primary_emotion, secondary_emotion, primary_weight)
    
    def get_available_emotions(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªæ„Ÿæƒ…åã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        return self.emotion_manager.get_available_emotions()
    
    # å“è³ªè©•ä¾¡API
    def evaluate_voice_sample_quality(self, audio_path: str) -> Dict[str, Any]:
        """éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«å“è³ªè©•ä¾¡"""
        return self.quality_evaluator.evaluate_voice_sample_quality(audio_path)
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹API
    def cleanup_old_files(self, max_age_hours: int = 24) -> int:
        """å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
        return self.audio_processor.cleanup_old_files(max_age_hours)
    
    def clear_audio_cache(self) -> int:
        """éŸ³å£°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        return self.audio_processor.clear_cache()
    
    # éåŒæœŸAPI
    async def generate_speech_async(self, text: str, **kwargs) -> str:
        """éåŒæœŸéŸ³å£°ç”Ÿæˆ"""
        return await self.audio_processor.generate_audio_async(self.generate_speech, text, **kwargs)
    
    # æƒ…å ±å–å¾—API
    def get_supported_languages(self) -> List[str]:
        """ã‚µãƒãƒ¼ãƒˆè¨€èªã‚’å–å¾—"""
        return self.tts_config.get_supported_languages()
    
    def get_service_status(self) -> Dict[str, Any]:
        """ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ã‚’å–å¾—"""
        status = {
            'initialized': self.is_initialized,
            'model_name': self.tts_config.model_name,
            'device_info': self.device_manager.get_device_info(),
            'voice_cloning_enabled': self.tts_config.enable_voice_cloning,
            'default_language': self.tts_config.default_language,
            'config': self.tts_config.to_dict(),
            'supported_languages': self.get_supported_languages(),
            'available_emotions': self.get_available_emotions()
        }
        
        return status
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚’å–å¾—"""
        metrics = self.audio_processor.get_performance_metrics()
        metrics['device_info'] = self.device_manager.get_device_info()
        metrics['emotion_info'] = self.emotion_manager.get_emotion_info()
        return metrics
    
    def generate_speech_fast(self, 
                           text: str,
                           speaker_sample_path: Optional[str] = None,
                           language: Optional[str] = None,
                           emotion: str = 'neutral',
                           speed: float = 1.0,
                           pitch: float = 1.0,
                           max_frequency: int = 24000,
                           audio_quality: float = 4.0,
                           vq_score: float = 0.78,
                           output_path: Optional[str] = None,
                           # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                           cfg_scale: float = 0.8,
                           min_p: float = 0.0,
                           seed: Optional[int] = None,
                           # ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
                           breath_style: bool = False,
                           whisper_style: bool = False,
                           style_intensity: float = 0.5,
                           speaker_noised: bool = False,
                           # å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                           noise_reduction: bool = True) -> str:
        """é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰éŸ³å£°åˆæˆ
        
        Args:
            text: åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            speaker_sample_path: éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ç”¨ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            language: è¨€èªã‚³ãƒ¼ãƒ‰ (ja, en-us, etc.)
            emotion: æ„Ÿæƒ…è¨­å®š (neutral, happy, sad, angry, etc.)
            speed: è©±é€Ÿèª¿æ•´ (0.5-2.0)
            pitch: éŸ³ç¨‹èª¿æ•´ (0.5-2.0)
            max_frequency: æœ€å¤§å‘¨æ³¢æ•° (8000-24000 Hz)
            audio_quality: éŸ³è³ªã‚¹ã‚³ã‚¢ç›®æ¨™ (1.0-5.0)
            vq_score: VQã‚¹ã‚³ã‚¢ (0.5-0.8)
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
            
            # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            cfg_scale: æ¡ä»¶ä»˜ãç¢ºç‡ã‚¹ã‚±ãƒ¼ãƒ« (0.0-1.5)
            min_p: æœ€å°ç¢ºç‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (0.0-1.0)
            seed: ä¹±æ•°ã‚·ãƒ¼ãƒ‰å€¤ï¼ˆå†ç¾æ€§ã®ãŸã‚ï¼‰
            
            # ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
            breath_style: æ¯ç¶™ãã‚¹ã‚¿ã‚¤ãƒ«ã®é©ç”¨
            whisper_style: ã•ã•ã‚„ãã‚¹ã‚¿ã‚¤ãƒ«ã®é©ç”¨
            style_intensity: ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨å¼·åº¦ (0.1-1.0)
            speaker_noised: è©±è€…ãƒã‚¤ã‚ºä»˜ä¸
            
            # å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            noise_reduction: ãƒã‚¤ã‚ºé™¤å»é©ç”¨
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        # ã‚¯ã‚¤ãƒƒã‚¯ãƒã‚§ãƒƒã‚¯
        if speaker_sample_path:
            logger.warning("é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ã§ã¯ãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³æ©Ÿèƒ½ã®ä¸€éƒ¨ã«åˆ¶é™ãŒã‚ã‚Šã¾ã™")
        
        # æ¨™æº–ã®éŸ³å£°åˆæˆé–¢æ•°ã«å§”è­²ã—ã€é«˜é€ŸåŒ–ç”¨ã®è¨­å®šã‚’é©ç”¨
        return self.generate_speech(
            text=text,
            speaker_sample_path=speaker_sample_path,
            language=language,
            emotion=emotion,
            speed=speed,
            pitch=pitch,
            max_frequency=max_frequency,
            audio_quality=audio_quality,
            vq_score=vq_score,
            output_path=output_path,
            cfg_scale=cfg_scale,
            min_p=min_p,
            seed=seed,
            breath_style=breath_style,
            whisper_style=whisper_style,
            style_intensity=style_intensity,
            speaker_noised=speaker_noised,
            noise_reduction=noise_reduction
        )
    
    def clone_voice_fast(self, text: str, reference_audio_path: str, 
                        language: Optional[str] = None, 
                        emotion: str = 'neutral',
                        speed: float = 1.0,
                        pitch: float = 1.0,
                        max_frequency: int = 24000,
                        audio_quality: float = 4.0,
                        vq_score: float = 0.78,
                        output_path: Optional[str] = None) -> str:
        """é«˜é€ŸéŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆç›¸å½“ï¼‰
        
        Args:
            text: åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            reference_audio_path: å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            language: è¨€èªã‚³ãƒ¼ãƒ‰
            emotion: æ„Ÿæƒ…è¨­å®š
            speed: è©±é€Ÿèª¿æ•´ (0.5-2.0)
            pitch: éŸ³ç¨‹èª¿æ•´ (0.5-2.0)
            max_frequency: æœ€å¤§å‘¨æ³¢æ•° (8000-24000 Hz)
            audio_quality: éŸ³è³ªã‚¹ã‚³ã‚¢ç›®æ¨™ (1.0-5.0)
            vq_score: VQã‚¹ã‚³ã‚¢ (0.5-0.8)
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        return self.generate_speech_fast(
            text=text,
            speaker_sample_path=reference_audio_path,
            language=language,
            emotion=emotion,
            speed=speed,
            pitch=pitch,
            max_frequency=max_frequency,
            audio_quality=audio_quality,
            vq_score=vq_score,
            output_path=output_path
        ) 