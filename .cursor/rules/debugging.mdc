---
description: 
globs: 
alwaysApply: false
---
# 🔧 KanshiChan デバッグ専用ルール

## 📋 このルールの目的
KanshiChan（監視ちゃん）プロジェクトにおけるデバッグ作業を効率的かつ体系的に実行するための専用ルールです。

## 🎯 デバッグ方針

### 📌 必須確認事項
デバッグ開始前に以下の規約を必ず参照してください：
- **[project_rules/main_rules.yaml](mdc:project_rules/main_rules.yaml)** - プロジェクト全体規約
- **[project_rules/backend_rules.yaml](mdc:project_rules/backend_rules.yaml)** - Python/Flask 規約
- **[project_rules/frontend_rules.yaml](mdc:project_rules/frontend_rules.yaml)** - React/TypeScript 規約
- **[project_rules/ai_ml_rules.yaml](mdc:project_rules/ai_ml_rules.yaml)** - AI/ML 規約

### 🔍 デバッグ優先順位
1. **セキュリティ問題** - 脆弱性、データ漏洩
2. **パフォーマンス問題** - AI処理遅延、メモリリーク
3. **機能不具合** - API エラー、UI動作不良
4. **データ整合性** - 検出結果、設定値
5. **ユーザビリティ** - 操作性、表示問題

---

## 🔄 デバッグプロセス

### 1. 問題の初期分析（10分）
```markdown
### 🚨 問題報告テンプレート
- **発生日時**: [日時]
- **環境**: [本番/ステージング/開発/ローカル]
- **影響範囲**: [全体/特定機能/特定ユーザー]
- **緊急度**: [Critical/High/Medium/Low]
- **再現性**: [必ず/時々/稀に/不明]

### 問題詳細
- **症状**: [具体的な症状を記述]
- **期待される動作**: [正常時の期待動作]
- **実際の動作**: [問題発生時の実際の動作]
- **エラーメッセージ**: [表示されたエラーがあれば記載]
- **再現手順**: [問題を再現するための手順]

### 環境情報
- **OS**: [OS種別・バージョン]
- **ブラウザ**: [ブラウザ・バージョン]※フロントエンド問題の場合
- **Python Version**: [バージョン]※バックエンド問題の場合
- **Node.js Version**: [バージョン]※フロントエンド問題の場合
```

### 2. ログ分析とデータ収集（15分）

#### 🐍 Backend (Python/Flask) ログ分析
```bash
# アプリケーションログ確認
tail -f backend/logs/app.log | grep ERROR
tail -f backend/logs/app.log | grep -A5 -B5 "トレース対象のキーワード"

# システムレベルログ確認
journalctl -u kanshi-chan.service -f
dmesg | grep -i error

# パフォーマンス監視
top -p $(pgrep -f "python.*kanshi-chan")
htop -p $(pgrep -f "python.*kanshi-chan")

# メモリ使用量詳細
python -c "
import psutil
import os
process = psutil.Process(os.getpid())
print(f'Memory usage: {process.memory_info().rss / 1024 / 1024:.2f} MB')
print(f'Open files: {len(process.open_files())}')
"
```

#### ⚛️ Frontend (React/TypeScript) デバッグ
```javascript
// ブラウザコンソールでのデバッグ
console.log('Component state:', state);
console.table(detectionResults);

// React DevTools 活用
// 1. Components タブでコンポーネント状態確認
// 2. Profiler タブでパフォーマンス問題特定

// ネットワークタブでAPI呼び出し確認
// 1. 失敗したリクエストの詳細確認
// 2. レスポンス時間の分析
// 3. ペイロードサイズの確認

// Performance タブでレンダリング問題分析
// 1. Frame rate の確認
// 2. 重い処理の特定
// 3. メモリリークの検出
```

#### 🤖 AI/ML デバッグ
```python
# YOLO デバッグ
import cv2
import numpy as np

def debug_yolo_detection(image_path, model):
    """YOLO検出のデバッグ用関数"""
    # 画像読み込み
    image = cv2.imread(image_path)
    print(f"Image shape: {image.shape}")
    print(f"Image dtype: {image.dtype}")
    print(f"Image range: [{image.min()}, {image.max()}]")
    
    # 前処理確認
    processed = model.preprocess(image)
    print(f"Processed shape: {processed.shape}")
    
    # 推論実行
    import time
    start_time = time.time()
    results = model.predict(image)
    inference_time = time.time() - start_time
    print(f"Inference time: {inference_time:.3f}s")
    
    # 結果分析
    if results:
        for i, result in enumerate(results):
            print(f"Result {i}:")
            print(f"  Boxes: {len(result.boxes) if result.boxes else 0}")
            if result.boxes:
                print(f"  Confidences: {result.boxes.conf.tolist()}")
                print(f"  Classes: {result.boxes.cls.tolist()}")
    
    return results

# MediaPipe デバッグ
def debug_mediapipe_pose(image_path, pose_detector):
    """MediaPipe姿勢検出のデバッグ用関数"""
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # 処理時間計測
    start_time = time.time()
    results = pose_detector.process(image_rgb)
    processing_time = time.time() - start_time
    print(f"MediaPipe processing time: {processing_time:.3f}s")
    
    # ランドマーク分析
    if results.pose_landmarks:
        landmarks = results.pose_landmarks.landmark
        print(f"Detected landmarks: {len(landmarks)}")
        
        # 重要なランドマークの座標確認
        important_landmarks = [0, 11, 12, 15, 16]  # 鼻、肩、手首
        for i in important_landmarks:
            landmark = landmarks[i]
            print(f"Landmark {i}: x={landmark.x:.3f}, y={landmark.y:.3f}, z={landmark.z:.3f}")
    else:
        print("No pose landmarks detected")
    
    return results
```

### 3. 仮説立案と検証（20分）

#### 🔍 問題分類と仮説立案
```markdown
### 問題分類
- [ ] **ロジック問題**: アルゴリズムやビジネスロジックの不具合
- [ ] **パフォーマンス問題**: 処理速度、メモリ使用量の問題
- [ ] **インテグレーション問題**: API連携、サービス間通信の問題
- [ ] **データ問題**: 入力データ、設定データの問題
- [ ] **環境問題**: OS、依存関係、設定の問題

### 仮説立案（問題分類別）
#### ロジック問題
- [ ] 条件分岐の誤り
- [ ] データ型の不一致
- [ ] null/undefined の未処理
- [ ] 非同期処理の競合状態

#### パフォーマンス問題
- [ ] メモリリーク
- [ ] 不要な再計算
- [ ] データベースN+1問題
- [ ] 大きなファイル/画像の処理

#### インテグレーション問題
- [ ] API エンドポイントの変更
- [ ] 認証トークンの期限切れ
- [ ] CORS設定の問題
- [ ] ネットワーク接続の問題
```

#### 🧪 仮説検証手法
```python
# Backend デバッグ検証例
def verify_hypothesis_data_processing():
    """データ処理仮説の検証"""
    # 1. 入力データの検証
    test_data = load_test_data()
    assert test_data is not None, "Test data should not be None"
    assert len(test_data) > 0, "Test data should not be empty"
    
    # 2. 処理結果の検証
    result = process_data(test_data)
    assert isinstance(result, dict), "Result should be a dictionary"
    assert 'status' in result, "Result should contain status"
    
    # 3. パフォーマンス検証
    import time
    start_time = time.time()
    large_data = generate_large_test_data(1000)
    process_data(large_data)
    processing_time = time.time() - start_time
    assert processing_time < 1.0, f"Processing should be under 1s, got {processing_time:.3f}s"

# Frontend デバッグ検証例
function verifyHypothesisComponentRendering() {
    // 1. State の検証
    console.assert(state.isDetecting !== undefined, 'isDetecting should be defined');
    console.assert(typeof state.isDetecting === 'boolean', 'isDetecting should be boolean');
    
    // 2. Props の検証
    console.assert(props.onToggleFullscreen, 'onToggleFullscreen prop is required');
    console.assert(typeof props.onToggleFullscreen === 'function', 'onToggleFullscreen should be function');
    
    // 3. レンダリング検証
    const element = document.querySelector('[data-testid="monitor-view"]');
    console.assert(element, 'Monitor view element should be rendered');
}
```

### 4. 問題の根本原因特定（30分）

#### 🔬 根本原因分析手法

##### 5 Whys分析
```markdown
### 5 Whys分析例
**問題**: AI検出処理が15 FPS を下回る

1. **なぜ FPS が低いのか？**
   → 1フレームあたりの処理時間が長いから

2. **なぜ処理時間が長いのか？**
   → YOLOモデルの推論に時間がかかっているから

3. **なぜ推論に時間がかかるのか？**
   → GPU を使用せずCPU で処理しているから

4. **なぜ GPU を使用していないのか？**
   → CUDA の設定が正しくないから

5. **なぜ CUDA の設定が正しくないのか？**
   → 環境変数 `CUDA_VISIBLE_DEVICES` が設定されていないから

**根本原因**: CUDA環境変数の未設定
**対策**: 環境変数の設定とGPU使用の確認
```

##### フィッシュボーン図分析
```markdown
### フィッシュボーン図（例：API応答遅延）

               人的要因          プロセス要因
                  │                │
            コード品質 ───┐    ┌─── アルゴリズム
            レビュー不足 ──┼────┼─── N+1クエリ
                  │      │    │      │
                         │    │      │
                      ┌─── API応答遅延 ───┐
                      │                  │
            ハードウェア ───┼────┼─── データベース
            CPU不足 ────┘    └─── インデックス不足
                  │                │
               環境要因          データ要因
```

#### 🛠️ 専門領域別デバッグ技術

##### Backend (Python) デバッグ
```python
# 1. pdb デバッガー使用
import pdb

def problematic_function(data):
    pdb.set_trace()  # ブレークポイント設定
    # ここでステップ実行可能
    result = process_data(data)
    return result

# 2. ログベースデバッグ
import logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

def debug_with_logging(data):
    logger.debug(f"Input data: {data}")
    try:
        result = risky_operation(data)
        logger.debug(f"Operation result: {result}")
        return result
    except Exception as e:
        logger.error(f"Operation failed: {e}", exc_info=True)
        raise

# 3. プロファイリング
import cProfile
import pstats

def profile_function():
    profiler = cProfile.Profile()
    profiler.enable()
    
    # 測定対象の処理
    heavy_computation()
    
    profiler.disable()
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(10)  # 上位10件表示

# 4. メモリ使用量デバッグ
from memory_profiler import profile

@profile
def memory_intensive_function():
    # メモリ使用量がライン単位で表示される
    large_list = [i for i in range(1000000)]
    return large_list
```

##### Frontend (React/TypeScript) デバッグ
```typescript
// 1. React DevTools Profiler
import { Profiler } from 'react';

function onRenderCallback(id: string, phase: string, actualDuration: number) {
  console.log(`Component ${id} took ${actualDuration}ms to ${phase}`);
}

const DebuggedComponent: React.FC = () => (
  <Profiler id="MonitorView" onRender={onRenderCallback}>
    <MonitorView />
  </Profiler>
);

// 2. useEffect デバッグ
useEffect(() => {
  console.log('Effect triggered:', { isDetecting, status });
  
  return () => {
    console.log('Effect cleanup');
  };
}, [isDetecting, status]);

// 3. カスタムデバッグHook
function useDebugValue<T>(value: T, label: string): T {
  useDebugValue(value, (val) => `${label}: ${JSON.stringify(val)}`);
  
  useEffect(() => {
    console.log(`${label} changed:`, value);
  }, [value, label]);
  
  return value;
}

// 4. パフォーマンス計測
function measurePerformance<T extends (...args: any[]) => any>(
  fn: T,
  label: string
): T {
  return ((...args: any[]) => {
    const start = performance.now();
    const result = fn(...args);
    const end = performance.now();
    console.log(`${label} took ${end - start}ms`);
    return result;
  }) as T;
}
```

##### AI/ML デバッグ
```python
# 1. モデル出力の可視化
def visualize_detection_results(image, results, save_path=None):
    """検出結果の可視化"""
    import matplotlib.pyplot as plt
    import matplotlib.patches as patches
    
    fig, ax = plt.subplots(1, figsize=(12, 8))
    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    
    # バウンディングボックス描画
    for result in results:
        if result.boxes:
            for box, conf, cls in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):
                x1, y1, x2, y2 = box.tolist()
                width, height = x2 - x1, y2 - y1
                
                # 矩形描画
                rect = patches.Rectangle(
                    (x1, y1), width, height,
                    linewidth=2, edgecolor='red', facecolor='none'
                )
                ax.add_patch(rect)
                
                # ラベル描画
                ax.text(x1, y1-10, f'Class: {int(cls)}, Conf: {conf:.2f}',
                       bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow"))
    
    if save_path:
        plt.savefig(save_path)
    plt.show()

# 2. 推論過程のステップ確認
def debug_inference_pipeline(image, model):
    """推論パイプラインのデバッグ"""
    print("=== Inference Pipeline Debug ===")
    
    # 前処理確認
    print("1. Image preprocessing...")
    print(f"   Original shape: {image.shape}")
    print(f"   Original dtype: {image.dtype}")
    
    # モデル入力形式確認
    print("2. Model input preparation...")
    preprocessed = model.preprocess(image)
    print(f"   Preprocessed shape: {preprocessed.shape}")
    
    # 推論実行
    print("3. Model inference...")
    import time
    start_time = time.time()
    raw_output = model.predict(image)
    inference_time = time.time() - start_time
    print(f"   Inference time: {inference_time:.3f}s")
    print(f"   Raw output type: {type(raw_output)}")
    
    # 後処理確認
    print("4. Post-processing...")
    if hasattr(raw_output[0], 'boxes') and raw_output[0].boxes is not None:
        boxes = raw_output[0].boxes
        print(f"   Detected boxes: {len(boxes.xyxy)}")
        print(f"   Confidence range: [{boxes.conf.min():.3f}, {boxes.conf.max():.3f}]")
        print(f"   Classes: {set(boxes.cls.int().tolist())}")
    else:
        print("   No boxes detected")
    
    return raw_output

# 3. GPU/CPU 使用状況確認
def monitor_gpu_usage():
    """GPU使用状況の監視"""
    try:
        import GPUtil
        gpus = GPUtil.getGPUs()
        for gpu in gpus:
            print(f"GPU {gpu.id}: {gpu.name}")
            print(f"  Memory: {gpu.memoryUsed}MB / {gpu.memoryTotal}MB ({gpu.memoryUtil*100:.1f}%)")
            print(f"  GPU Load: {gpu.load*100:.1f}%")
            print(f"  Temperature: {gpu.temperature}°C")
    except ImportError:
        print("GPUtil not available. Install with: pip install GPUtil")
```

---

## 🚨 緊急時対応プロセス

### Critical 問題対応（15分以内）
```markdown
### 緊急対応チェックリスト
- [ ] **影響範囲の特定**: 全ユーザー/特定機能/特定環境
- [ ] **一時回避策の適用**: サービス復旧の最短経路
- [ ] **ログとエビデンスの保存**: 後の詳細分析のため
- [ ] **関係者への報告**: 管理者・利用者への状況共有

### 一時回避策例
#### Backend サービス問題
```bash
# サービス再起動
sudo systemctl restart kanshi-chan.service

# ログ確認
sudo journalctl -u kanshi-chan.service --since "5 minutes ago"

# リソース確認
free -h
df -h
```

#### AI処理問題
```python
# フォールバック処理への切り替え
def emergency_fallback_detection():
    """緊急時のフォールバック検出処理"""
    return {
        'person_detected': False,
        'smartphone_detected': False,
        'confidence': 0.0,
        'fallback_mode': True,
        'message': 'AI処理が一時的に利用できません'
    }
```
```

### High 問題対応（1時間以内）
- 詳細な根本原因分析
- 恒久対策の立案と実装
- テストによる修正内容の検証
- ドキュメント更新

---

## 📊 デバッグ効率化ツール

### 🛠️ 推奨デバッグツール

#### Backend (Python)
```bash
# 必須ツール
pip install ipdb          # 高機能デバッガー
pip install memory-profiler  # メモリ使用量プロファイリング
pip install line-profiler   # ライン単位パフォーマンス分析
pip install py-spy          # プロダクション環境でのプロファイリング

# 使用例
python -m memory_profiler backend/src/core/detector.py
py-spy record -o profile.svg -- python -m backend.src.main
```

#### Frontend (TypeScript/React)
```bash
# ブラウザ拡張機能
# - React Developer Tools
# - Redux DevTools (状態管理使用時)
# - Vue.js devtools (Vue使用時)

# パフォーマンス分析
npm install --save-dev @typescript-eslint/parser
npm install --save-dev eslint-plugin-react-hooks

# Bundle分析
npm install --save-dev webpack-bundle-analyzer
npm run build:analyze
```

#### AI/ML
```bash
# モデル分析ツール
pip install tensorboard      # 学習過程可視化
pip install netron          # モデル構造可視化
pip install onnx onnxruntime # モデル最適化
pip install torchviz         # PyTorch計算グラフ可視化

# 使用例
tensorboard --logdir=runs
```

### 📈 自動監視とアラート設定
```python
# backend/src/utils/monitoring.py
import logging
import time
from functools import wraps

class PerformanceMonitor:
    """パフォーマンス監視クラス"""
    
    def __init__(self, threshold_ms=100):
        self.threshold_ms = threshold_ms
        self.logger = logging.getLogger(__name__)
    
    def monitor_execution_time(self, func_name=None):
        """実行時間監視デコレータ"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                start_time = time.time()
                try:
                    result = func(*args, **kwargs)
                    return result
                finally:
                    execution_time = (time.time() - start_time) * 1000
                    name = func_name or func.__name__
                    
                    if execution_time > self.threshold_ms:
                        self.logger.warning(
                            f"Slow execution detected: {name} took {execution_time:.2f}ms"
                        )
                    else:
                        self.logger.debug(
                            f"Execution time: {name} took {execution_time:.2f}ms"
                        )
            return wrapper
        return decorator

# 使用例
monitor = PerformanceMonitor(threshold_ms=50)

@monitor.monitor_execution_time()
def detect_objects(frame):
    # 検出処理
    pass
```

---

## 📝 デバッグレポートテンプレート

```markdown
# 🔧 デバッグレポート

## 📋 基本情報
- **問題ID**: [一意のID]
- **報告日時**: [日時]
- **担当者**: [デバッグ担当者]
- **緊急度**: [Critical/High/Medium/Low]
- **解決状況**: [解決済み/対応中/保留]

## 🚨 問題概要
### 症状
- [具体的な症状を記述]

### 影響範囲
- [影響を受ける機能・ユーザー]

### 再現条件
1. [手順1]
2. [手順2]
...

## 🔍 調査結果
### 根本原因
- [特定された根本原因]

### 発生メカニズム
- [問題が発生する仕組み]

### ログ・エビデンス
```text
[関連するログやエラーメッセージ]
```

## 🛠️ 対応内容
### 緊急対応
- [実施した緊急対応]

### 恒久対策
- [実施した恒久対策]

### 修正箇所
- [変更したファイル・関数]

## ✅ 検証結果
### テスト内容
- [実施したテスト]

### 結果
- [テスト結果]

### パフォーマンス影響
- [パフォーマンスへの影響]

## 📚 学習事項
### 今回学んだこと
- [デバッグ過程で学んだ技術・手法]

### 今後の予防策
- [同様の問題を防ぐための対策]

## 📈 フォローアップ
### 継続監視項目
- [今後監視すべき項目]

### 関連課題
- [関連する技術的課題]
```

---

## 🚀 継続的改善

### デバッグ効率化施策
- **月次**: デバッグツール・手法の見直し
- **四半期**: よくある問題パターンの文書化
- **半年**: 監視・アラート体制の改善

### チーム知識共有
- デバッグ事例の社内wiki蓄積
- デバッグ手法の勉強会開催
- 新メンバー向けデバッグガイド作成

このデバッグルールに従い、KanshiChanプロジェクトの問題を迅速かつ効果的に解決していきます。
